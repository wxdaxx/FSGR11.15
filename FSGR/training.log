nohup: ignoring input
/root/miniconda3/envs/m2release/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
使用设备: cuda
实验参数: exp_name=fsgr_baseline_test, batch_size=32, xe_base_lr=0.0002
加载已有词汇表...
词汇表大小: 10201
Loaded text embeddings from text_embeddings/ram_ViT16_clip_text.pth
===Missing keys: ['visual.prompt_embeddings', 'visual.deep_prompt_embeddings', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.bias', 'visual.prompt_proj.weight', 'visual.prompt_proj.bias', 'visual.prompt_norm.weight', 'visual.prompt_norm.bias', 'transformer.resblocks.0.S_Adapter.D_fc1.weight', 'transformer.resblocks.0.S_Adapter.D_fc1.bias', 'transformer.resblocks.0.S_Adapter.D_fc2.weight', 'transformer.resblocks.0.S_Adapter.D_fc2.bias', 'transformer.resblocks.1.S_Adapter.D_fc1.weight', 'transformer.resblocks.1.S_Adapter.D_fc1.bias', 'transformer.resblocks.1.S_Adapter.D_fc2.weight', 'transformer.resblocks.1.S_Adapter.D_fc2.bias', 'transformer.resblocks.2.S_Adapter.D_fc1.weight', 'transformer.resblocks.2.S_Adapter.D_fc1.bias', 'transformer.resblocks.2.S_Adapter.D_fc2.weight', 'transformer.resblocks.2.S_Adapter.D_fc2.bias', 'transformer.resblocks.3.S_Adapter.D_fc1.weight', 'transformer.resblocks.3.S_Adapter.D_fc1.bias', 'transformer.resblocks.3.S_Adapter.D_fc2.weight', 'transformer.resblocks.3.S_Adapter.D_fc2.bias', 'transformer.resblocks.4.S_Adapter.D_fc1.weight', 'transformer.resblocks.4.S_Adapter.D_fc1.bias', 'transformer.resblocks.4.S_Adapter.D_fc2.weight', 'transformer.resblocks.4.S_Adapter.D_fc2.bias', 'transformer.resblocks.5.S_Adapter.D_fc1.weight', 'transformer.resblocks.5.S_Adapter.D_fc1.bias', 'transformer.resblocks.5.S_Adapter.D_fc2.weight', 'transformer.resblocks.5.S_Adapter.D_fc2.bias', 'transformer.resblocks.6.S_Adapter.D_fc1.weight', 'transformer.resblocks.6.S_Adapter.D_fc1.bias', 'transformer.resblocks.6.S_Adapter.D_fc2.weight', 'transformer.resblocks.6.S_Adapter.D_fc2.bias', 'transformer.resblocks.7.S_Adapter.D_fc1.weight', 'transformer.resblocks.7.S_Adapter.D_fc1.bias', 'transformer.resblocks.7.S_Adapter.D_fc2.weight', 'transformer.resblocks.7.S_Adapter.D_fc2.bias', 'transformer.resblocks.8.S_Adapter.D_fc1.weight', 'transformer.resblocks.8.S_Adapter.D_fc1.bias', 'transformer.resblocks.8.S_Adapter.D_fc2.weight', 'transformer.resblocks.8.S_Adapter.D_fc2.bias', 'transformer.resblocks.9.S_Adapter.D_fc1.weight', 'transformer.resblocks.9.S_Adapter.D_fc1.bias', 'transformer.resblocks.9.S_Adapter.D_fc2.weight', 'transformer.resblocks.9.S_Adapter.D_fc2.bias', 'transformer.resblocks.10.S_Adapter.D_fc1.weight', 'transformer.resblocks.10.S_Adapter.D_fc1.bias', 'transformer.resblocks.10.S_Adapter.D_fc2.weight', 'transformer.resblocks.10.S_Adapter.D_fc2.bias', 'transformer.resblocks.11.S_Adapter.D_fc1.weight', 'transformer.resblocks.11.S_Adapter.D_fc1.bias', 'transformer.resblocks.11.S_Adapter.D_fc2.weight', 'transformer.resblocks.11.S_Adapter.D_fc2.bias']
===Unexpected keys: []
load pretrained weights!
开始训练...

===== Epoch 0 =====
Backbone lr = 0.000000, Dec lr = 0.000000
Epoch 0 - train:   0%|                                                                                             | 0/17710 [00:00<?, ?it/s]Epoch 0 - train:   0%|                                                                                  | 1/17710 [00:02<14:15:53,  2.90s/it]Epoch 0 - train:   0%|                                                                                   | 3/17710 [00:04<6:31:58,  1.33s/it]Epoch 0 - train:   0%|                                                                                   | 5/17710 [00:05<5:07:10,  1.04s/it]Epoch 0 - train:   0%|                                                                                   | 7/17710 [00:07<4:29:17,  1.10it/s]Epoch 0 - train:   0%|                                                                                   | 9/17710 [00:08<4:07:27,  1.19it/s]Epoch 0 - train:   0%|                                                                                  | 11/17710 [00:10<3:57:47,  1.24it/s]Epoch 0 - train:   0%|                                                                                  | 13/17710 [00:11<3:50:54,  1.28it/s]Epoch 0 - train:   0%|                                                                                  | 15/17710 [00:13<3:44:03,  1.32it/s]DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
Epoch 0 - train:   0%|                                                                                  | 17/17710 [00:14<3:41:48,  1.33it/s]Epoch 0 - train:   0%|                                                                                  | 19/17710 [00:16<3:39:43,  1.34it/s]Epoch 0 - train:   0%|                                                                                  | 21/17710 [00:17<3:36:30,  1.36it/s]Epoch 0 - train:   0%|                                                                                  | 23/17710 [00:19<3:34:11,  1.38it/s]Epoch 0 - train:   0%|                                                                                  | 25/17710 [00:20<3:32:43,  1.39it/s]Epoch 0 - train:   0%|▏                                                                                 | 27/17710 [00:21<3:32:13,  1.39it/s]Epoch 0 - train:   0%|▏                                                                                 | 29/17710 [00:23<3:30:40,  1.40it/s]mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
Epoch 0 - train:   0%|▏                                                                                 | 31/17710 [00:24<3:28:46,  1.41it/s]Epoch 0 - train:   0%|▏                                                                                 | 33/17710 [00:26<3:29:12,  1.41it/s]Epoch 0 - train:   0%|▏                                                                                 | 35/17710 [00:27<3:30:18,  1.40it/s]Epoch 0 - train:   0%|▏                                                                                 | 37/17710 [00:29<3:31:01,  1.40it/s]Epoch 0 - train:   0%|▏                                                                                 | 39/17710 [00:30<3:33:18,  1.38it/s]Epoch 0 - train:   0%|▏                                                                                 | 41/17710 [00:31<3:32:16,  1.39it/s]Epoch 0 - train:   0%|▏                                                                                 | 43/17710 [00:33<3:32:35,  1.39it/s]Epoch 0 - train:   0%|▏                                                                                 | 45/17710 [00:34<3:31:48,  1.39it/s]DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
Epoch 0 - train:   0%|▏                                                                                 | 47/17710 [00:36<3:33:54,  1.38it/s]Epoch 0 - train:   0%|▏                                                                                 | 49/17710 [00:37<3:32:12,  1.39it/s]Epoch 0 - train:   0%|▏                                                                      | 49/17710 [00:38<3:32:12,  1.39it/s, loss=9.28]Epoch 0 - train:   1%|▍                                                                       | 100/17710 [00:39<25:33, 11.48it/s, loss=9.28]DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
Epoch 0 - train:   1%|▍                                                                     | 112/17710 [00:48<1:10:16,  4.17it/s, loss=9.28]Epoch 0 - train:   1%|▍                                                                     | 121/17710 [00:54<1:39:26,  2.95it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
Epoch 0 - train:   1%|▌                                                                     | 128/17710 [01:00<2:03:43,  2.37it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 133/17710 [01:04<2:19:37,  2.10it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 137/17710 [01:06<2:31:16,  1.94it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 140/17710 [01:09<2:40:14,  1.83it/s, loss=9.28]padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
Epoch 0 - train:   1%|▌                                                                     | 143/17710 [01:11<2:50:05,  1.72it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 146/17710 [01:13<2:58:46,  1.64it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 148/17710 [01:15<3:04:29,  1.59it/s, loss=9.28]Epoch 0 - train:   1%|▌                                                                     | 148/17710 [01:15<3:04:29,  1.59it/s, loss=9.28]Epoch 0 - train:   1%|▊                                                                       | 199/17710 [01:16<34:53,  8.37it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 37]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 37, 37])
input shape: torch.Size([32, 37])
padding check shape: torch.Size([32, 37])
After unsqueeze shape: torch.Size([32, 1, 1, 37])
DEBUG: input.shape=torch.Size([32, 37])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 37, 37])
DEBUG: (input==padding).shape=torch.Size([32, 37])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 37])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:   1%|▊                                                                     | 211/17710 [01:25<1:14:40,  3.91it/s, loss=9.28]Epoch 0 - train:   1%|▊                                                                     | 220/17710 [01:31<1:40:33,  2.90it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
Epoch 0 - train:   1%|▉                                                                     | 227/17710 [01:36<1:58:50,  2.45it/s, loss=9.28]Epoch 0 - train:   1%|▉                                                                     | 232/17710 [01:40<2:12:07,  2.20it/s, loss=9.28]padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
Epoch 0 - train:   1%|▉                                                                     | 236/17710 [01:43<2:22:55,  2.04it/s, loss=9.28]Epoch 0 - train:   1%|▉                                                                     | 240/17710 [01:46<2:34:38,  1.88it/s, loss=9.28]Epoch 0 - train:   1%|▉                                                                     | 243/17710 [01:48<2:43:27,  1.78it/s, loss=9.28]Epoch 0 - train:   1%|▉                                                                     | 246/17710 [01:50<2:50:39,  1.71it/s, loss=9.28]Epoch 0 - train:   1%|▉                                                                     | 247/17710 [01:51<2:50:38,  1.71it/s, loss=9.28]Epoch 0 - train:   2%|█▏                                                                      | 297/17710 [01:51<37:32,  7.73it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
Epoch 0 - train:   2%|█▏                                                                    | 310/17710 [02:02<1:22:35,  3.51it/s, loss=9.28]Epoch 0 - train:   2%|█▏                                                                    | 312/17710 [02:03<1:29:23,  3.24it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
Epoch 0 - train:   2%|█▎                                                                    | 322/17710 [02:10<2:00:05,  2.41it/s, loss=9.28]Epoch 0 - train:   2%|█▎                                                                    | 329/17710 [02:16<2:19:02,  2.08it/s, loss=9.28]padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
Epoch 0 - train:   2%|█▎                                                                    | 335/17710 [02:20<2:34:01,  1.88it/s, loss=9.28]Epoch 0 - train:   2%|█▎                                                                    | 340/17710 [02:24<2:44:01,  1.76it/s, loss=9.28]Epoch 0 - train:   2%|█▎                                                                    | 344/17710 [02:27<2:53:38,  1.67it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
Epoch 0 - train:   2%|█▎                                                                    | 346/17710 [02:29<2:53:37,  1.67it/s, loss=9.28]Epoch 0 - train:   2%|█▌                                                                      | 396/17710 [02:29<49:17,  5.85it/s, loss=9.28]Epoch 0 - train:   2%|█▌                                                                    | 405/17710 [02:35<1:15:14,  3.83it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 35]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 35, 35])
input shape: torch.Size([32, 35])
padding check shape: torch.Size([32, 35])
After unsqueeze shape: torch.Size([32, 1, 1, 35])
DEBUG: input.shape=torch.Size([32, 35])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 35, 35])
DEBUG: (input==padding).shape=torch.Size([32, 35])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 35])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
Epoch 0 - train:   2%|█▋                                                                    | 412/17710 [02:41<1:36:07,  3.00it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 418/17710 [02:45<1:53:57,  2.53it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 422/17710 [02:48<2:06:35,  2.28it/s, loss=9.28]padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 33]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 33, 33])
input shape: torch.Size([32, 33])
padding check shape: torch.Size([32, 33])
After unsqueeze shape: torch.Size([32, 1, 1, 33])
DEBUG: input.shape=torch.Size([32, 33])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 33, 33])
DEBUG: (input==padding).shape=torch.Size([32, 33])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 33])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
Epoch 0 - train:   2%|█▋                                                                    | 426/17710 [02:51<2:19:47,  2.06it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 429/17710 [02:53<2:29:17,  1.93it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 432/17710 [02:55<2:40:48,  1.79it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 434/17710 [02:57<2:47:41,  1.72it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 436/17710 [02:58<2:53:30,  1.66it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                    | 436/17710 [03:12<2:53:30,  1.66it/s, loss=9.28]Epoch 0 - train:   2%|█▋                                                                   | 437/17710 [03:25<16:02:21,  3.34s/it, loss=9.28]Epoch 0 - train:   2%|█▋                                                                   | 438/17710 [03:27<15:28:33,  3.23s/it, loss=9.28]Epoch 0 - train:   2%|█▋                                                                   | 440/17710 [03:30<13:10:15,  2.75s/it, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 35]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 35, 35])
input shape: torch.Size([32, 35])
padding check shape: torch.Size([32, 35])
After unsqueeze shape: torch.Size([32, 1, 1, 35])
DEBUG: input.shape=torch.Size([32, 35])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 35, 35])
DEBUG: (input==padding).shape=torch.Size([32, 35])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 35])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
Epoch 0 - train:   2%|█▋                                                                   | 442/17710 [03:32<10:42:36,  2.23s/it, loss=9.28]Epoch 0 - train:   3%|█▊                                                                    | 444/17710 [03:33<8:35:37,  1.79s/it, loss=9.28]Epoch 0 - train:   3%|█▊                                                                    | 445/17710 [03:35<8:35:36,  1.79s/it, loss=9.28]Epoch 0 - train:   3%|██                                                                      | 495/17710 [03:35<51:59,  5.52it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
Epoch 0 - train:   3%|██                                                                    | 508/17710 [03:44<1:28:36,  3.24it/s, loss=9.28]Epoch 0 - train:   3%|██                                                                    | 517/17710 [03:50<1:50:03,  2.60it/s, loss=9.28]padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
Epoch 0 - train:   3%|██                                                                    | 524/17710 [03:55<2:05:58,  2.27it/s, loss=9.28]Epoch 0 - train:   3%|██                                                                    | 529/17710 [04:10<2:05:55,  2.27it/s, loss=9.28]Epoch 0 - train:   3%|██                                                                   | 530/17710 [05:33<15:55:24,  3.34s/it, loss=9.28]Epoch 0 - train:   3%|██                                                                   | 531/17710 [05:40<16:30:51,  3.46s/it, loss=9.28]Epoch 0 - train:   3%|██                                                                   | 535/17710 [05:43<14:10:36,  2.97s/it, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 32]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 32, 32])
input shape: torch.Size([32, 32])
padding check shape: torch.Size([32, 32])
After unsqueeze shape: torch.Size([32, 1, 1, 32])
DEBUG: input.shape=torch.Size([32, 32])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 32, 32])
DEBUG: (input==padding).shape=torch.Size([32, 32])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 32])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
Epoch 0 - train:   3%|██                                                                   | 538/17710 [05:46<12:21:53,  2.59s/it, loss=9.28]Epoch 0 - train:   3%|██                                                                   | 541/17710 [05:48<10:37:51,  2.23s/it, loss=9.28]Epoch 0 - train:   3%|██▏                                                                   | 544/17710 [05:50<9:02:54,  1.90s/it, loss=9.28]Epoch 0 - train:   3%|██▏                                                                   | 544/17710 [05:51<9:02:54,  1.90s/it, loss=9.28]Epoch 0 - train:   3%|██▎                                                                   | 595/17710 [05:51<1:32:45,  3.08it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
Epoch 0 - train:   3%|██▍                                                                   | 605/17710 [06:06<1:32:41,  3.08it/s, loss=9.28]Epoch 0 - train:   3%|██▍                                                                   | 606/17710 [06:15<3:17:26,  1.44it/s, loss=9.28]Epoch 0 - train:   3%|██▍                                                                   | 607/17710 [06:16<3:25:01,  1.39it/s, loss=9.28]padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
Epoch 0 - train:   3%|██▍                                                                   | 616/17710 [06:23<3:29:15,  1.36it/s, loss=9.28]Epoch 0 - train:   4%|██▍                                                                   | 623/17710 [06:28<3:28:23,  1.37it/s, loss=9.28]Epoch 0 - train:   4%|██▍                                                                   | 628/17710 [06:32<3:27:34,  1.37it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 47]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 47, 47])
input shape: torch.Size([32, 47])
padding check shape: torch.Size([32, 47])
After unsqueeze shape: torch.Size([32, 1, 1, 47])
DEBUG: input.shape=torch.Size([32, 47])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 47, 47])
DEBUG: (input==padding).shape=torch.Size([32, 47])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 47])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
Epoch 0 - train:   4%|██▍                                                                   | 632/17710 [06:35<3:26:33,  1.38it/s, loss=9.28]Epoch 0 - train:   4%|██▌                                                                   | 636/17710 [06:38<3:26:13,  1.38it/s, loss=9.28]Epoch 0 - train:   4%|██▌                                                                   | 639/17710 [06:40<3:24:58,  1.39it/s, loss=9.28]Epoch 0 - train:   4%|██▌                                                                   | 642/17710 [06:42<3:24:24,  1.39it/s, loss=9.28]Epoch 0 - train:   4%|██▌                                                                   | 643/17710 [06:43<3:24:23,  1.39it/s, loss=9.28]Epoch 0 - train:   4%|██▊                                                                     | 693/17710 [06:43<41:37,  6.81it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 31]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 31, 31])
input shape: torch.Size([32, 31])
padding check shape: torch.Size([32, 31])
After unsqueeze shape: torch.Size([32, 1, 1, 31])
DEBUG: input.shape=torch.Size([32, 31])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 31, 31])
DEBUG: (input==padding).shape=torch.Size([32, 31])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 31])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 31]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 31, 31])
input shape: torch.Size([32, 31])
padding check shape: torch.Size([32, 31])
After unsqueeze shape: torch.Size([32, 1, 1, 31])
DEBUG: input.shape=torch.Size([32, 31])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 31, 31])
DEBUG: (input==padding).shape=torch.Size([32, 31])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 31])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
Epoch 0 - train:   4%|██▊                                                                   | 705/17710 [06:52<1:16:10,  3.72it/s, loss=9.28]padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 33]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 33, 33])
input shape: torch.Size([32, 33])
padding check shape: torch.Size([32, 33])
After unsqueeze shape: torch.Size([32, 1, 1, 33])
DEBUG: input.shape=torch.Size([32, 33])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 33, 33])
DEBUG: (input==padding).shape=torch.Size([32, 33])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 33])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
Epoch 0 - train:   4%|██▊                                                                   | 714/17710 [06:58<1:39:05,  2.86it/s, loss=9.28]Epoch 0 - train:   4%|██▊                                                                   | 721/17710 [07:05<2:08:18,  2.21it/s, loss=9.28]Epoch 0 - train:   4%|██▊                                                                   | 726/17710 [07:08<2:18:26,  2.04it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
Epoch 0 - train:   4%|██▉                                                                   | 730/17710 [07:11<2:26:47,  1.93it/s, loss=9.28]Epoch 0 - train:   4%|██▉                                                                   | 734/17710 [07:14<2:36:31,  1.81it/s, loss=9.28]Epoch 0 - train:   4%|██▉                                                                   | 737/17710 [07:16<2:43:04,  1.73it/s, loss=9.28]Epoch 0 - train:   4%|██▉                                                                   | 740/17710 [07:18<2:50:49,  1.66it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
Epoch 0 - train:   4%|██▉                                                                   | 742/17710 [07:20<2:55:17,  1.61it/s, loss=9.28]Epoch 0 - train:   4%|██▉                                                                   | 742/17710 [07:20<2:55:17,  1.61it/s, loss=9.28]Epoch 0 - train:   4%|███▏                                                                    | 793/17710 [07:21<33:58,  8.30it/s, loss=9.28]Epoch 0 - train:   5%|███▏                                                                  | 805/17710 [07:30<1:11:02,  3.97it/s, loss=9.28]padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 52]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 52, 52])
input shape: torch.Size([32, 52])
padding check shape: torch.Size([32, 52])
After unsqueeze shape: torch.Size([32, 1, 1, 52])
DEBUG: input.shape=torch.Size([32, 52])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 52, 52])
DEBUG: (input==padding).shape=torch.Size([32, 52])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 52])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
Epoch 0 - train:   5%|███▏                                                                  | 814/17710 [07:36<1:35:54,  2.94it/s, loss=9.28]Epoch 0 - train:   5%|███▏                                                                  | 821/17710 [07:41<1:54:00,  2.47it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
Epoch 0 - train:   5%|███▎                                                                  | 827/17710 [07:45<2:08:48,  2.18it/s, loss=9.28]Epoch 0 - train:   5%|███▎                                                                  | 831/17710 [07:48<2:19:40,  2.01it/s, loss=9.28]Epoch 0 - train:   5%|███▎                                                                  | 835/17710 [07:51<2:30:05,  1.87it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 31]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 31, 31])
input shape: torch.Size([32, 31])
padding check shape: torch.Size([32, 31])
After unsqueeze shape: torch.Size([32, 1, 1, 31])
DEBUG: input.shape=torch.Size([32, 31])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 31, 31])
DEBUG: (input==padding).shape=torch.Size([32, 31])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 31])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 48]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 48, 48])
input shape: torch.Size([32, 48])
padding check shape: torch.Size([32, 48])
After unsqueeze shape: torch.Size([32, 1, 1, 48])
DEBUG: input.shape=torch.Size([32, 48])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 48, 48])
DEBUG: (input==padding).shape=torch.Size([32, 48])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 48])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
Epoch 0 - train:   5%|███▎                                                                  | 838/17710 [07:53<2:37:24,  1.79it/s, loss=9.28]Epoch 0 - train:   5%|███▎                                                                  | 841/17710 [07:55<2:43:03,  1.72it/s, loss=9.28]Epoch 0 - train:   5%|███▎                                                                  | 841/17710 [07:56<2:43:03,  1.72it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                    | 892/17710 [07:56<36:18,  7.72it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                    | 895/17710 [08:07<36:18,  7.72it/s, loss=9.28]Epoch 0 - train:   5%|███▌                                                                  | 896/17710 [08:31<3:57:12,  1.18it/s, loss=9.28]Epoch 0 - train:   5%|███▌                                                                  | 897/17710 [08:34<4:16:48,  1.09it/s, loss=9.28]padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 51]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 51, 51])
input shape: torch.Size([32, 51])
padding check shape: torch.Size([32, 51])
After unsqueeze shape: torch.Size([32, 1, 1, 51])
DEBUG: input.shape=torch.Size([32, 51])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 51, 51])
DEBUG: (input==padding).shape=torch.Size([32, 51])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 51])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 31]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 31, 31])
input shape: torch.Size([32, 31])
padding check shape: torch.Size([32, 31])
After unsqueeze shape: torch.Size([32, 1, 1, 31])
DEBUG: input.shape=torch.Size([32, 31])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 31, 31])
DEBUG: (input==padding).shape=torch.Size([32, 31])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 31])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
Epoch 0 - train:   5%|███▌                                                                  | 906/17710 [08:43<4:22:18,  1.07it/s, loss=9.28]Epoch 0 - train:   5%|███▌                                                                  | 913/17710 [08:49<4:09:37,  1.12it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:   5%|███▋                                                                  | 918/17710 [08:52<4:00:13,  1.17it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 922/17710 [08:55<3:53:43,  1.20it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 926/17710 [08:58<3:48:31,  1.22it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 929/17710 [09:02<4:05:55,  1.14it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
Epoch 0 - train:   5%|███▋                                                                  | 932/17710 [09:04<3:58:19,  1.17it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 934/17710 [09:05<3:52:41,  1.20it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 936/17710 [09:07<3:44:59,  1.24it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 938/17710 [09:08<3:39:05,  1.28it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 940/17710 [09:09<3:32:41,  1.31it/s, loss=9.28]Epoch 0 - train:   5%|███▋                                                                  | 940/17710 [09:10<3:32:41,  1.31it/s, loss=9.28]Epoch 0 - train:   6%|████                                                                    | 991/17710 [09:11<29:19,  9.50it/s, loss=9.28]padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 38]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 38, 38])
input shape: torch.Size([32, 38])
padding check shape: torch.Size([32, 38])
After unsqueeze shape: torch.Size([32, 1, 1, 38])
DEBUG: input.shape=torch.Size([32, 38])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 38, 38])
DEBUG: (input==padding).shape=torch.Size([32, 38])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 38])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
Epoch 0 - train:   6%|███▉                                                                 | 1003/17710 [09:19<1:07:53,  4.10it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 38]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 38, 38])
input shape: torch.Size([32, 38])
padding check shape: torch.Size([32, 38])
After unsqueeze shape: torch.Size([32, 1, 1, 38])
DEBUG: input.shape=torch.Size([32, 38])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 38, 38])
DEBUG: (input==padding).shape=torch.Size([32, 38])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 38])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
Epoch 0 - train:   6%|███▉                                                                 | 1012/17710 [09:26<1:32:26,  3.01it/s, loss=9.28]Epoch 0 - train:   6%|███▉                                                                 | 1019/17710 [09:31<1:51:43,  2.49it/s, loss=9.28]Epoch 0 - train:   6%|███▉                                                                 | 1024/17710 [09:34<2:04:51,  2.23it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 44]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 44, 44])
input shape: torch.Size([32, 44])
padding check shape: torch.Size([32, 44])
After unsqueeze shape: torch.Size([32, 1, 1, 44])
DEBUG: input.shape=torch.Size([32, 44])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 44, 44])
DEBUG: (input==padding).shape=torch.Size([32, 44])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 44])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
Epoch 0 - train:   6%|████                                                                 | 1028/17710 [09:37<2:16:02,  2.04it/s, loss=9.28]Epoch 0 - train:   6%|████                                                                 | 1032/17710 [09:40<2:25:31,  1.91it/s, loss=9.28]Epoch 0 - train:   6%|████                                                                 | 1035/17710 [09:42<2:32:52,  1.82it/s, loss=9.28]Epoch 0 - train:   6%|████                                                                 | 1038/17710 [09:44<2:39:43,  1.74it/s, loss=9.28]Epoch 0 - train:   6%|████                                                                 | 1039/17710 [09:45<2:39:42,  1.74it/s, loss=9.28]Epoch 0 - train:   6%|████▎                                                                  | 1089/17710 [09:45<35:18,  7.85it/s, loss=9.28]padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
Epoch 0 - train:   6%|████▎                                                                | 1102/17710 [09:54<1:10:50,  3.91it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 46]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 46, 46])
input shape: torch.Size([32, 46])
padding check shape: torch.Size([32, 46])
After unsqueeze shape: torch.Size([32, 1, 1, 46])
DEBUG: input.shape=torch.Size([32, 46])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 46, 46])
DEBUG: (input==padding).shape=torch.Size([32, 46])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 46])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:   6%|████▎                                                                | 1109/17710 [10:08<1:10:48,  3.91it/s, loss=9.28]Epoch 0 - train:   6%|████▎                                                                | 1110/17710 [10:09<2:26:30,  1.89it/s, loss=9.28]Epoch 0 - train:   6%|████▎                                                                | 1111/17710 [10:10<2:30:42,  1.84it/s, loss=9.28]Epoch 0 - train:   6%|████▎                                                                | 1118/17710 [10:16<2:43:25,  1.69it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
Epoch 0 - train:   6%|████▍                                                                | 1123/17710 [10:19<2:50:19,  1.62it/s, loss=9.28]Epoch 0 - train:   6%|████▍                                                                | 1127/17710 [10:22<2:55:26,  1.58it/s, loss=9.28]Epoch 0 - train:   6%|████▍                                                                | 1131/17710 [10:25<2:59:39,  1.54it/s, loss=9.28]Epoch 0 - train:   6%|████▍                                                                | 1134/17710 [10:27<3:03:32,  1.51it/s, loss=9.28]padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
Epoch 0 - train:   6%|████▍                                                                | 1137/17710 [10:29<3:05:08,  1.49it/s, loss=9.28]Epoch 0 - train:   6%|████▍                                                                | 1138/17710 [10:31<3:05:07,  1.49it/s, loss=9.28]Epoch 0 - train:   7%|████▊                                                                  | 1188/17710 [10:31<37:29,  7.34it/s, loss=9.28]Epoch 0 - train:   7%|████▋                                                                | 1201/17710 [10:40<1:13:45,  3.73it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:   7%|████▋                                                                | 1211/17710 [10:47<1:38:58,  2.78it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 32]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 32, 32])
input shape: torch.Size([32, 32])
Epoch 0 - train:   7%|████▋                                                                | 1218/17710 [10:52<1:55:34,  2.38it/s, loss=9.28]Epoch 0 - train:   7%|████▊                                                                | 1224/17710 [10:56<2:08:42,  2.13it/s, loss=9.28]Epoch 0 - train:   7%|████▊                                                                | 1229/17710 [11:02<2:40:26,  1.71it/s, loss=9.28]padding check shape: torch.Size([32, 32])
After unsqueeze shape: torch.Size([32, 1, 1, 32])
DEBUG: input.shape=torch.Size([32, 32])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 32, 32])
DEBUG: (input==padding).shape=torch.Size([32, 32])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 32])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
Epoch 0 - train:   7%|████▊                                                                | 1233/17710 [11:05<2:48:18,  1.63it/s, loss=9.28]Epoch 0 - train:   7%|████▊                                                                | 1236/17710 [11:07<2:51:41,  1.60it/s, loss=9.28]Epoch 0 - train:   7%|████▊                                                                | 1237/17710 [11:08<2:51:40,  1.60it/s, loss=9.28]Epoch 0 - train:   7%|█████▏                                                                 | 1287/17710 [11:08<43:12,  6.33it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 36]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 36, 36])
input shape: torch.Size([32, 36])
padding check shape: torch.Size([32, 36])
After unsqueeze shape: torch.Size([32, 1, 1, 36])
DEBUG: input.shape=torch.Size([32, 36])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 36, 36])
DEBUG: (input==padding).shape=torch.Size([32, 36])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 36])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
Epoch 0 - train:   7%|█████                                                                | 1300/17710 [11:18<1:17:34,  3.53it/s, loss=9.28]Epoch 0 - train:   7%|█████                                                                | 1310/17710 [11:25<1:41:46,  2.69it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
Epoch 0 - train:   7%|█████▏                                                               | 1317/17710 [11:30<1:56:34,  2.34it/s, loss=9.28]Epoch 0 - train:   7%|█████▏                                                               | 1323/17710 [11:34<2:08:02,  2.13it/s, loss=9.28]padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
Epoch 0 - train:   7%|█████▏                                                               | 1328/17710 [11:38<2:17:38,  1.98it/s, loss=9.28]Epoch 0 - train:   8%|█████▏                                                               | 1332/17710 [11:41<2:26:54,  1.86it/s, loss=9.28]Epoch 0 - train:   8%|█████▏                                                               | 1335/17710 [11:43<2:33:02,  1.78it/s, loss=9.28]Epoch 0 - train:   8%|█████▏                                                               | 1336/17710 [11:44<2:33:01,  1.78it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                                 | 1386/17710 [11:44<39:33,  6.88it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:   8%|█████▍                                                               | 1399/17710 [11:53<1:12:35,  3.75it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 33]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 33, 33])
input shape: torch.Size([32, 33])
padding check shape: torch.Size([32, 33])
After unsqueeze shape: torch.Size([32, 1, 1, 33])
DEBUG: input.shape=torch.Size([32, 33])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 33, 33])
DEBUG: (input==padding).shape=torch.Size([32, 33])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 33])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 49]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 49, 49])
input shape: torch.Size([32, 49])
padding check shape: torch.Size([32, 49])
After unsqueeze shape: torch.Size([32, 1, 1, 49])
DEBUG: input.shape=torch.Size([32, 49])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 49, 49])
DEBUG: (input==padding).shape=torch.Size([32, 49])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 49])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
Epoch 0 - train:   8%|█████▍                                                               | 1409/17710 [12:05<2:03:42,  2.20it/s, loss=9.28]Epoch 0 - train:   8%|█████▍                                                               | 1411/17710 [12:07<2:08:42,  2.11it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                               | 1418/17710 [12:12<2:22:21,  1.91it/s, loss=9.28]padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 49]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 49, 49])
input shape: torch.Size([32, 49])
padding check shape: torch.Size([32, 49])
After unsqueeze shape: torch.Size([32, 1, 1, 49])
DEBUG: input.shape=torch.Size([32, 49])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 49, 49])
DEBUG: (input==padding).shape=torch.Size([32, 49])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 49])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
Epoch 0 - train:   8%|█████▌                                                               | 1424/17710 [12:16<2:32:30,  1.78it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                               | 1428/17710 [12:19<2:39:24,  1.70it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                               | 1432/17710 [12:22<2:45:24,  1.64it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                               | 1435/17710 [12:24<2:48:36,  1.61it/s, loss=9.28]Epoch 0 - train:   8%|█████▌                                                               | 1435/17710 [12:25<2:48:36,  1.61it/s, loss=9.28]Epoch 0 - train:   8%|█████▉                                                                 | 1486/17710 [12:25<39:16,  6.89it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 35]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 35, 35])
input shape: torch.Size([32, 35])
padding check shape: torch.Size([32, 35])
After unsqueeze shape: torch.Size([32, 1, 1, 35])
DEBUG: input.shape=torch.Size([32, 35])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 35, 35])
DEBUG: (input==padding).shape=torch.Size([32, 35])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 35])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
Epoch 0 - train:   8%|█████▊                                                               | 1499/17710 [12:35<1:13:08,  3.69it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
Epoch 0 - train:   9%|█████▉                                                               | 1508/17710 [12:41<1:34:32,  2.86it/s, loss=9.28]Epoch 0 - train:   9%|█████▉                                                               | 1515/17710 [12:46<1:51:09,  2.43it/s, loss=9.28]padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 29]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 29, 29])
input shape: torch.Size([32, 29])
padding check shape: torch.Size([32, 29])
After unsqueeze shape: torch.Size([32, 1, 1, 29])
DEBUG: input.shape=torch.Size([32, 29])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 29, 29])
DEBUG: (input==padding).shape=torch.Size([32, 29])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 29])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 41]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 41, 41])
input shape: torch.Size([32, 41])
padding check shape: torch.Size([32, 41])
After unsqueeze shape: torch.Size([32, 1, 1, 41])
DEBUG: input.shape=torch.Size([32, 41])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 41, 41])
Epoch 0 - train:   9%|█████▉                                                               | 1521/17710 [12:50<2:04:13,  2.17it/s, loss=9.28]Epoch 0 - train:   9%|█████▉                                                               | 1525/17710 [12:53<2:12:38,  2.03it/s, loss=9.28]Epoch 0 - train:   9%|█████▉                                                               | 1529/17710 [12:56<2:21:41,  1.90it/s, loss=9.28]Epoch 0 - train:   9%|█████▉                                                               | 1532/17710 [12:58<2:28:39,  1.81it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 41])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 41])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
Epoch 0 - train:   9%|█████▉                                                               | 1534/17710 [13:00<2:28:37,  1.81it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                                | 1584/17710 [13:00<42:06,  6.38it/s, loss=9.28]Epoch 0 - train:   9%|██████▏                                                              | 1592/17710 [13:06<1:03:35,  4.22it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
Epoch 0 - train:   9%|██████▏                                                              | 1598/17710 [13:10<1:20:46,  3.32it/s, loss=9.28]Epoch 0 - train:   9%|██████▏                                                              | 1603/17710 [13:14<1:35:14,  2.82it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1607/17710 [13:16<1:47:36,  2.49it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1610/17710 [13:18<1:57:37,  2.28it/s, loss=9.28]padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 33]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 33, 33])
input shape: torch.Size([32, 33])
padding check shape: torch.Size([32, 33])
After unsqueeze shape: torch.Size([32, 1, 1, 33])
DEBUG: input.shape=torch.Size([32, 33])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 33, 33])
DEBUG: (input==padding).shape=torch.Size([32, 33])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 33])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
Epoch 0 - train:   9%|██████▎                                                              | 1613/17710 [13:20<2:07:59,  2.10it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1616/17710 [13:23<2:18:44,  1.93it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1618/17710 [13:24<2:27:17,  1.82it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1620/17710 [13:26<2:36:01,  1.72it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1622/17710 [13:27<2:43:38,  1.64it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1624/17710 [13:28<2:49:14,  1.58it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1626/17710 [13:30<2:53:37,  1.54it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
Epoch 0 - train:   9%|██████▎                                                              | 1628/17710 [13:31<2:57:22,  1.51it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1630/17710 [13:33<2:58:36,  1.50it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1632/17710 [13:34<3:00:11,  1.49it/s, loss=9.28]Epoch 0 - train:   9%|██████▎                                                              | 1633/17710 [13:35<3:00:10,  1.49it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                                | 1683/17710 [13:35<22:50, 11.70it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 38]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 38, 38])
input shape: torch.Size([32, 38])
padding check shape: torch.Size([32, 38])
After unsqueeze shape: torch.Size([32, 1, 1, 38])
DEBUG: input.shape=torch.Size([32, 38])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 38, 38])
DEBUG: (input==padding).shape=torch.Size([32, 38])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 38])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
Epoch 0 - train:  10%|██████▌                                                              | 1696/17710 [13:44<1:03:11,  4.22it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1705/17710 [13:51<1:26:59,  3.07it/s, loss=9.28]padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
Epoch 0 - train:  10%|██████▋                                                              | 1712/17710 [13:55<1:44:13,  2.56it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1718/17710 [14:00<1:59:27,  2.23it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1722/17710 [14:02<2:10:24,  2.04it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
Epoch 0 - train:  10%|██████▋                                                              | 1726/17710 [14:06<2:22:48,  1.87it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1729/17710 [14:08<2:30:43,  1.77it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1732/17710 [14:10<2:38:13,  1.68it/s, loss=9.28]Epoch 0 - train:  10%|██████▋                                                              | 1732/17710 [14:11<2:38:13,  1.68it/s, loss=9.28]Epoch 0 - train:  10%|███████▏                                                               | 1783/17710 [14:11<34:53,  7.61it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
Epoch 0 - train:  10%|██████▉                                                              | 1796/17710 [14:20<1:09:00,  3.84it/s, loss=9.28]padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
Epoch 0 - train:  10%|███████                                                              | 1806/17710 [14:27<1:32:31,  2.86it/s, loss=9.28]Epoch 0 - train:  10%|███████                                                              | 1813/17710 [14:32<1:47:30,  2.46it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 33]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 33, 33])
input shape: torch.Size([32, 33])
padding check shape: torch.Size([32, 33])
After unsqueeze shape: torch.Size([32, 1, 1, 33])
DEBUG: input.shape=torch.Size([32, 33])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 33, 33])
DEBUG: (input==padding).shape=torch.Size([32, 33])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 33])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 51]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 51, 51])
input shape: torch.Size([32, 51])
padding check shape: torch.Size([32, 51])
After unsqueeze shape: torch.Size([32, 1, 1, 51])
DEBUG: input.shape=torch.Size([32, 51])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 51, 51])
DEBUG: (input==padding).shape=torch.Size([32, 51])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 51])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
Epoch 0 - train:  10%|███████                                                              | 1819/17710 [14:36<2:00:32,  2.20it/s, loss=9.28]Epoch 0 - train:  10%|███████                                                              | 1824/17710 [14:40<2:11:31,  2.01it/s, loss=9.28]Epoch 0 - train:  10%|███████                                                              | 1828/17710 [14:43<2:20:30,  1.88it/s, loss=9.28]Epoch 0 - train:  10%|███████▏                                                             | 1831/17710 [14:45<2:27:39,  1.79it/s, loss=9.28]Epoch 0 - train:  10%|███████▏                                                             | 1831/17710 [14:45<2:27:39,  1.79it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
Epoch 0 - train:  11%|███████▌                                                               | 1882/17710 [14:46<37:51,  6.97it/s, loss=9.28]Epoch 0 - train:  11%|███████▍                                                             | 1895/17710 [14:55<1:09:49,  3.78it/s, loss=9.28]padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
Epoch 0 - train:  11%|███████▍                                                             | 1905/17710 [15:02<1:33:14,  2.83it/s, loss=9.28]Epoch 0 - train:  11%|███████▍                                                             | 1912/17710 [15:07<1:48:00,  2.44it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 14]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 14, 14])
input shape: torch.Size([32, 14])
padding check shape: torch.Size([32, 14])
After unsqueeze shape: torch.Size([32, 1, 1, 14])
DEBUG: input.shape=torch.Size([32, 14])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 14, 14])
DEBUG: (input==padding).shape=torch.Size([32, 14])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 14])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
Epoch 0 - train:  11%|███████▍                                                             | 1918/17710 [15:12<2:01:14,  2.17it/s, loss=9.28]Epoch 0 - train:  11%|███████▍                                                             | 1923/17710 [15:15<2:11:28,  2.00it/s, loss=9.28]Epoch 0 - train:  11%|███████▌                                                             | 1927/17710 [15:18<2:19:23,  1.89it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 27]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 27, 27])
input shape: torch.Size([32, 27])
padding check shape: torch.Size([32, 27])
After unsqueeze shape: torch.Size([32, 1, 1, 27])
DEBUG: input.shape=torch.Size([32, 27])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 27, 27])
DEBUG: (input==padding).shape=torch.Size([32, 27])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 27])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
Epoch 0 - train:  11%|███████▌                                                             | 1930/17710 [15:20<2:24:51,  1.82it/s, loss=9.28]Epoch 0 - train:  11%|███████▌                                                             | 1930/17710 [15:20<2:24:51,  1.82it/s, loss=9.28]Epoch 0 - train:  11%|███████▉                                                               | 1981/17710 [15:21<37:25,  7.00it/s, loss=9.28]padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
Epoch 0 - train:  11%|███████▊                                                             | 1994/17710 [15:30<1:09:16,  3.78it/s, loss=9.28]Epoch 0 - train:  11%|███████▊                                                             | 2004/17710 [15:37<1:32:19,  2.84it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 34]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 34, 34])
input shape: torch.Size([32, 34])
padding check shape: torch.Size([32, 34])
After unsqueeze shape: torch.Size([32, 1, 1, 34])
DEBUG: input.shape=torch.Size([32, 34])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 34, 34])
DEBUG: (input==padding).shape=torch.Size([32, 34])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 34])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
Epoch 0 - train:  11%|███████▊                                                             | 2011/17710 [15:42<1:47:53,  2.43it/s, loss=9.28]Epoch 0 - train:  11%|███████▊                                                             | 2017/17710 [15:47<2:00:27,  2.17it/s, loss=9.28]Epoch 0 - train:  11%|███████▉                                                             | 2022/17710 [15:50<2:10:40,  2.00it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 30]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 30, 30])
input shape: torch.Size([32, 30])
Epoch 0 - train:  11%|███████▉                                                             | 2026/17710 [15:53<2:18:32,  1.89it/s, loss=9.28]Epoch 0 - train:  11%|███████▉                                                             | 2029/17710 [15:55<2:24:50,  1.80it/s, loss=9.28]Epoch 0 - train:  11%|███████▉                                                             | 2029/17710 [15:56<2:24:50,  1.80it/s, loss=9.28]Epoch 0 - train:  12%|████████▎                                                              | 2080/17710 [15:56<37:14,  7.00it/s, loss=9.28]padding check shape: torch.Size([32, 30])
After unsqueeze shape: torch.Size([32, 1, 1, 30])
DEBUG: input.shape=torch.Size([32, 30])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 30, 30])
DEBUG: (input==padding).shape=torch.Size([32, 30])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 30])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
Epoch 0 - train:  12%|████████▏                                                            | 2093/17710 [16:05<1:09:18,  3.76it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
Epoch 0 - train:  12%|████████▏                                                            | 2103/17710 [16:12<1:30:38,  2.87it/s, loss=9.28]Epoch 0 - train:  12%|████████▏                                                            | 2111/17710 [16:18<1:47:00,  2.43it/s, loss=9.28]Epoch 0 - train:  12%|████████▏                                                            | 2117/17710 [16:22<1:58:39,  2.19it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
Epoch 0 - train:  12%|████████▎                                                            | 2122/17710 [16:25<2:09:05,  2.01it/s, loss=9.28]Epoch 0 - train:  12%|████████▎                                                            | 2126/17710 [16:28<2:16:38,  1.90it/s, loss=9.28]Epoch 0 - train:  12%|████████▎                                                            | 2128/17710 [16:30<2:16:37,  1.90it/s, loss=9.28]Epoch 0 - train:  12%|████████▋                                                              | 2178/17710 [16:30<42:30,  6.09it/s, loss=9.28]padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 28]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 28, 28])
input shape: torch.Size([32, 28])
padding check shape: torch.Size([32, 28])
After unsqueeze shape: torch.Size([32, 1, 1, 28])
DEBUG: input.shape=torch.Size([32, 28])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 28, 28])
DEBUG: (input==padding).shape=torch.Size([32, 28])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 28])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
Epoch 0 - train:  12%|████████▌                                                            | 2188/17710 [16:37<1:05:43,  3.94it/s, loss=9.28]Epoch 0 - train:  12%|████████▌                                                            | 2196/17710 [16:43<1:23:55,  3.08it/s, loss=9.28]DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 25]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 25, 25])
input shape: torch.Size([32, 25])
padding check shape: torch.Size([32, 25])
After unsqueeze shape: torch.Size([32, 1, 1, 25])
DEBUG: input.shape=torch.Size([32, 25])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 25, 25])
DEBUG: (input==padding).shape=torch.Size([32, 25])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 25])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 36]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 36, 36])
input shape: torch.Size([32, 36])
padding check shape: torch.Size([32, 36])
After unsqueeze shape: torch.Size([32, 1, 1, 36])
DEBUG: input.shape=torch.Size([32, 36])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 36, 36])
DEBUG: (input==padding).shape=torch.Size([32, 36])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 36])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 24]), seq.dtype=torch.int64
Epoch 0 - train:  12%|████████▌                                                            | 2202/17710 [16:47<1:38:10,  2.63it/s, loss=9.28]Epoch 0 - train:  12%|████████▌                                                            | 2207/17710 [16:50<1:50:24,  2.34it/s, loss=9.28]Epoch 0 - train:  12%|████████▌                                                            | 2211/17710 [16:53<2:00:25,  2.14it/s, loss=9.28]DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 24, 24])
input shape: torch.Size([32, 24])
padding check shape: torch.Size([32, 24])
After unsqueeze shape: torch.Size([32, 1, 1, 24])
DEBUG: input.shape=torch.Size([32, 24])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 24, 24])
DEBUG: (input==padding).shape=torch.Size([32, 24])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 24])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 26]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 26, 26])
input shape: torch.Size([32, 26])
padding check shape: torch.Size([32, 26])
After unsqueeze shape: torch.Size([32, 1, 1, 26])
DEBUG: input.shape=torch.Size([32, 26])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 26, 26])
DEBUG: (input==padding).shape=torch.Size([32, 26])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 26])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 23]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 23, 23])
input shape: torch.Size([32, 23])
padding check shape: torch.Size([32, 23])
After unsqueeze shape: torch.Size([32, 1, 1, 23])
DEBUG: input.shape=torch.Size([32, 23])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 23, 23])
DEBUG: (input==padding).shape=torch.Size([32, 23])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 23])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 22]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 22, 22])
input shape: torch.Size([32, 22])
padding check shape: torch.Size([32, 22])
After unsqueeze shape: torch.Size([32, 1, 1, 22])
DEBUG: input.shape=torch.Size([32, 22])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 22, 22])
DEBUG: (input==padding).shape=torch.Size([32, 22])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 22])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 20]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 20, 20])
input shape: torch.Size([32, 20])
padding check shape: torch.Size([32, 20])
After unsqueeze shape: torch.Size([32, 1, 1, 20])
DEBUG: input.shape=torch.Size([32, 20])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 20, 20])
DEBUG: (input==padding).shape=torch.Size([32, 20])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 20])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 19]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 19, 19])
input shape: torch.Size([32, 19])
padding check shape: torch.Size([32, 19])
After unsqueeze shape: torch.Size([32, 1, 1, 19])
DEBUG: input.shape=torch.Size([32, 19])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 19, 19])
DEBUG: (input==padding).shape=torch.Size([32, 19])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 19])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 15]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 15, 15])
input shape: torch.Size([32, 15])
padding check shape: torch.Size([32, 15])
After unsqueeze shape: torch.Size([32, 1, 1, 15])
DEBUG: input.shape=torch.Size([32, 15])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 15, 15])
DEBUG: (input==padding).shape=torch.Size([32, 15])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 15])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 17]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 17, 17])
input shape: torch.Size([32, 17])
padding check shape: torch.Size([32, 17])
After unsqueeze shape: torch.Size([32, 1, 1, 17])
DEBUG: input.shape=torch.Size([32, 17])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 17, 17])
DEBUG: (input==padding).shape=torch.Size([32, 17])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 17])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 16]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 16, 16])
input shape: torch.Size([32, 16])
padding check shape: torch.Size([32, 16])
After unsqueeze shape: torch.Size([32, 1, 1, 16])
DEBUG: input.shape=torch.Size([32, 16])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 16, 16])
DEBUG: (input==padding).shape=torch.Size([32, 16])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 16])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 21]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 21, 21])
input shape: torch.Size([32, 21])
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [324,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [325,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [326,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [327,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.
Epoch 0 - train:  12%|████████▌                                                            | 2213/17710 [16:55<1:58:32,  2.18it/s, loss=9.28]
padding check shape: torch.Size([32, 21])
After unsqueeze shape: torch.Size([32, 1, 1, 21])
DEBUG: input.shape=torch.Size([32, 21])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 21, 21])
DEBUG: (input==padding).shape=torch.Size([32, 21])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 21])
DEBUG Transformer.forward: seq.shape=torch.Size([32, 18]), seq.dtype=torch.int64
DEBUG Transformer.forward: enc_output.shape=torch.Size([32, 196, 512])
mask_self_attention shape: torch.Size([1, 1, 18, 18])
input shape: torch.Size([32, 18])
padding check shape: torch.Size([32, 18])
After unsqueeze shape: torch.Size([32, 1, 1, 18])
DEBUG: input.shape=torch.Size([32, 18])
DEBUG: mask_self_attention.shape=torch.Size([1, 1, 18, 18])
DEBUG: (input==padding).shape=torch.Size([32, 18])
DEBUG: after unsqueeze=torch.Size([32, 1, 1, 18])
Traceback (most recent call last):
  File "train_transformer.py", line 417, in <module>
    train_loss = train_xe(model, dataloader_train, optim, text_field, device, loss_contrast, e, beta=args.beta)
  File "train_transformer.py", line 161, in train_xe
    out = model(detections, captions)
  File "/root/miniconda3/envs/m2release/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/FSGR/models/fsgr/transformer.py", line 183, in forward
    dec_output = self.decoder(0, seq, enc_output, mask_enc, pos=grid_embed)
  File "/root/miniconda3/envs/m2release/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/FSGR/models/fsgr/decoders.py", line 150, in forward
    out = self.word_emb(input) + self.pos_emb(seq)
  File "/root/miniconda3/envs/m2release/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/m2release/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/root/miniconda3/envs/m2release/lib/python3.8/site-packages/torch/nn/functional.py", line 2210, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

使用设备: cuda
实验参数: exp_name=fsgr_fix, batch_size=32, xe_base_lr=0.0002
加载已有词汇表...
词汇表大小: 10201
===Missing keys: ['visual.prompt_embeddings', 'visual.deep_prompt_embeddings', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.bias', 'visual.prompt_proj.weight', 'visual.prompt_proj.bias', 'visual.prompt_norm.weight', 'visual.prompt_norm.bias', 'transformer.resblocks.0.S_Adapter.D_fc1.weight', 'transformer.resblocks.0.S_Adapter.D_fc1.bias', 'transformer.resblocks.0.S_Adapter.D_fc2.weight', 'transformer.resblocks.0.S_Adapter.D_fc2.bias', 'transformer.resblocks.1.S_Adapter.D_fc1.weight', 'transformer.resblocks.1.S_Adapter.D_fc1.bias', 'transformer.resblocks.1.S_Adapter.D_fc2.weight', 'transformer.resblocks.1.S_Adapter.D_fc2.bias', 'transformer.resblocks.2.S_Adapter.D_fc1.weight', 'transformer.resblocks.2.S_Adapter.D_fc1.bias', 'transformer.resblocks.2.S_Adapter.D_fc2.weight', 'transformer.resblocks.2.S_Adapter.D_fc2.bias', 'transformer.resblocks.3.S_Adapter.D_fc1.weight', 'transformer.resblocks.3.S_Adapter.D_fc1.bias', 'transformer.resblocks.3.S_Adapter.D_fc2.weight', 'transformer.resblocks.3.S_Adapter.D_fc2.bias', 'transformer.resblocks.4.S_Adapter.D_fc1.weight', 'transformer.resblocks.4.S_Adapter.D_fc1.bias', 'transformer.resblocks.4.S_Adapter.D_fc2.weight', 'transformer.resblocks.4.S_Adapter.D_fc2.bias', 'transformer.resblocks.5.S_Adapter.D_fc1.weight', 'transformer.resblocks.5.S_Adapter.D_fc1.bias', 'transformer.resblocks.5.S_Adapter.D_fc2.weight', 'transformer.resblocks.5.S_Adapter.D_fc2.bias', 'transformer.resblocks.6.S_Adapter.D_fc1.weight', 'transformer.resblocks.6.S_Adapter.D_fc1.bias', 'transformer.resblocks.6.S_Adapter.D_fc2.weight', 'transformer.resblocks.6.S_Adapter.D_fc2.bias', 'transformer.resblocks.7.S_Adapter.D_fc1.weight', 'transformer.resblocks.7.S_Adapter.D_fc1.bias', 'transformer.resblocks.7.S_Adapter.D_fc2.weight', 'transformer.resblocks.7.S_Adapter.D_fc2.bias', 'transformer.resblocks.8.S_Adapter.D_fc1.weight', 'transformer.resblocks.8.S_Adapter.D_fc1.bias', 'transformer.resblocks.8.S_Adapter.D_fc2.weight', 'transformer.resblocks.8.S_Adapter.D_fc2.bias', 'transformer.resblocks.9.S_Adapter.D_fc1.weight', 'transformer.resblocks.9.S_Adapter.D_fc1.bias', 'transformer.resblocks.9.S_Adapter.D_fc2.weight', 'transformer.resblocks.9.S_Adapter.D_fc2.bias', 'transformer.resblocks.10.S_Adapter.D_fc1.weight', 'transformer.resblocks.10.S_Adapter.D_fc1.bias', 'transformer.resblocks.10.S_Adapter.D_fc2.weight', 'transformer.resblocks.10.S_Adapter.D_fc2.bias', 'transformer.resblocks.11.S_Adapter.D_fc1.weight', 'transformer.resblocks.11.S_Adapter.D_fc1.bias', 'transformer.resblocks.11.S_Adapter.D_fc2.weight', 'transformer.resblocks.11.S_Adapter.D_fc2.bias']
===Unexpected keys: []
load pretrained weights!
开始训练...

===== Epoch 0 =====
Backbone lr = 0.025000, Dec lr = 0.250000
Epoch 0 - train:   0%|                                                                                               | 0/17710 [00:00<?, ?it/s]Epoch 0 - train:   0%|                                                                                    | 1/17710 [00:07<37:23:55,  7.60s/it]Epoch 0 - train:   0%|                                                                                     | 8/17710 [00:08<4:04:09,  1.21it/s]Epoch 0 - train:   0%|                                                                                    | 16/17710 [00:09<2:01:53,  2.42it/s]Epoch 0 - train:   0%|                                                                                    | 22/17710 [00:11<1:41:33,  2.90it/s]Epoch 0 - train:   0%|▏                                                                                   | 28/17710 [00:12<1:25:20,  3.45it/s]Epoch 0 - train:   0%|▏                                                                                   | 34/17710 [00:13<1:17:23,  3.81it/s]Epoch 0 - train:   0%|▏                                                                                   | 40/17710 [00:14<1:08:26,  4.30it/s]Epoch 0 - train:   0%|▏                                                                                   | 46/17710 [00:15<1:06:47,  4.41it/s]Epoch 0 - train:   0%|▏                                                                         | 49/17710 [00:16<1:06:46,  4.41it/s, loss=nan]Epoch 0 - train:   0%|▏                                                                           | 53/17710 [00:16<59:09,  4.97it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 59/17710 [00:18<59:50,  4.92it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 66/17710 [00:19<56:09,  5.24it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 73/17710 [00:20<52:37,  5.59it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 79/17710 [00:21<55:49,  5.26it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                         | 85/17710 [00:23<1:00:28,  4.86it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                           | 91/17710 [00:24<58:24,  5.03it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                           | 97/17710 [00:25<58:20,  5.03it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                           | 99/17710 [00:25<58:20,  5.03it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 103/17710 [00:26<57:22,  5.11it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 110/17710 [00:27<52:41,  5.57it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 118/17710 [00:28<49:49,  5.88it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 126/17710 [00:30<47:25,  6.18it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 134/17710 [00:31<45:27,  6.44it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 142/17710 [00:32<44:29,  6.58it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 149/17710 [00:33<44:28,  6.58it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 150/17710 [00:33<43:33,  6.72it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 158/17710 [00:34<42:48,  6.83it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 166/17710 [00:35<42:35,  6.86it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 173/17710 [00:36<42:22,  6.90it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 181/17710 [00:37<41:59,  6.96it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 188/17710 [00:38<42:22,  6.89it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 195/17710 [00:39<42:22,  6.89it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 199/17710 [00:40<42:21,  6.89it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 202/17710 [00:40<42:56,  6.79it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 209/17710 [00:42<42:50,  6.81it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 216/17710 [00:43<43:39,  6.68it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 223/17710 [00:44<44:42,  6.52it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 230/17710 [00:45<44:36,  6.53it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 237/17710 [00:47<55:19,  5.26it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 243/17710 [00:48<55:14,  5.27it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 249/17710 [00:49<54:17,  5.36it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 249/17710 [00:49<54:17,  5.36it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 256/17710 [00:50<50:23,  5.77it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 263/17710 [00:51<48:50,  5.95it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 270/17710 [00:52<48:00,  6.05it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 278/17710 [00:53<46:17,  6.28it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 286/17710 [00:54<44:40,  6.50it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 293/17710 [00:56<44:01,  6.59it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 299/17710 [00:57<44:00,  6.59it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 300/17710 [00:57<43:34,  6.66it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 307/17710 [00:58<43:13,  6.71it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 315/17710 [00:59<42:03,  6.89it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 323/17710 [01:00<40:54,  7.08it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 331/17710 [01:01<40:09,  7.21it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 339/17710 [01:02<39:35,  7.31it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 347/17710 [01:03<39:19,  7.36it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 349/17710 [01:03<39:18,  7.36it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 355/17710 [01:04<39:31,  7.32it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 363/17710 [01:05<39:44,  7.27it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 371/17710 [01:06<39:44,  7.27it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 379/17710 [01:07<39:06,  7.39it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 387/17710 [01:08<38:53,  7.42it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 395/17710 [01:09<38:58,  7.41it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 399/17710 [01:10<38:57,  7.41it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 403/17710 [01:11<39:35,  7.29it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 411/17710 [01:12<39:21,  7.33it/s, loss=nan]Epoch 0 - train:   2%|█▊                                                                         | 419/17710 [01:13<39:30,  7.29it/s, loss=nan]Epoch 0 - train:   2%|█▊                                                                         | 427/17710 [01:14<39:41,  7.26it/s, loss=nan]Epoch 0 - train:   2%|█▊                                                                         | 435/17710 [01:15<39:30,  7.29it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 443/17710 [01:16<38:56,  7.39it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 449/17710 [01:17<38:55,  7.39it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 451/17710 [01:17<38:57,  7.38it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 459/17710 [01:18<39:21,  7.30it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 467/17710 [01:19<39:58,  7.19it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 475/17710 [01:20<40:10,  7.15it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 483/17710 [01:22<39:22,  7.29it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 491/17710 [01:23<39:02,  7.35it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 499/17710 [01:24<38:33,  7.44it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 499/17710 [01:24<38:33,  7.44it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 507/17710 [01:25<38:13,  7.50it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 515/17710 [01:26<37:56,  7.55it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 523/17710 [01:27<37:41,  7.60it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 531/17710 [01:28<37:27,  7.64it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 539/17710 [01:29<37:30,  7.63it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 547/17710 [01:30<37:29,  7.63it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 549/17710 [01:30<37:28,  7.63it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 555/17710 [01:31<37:27,  7.63it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 563/17710 [01:32<37:32,  7.61it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 571/17710 [01:33<38:32,  7.41it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 579/17710 [01:34<38:52,  7.34it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 587/17710 [01:35<38:29,  7.41it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 595/17710 [01:36<38:14,  7.46it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 599/17710 [01:37<38:13,  7.46it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 603/17710 [01:37<38:17,  7.45it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 611/17710 [01:39<38:51,  7.33it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 619/17710 [01:40<38:52,  7.33it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 627/17710 [01:41<38:29,  7.40it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 635/17710 [01:42<38:11,  7.45it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 643/17710 [01:43<38:07,  7.46it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 649/17710 [01:44<38:06,  7.46it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 651/17710 [01:44<39:19,  7.23it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 659/17710 [01:45<42:18,  6.72it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 666/17710 [01:47<42:55,  6.62it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 674/17710 [01:48<41:56,  6.77it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 681/17710 [01:49<41:45,  6.80it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 689/17710 [01:50<40:17,  7.04it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 697/17710 [01:51<39:33,  7.17it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 699/17710 [01:51<39:33,  7.17it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 705/17710 [01:52<38:55,  7.28it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 713/17710 [01:53<38:50,  7.29it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 721/17710 [01:54<38:20,  7.38it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 729/17710 [01:55<38:44,  7.31it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 737/17710 [01:56<38:23,  7.37it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 745/17710 [01:57<37:56,  7.45it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 749/17710 [01:58<37:55,  7.45it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 753/17710 [01:58<37:52,  7.46it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 761/17710 [01:59<37:38,  7.50it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                       | 769/17710 [02:00<37:25,  7.55it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                       | 777/17710 [02:01<37:16,  7.57it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                       | 785/17710 [02:03<37:09,  7.59it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                       | 793/17710 [02:04<37:01,  7.62it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                       | 799/17710 [02:04<37:00,  7.62it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                       | 801/17710 [02:05<36:53,  7.64it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                       | 809/17710 [02:06<37:04,  7.60it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                       | 817/17710 [02:07<37:17,  7.55it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                       | 825/17710 [02:08<37:32,  7.50it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 833/17710 [02:09<37:36,  7.48it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 841/17710 [02:10<37:39,  7.47it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 849/17710 [02:11<38:04,  7.38it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 849/17710 [02:11<38:04,  7.38it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 857/17710 [02:12<37:54,  7.41it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 865/17710 [02:13<37:53,  7.41it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 873/17710 [02:14<37:35,  7.46it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 881/17710 [02:15<37:38,  7.45it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 889/17710 [02:16<37:23,  7.50it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 897/17710 [02:17<37:10,  7.54it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 899/17710 [02:18<37:10,  7.54it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 905/17710 [02:19<37:06,  7.55it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 913/17710 [02:20<37:09,  7.53it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 921/17710 [02:21<37:14,  7.52it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 929/17710 [02:22<37:27,  7.47it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 937/17710 [02:23<37:35,  7.44it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 945/17710 [02:24<37:34,  7.44it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 949/17710 [02:25<37:33,  7.44it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 953/17710 [02:25<37:36,  7.43it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 961/17710 [02:26<37:44,  7.40it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 969/17710 [02:27<37:47,  7.38it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 977/17710 [02:28<37:45,  7.38it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 985/17710 [02:29<37:30,  7.43it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 993/17710 [02:30<37:17,  7.47it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 999/17710 [02:31<37:17,  7.47it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                     | 1001/17710 [02:31<37:04,  7.51it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                     | 1009/17710 [02:32<36:58,  7.53it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                     | 1017/17710 [02:34<36:55,  7.53it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1025/17710 [02:35<36:57,  7.52it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1033/17710 [02:36<36:59,  7.51it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1041/17710 [02:37<37:31,  7.40it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1049/17710 [02:38<37:28,  7.41it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1049/17710 [02:38<37:28,  7.41it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1057/17710 [02:39<37:29,  7.40it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1065/17710 [02:40<37:23,  7.42it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1073/17710 [02:41<37:08,  7.47it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1081/17710 [02:42<37:25,  7.41it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1089/17710 [02:43<37:40,  7.35it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1097/17710 [02:44<37:21,  7.41it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1099/17710 [02:45<37:21,  7.41it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1105/17710 [02:46<41:55,  6.60it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1113/17710 [02:47<40:44,  6.79it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1120/17710 [02:48<41:30,  6.66it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1127/17710 [02:49<41:09,  6.72it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1135/17710 [02:50<39:42,  6.96it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1143/17710 [02:51<38:48,  7.11it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1149/17710 [02:52<38:47,  7.11it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1151/17710 [02:52<38:01,  7.26it/s, loss=nan]Epoch 0 - train:   7%|████▊                                                                     | 1159/17710 [02:53<37:39,  7.33it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1167/17710 [02:54<37:12,  7.41it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1175/17710 [02:55<36:50,  7.48it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1183/17710 [02:56<36:28,  7.55it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1191/17710 [02:58<36:20,  7.58it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1199/17710 [02:59<36:08,  7.61it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1199/17710 [02:59<36:08,  7.61it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1207/17710 [03:00<36:01,  7.64it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1215/17710 [03:01<35:52,  7.66it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1223/17710 [03:02<35:54,  7.65it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1231/17710 [03:03<36:02,  7.62it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1239/17710 [03:04<35:58,  7.63it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1247/17710 [03:05<36:06,  7.60it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1249/17710 [03:05<36:05,  7.60it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1255/17710 [03:06<36:47,  7.45it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1263/17710 [03:07<36:46,  7.45it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1271/17710 [03:08<36:48,  7.45it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1279/17710 [03:09<36:47,  7.44it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1287/17710 [03:10<36:57,  7.41it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1295/17710 [03:11<37:08,  7.37it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1299/17710 [03:12<37:08,  7.37it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1303/17710 [03:13<37:27,  7.30it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1311/17710 [03:14<37:32,  7.28it/s, loss=nan]Epoch 0 - train:   7%|█████▌                                                                    | 1319/17710 [03:15<37:19,  7.32it/s, loss=nan]Epoch 0 - train:   7%|█████▌                                                                    | 1327/17710 [03:16<37:17,  7.32it/s, loss=nan]Epoch 0 - train:   8%|█████▌                                                                    | 1335/17710 [03:17<36:58,  7.38it/s, loss=nan]Epoch 0 - train:   8%|█████▌                                                                    | 1343/17710 [03:18<36:39,  7.44it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1349/17710 [03:19<36:39,  7.44it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1351/17710 [03:19<36:37,  7.44it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1359/17710 [03:20<36:49,  7.40it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1367/17710 [03:21<36:41,  7.42it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1375/17710 [03:22<36:30,  7.46it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1383/17710 [03:23<36:45,  7.40it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1391/17710 [03:24<37:00,  7.35it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1399/17710 [03:26<37:13,  7.30it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1399/17710 [03:26<37:13,  7.30it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1407/17710 [03:27<37:37,  7.22it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1415/17710 [03:28<37:35,  7.23it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1423/17710 [03:29<37:22,  7.26it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1431/17710 [03:30<37:11,  7.29it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1439/17710 [03:31<36:54,  7.35it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1447/17710 [03:32<36:39,  7.40it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1449/17710 [03:32<36:38,  7.40it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1455/17710 [03:33<36:36,  7.40it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1463/17710 [03:34<36:22,  7.44it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1471/17710 [03:35<36:14,  7.47it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1479/17710 [03:36<36:27,  7.42it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1487/17710 [03:37<36:13,  7.46it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1495/17710 [03:38<36:05,  7.49it/s, loss=nan]Epoch 0 - train:   8%|██████▎                                                                   | 1499/17710 [03:39<36:05,  7.49it/s, loss=nan]Epoch 0 - train:   8%|██████▎                                                                   | 1503/17710 [03:40<36:15,  7.45it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                   | 1511/17710 [03:41<36:07,  7.47it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                   | 1519/17710 [03:42<36:04,  7.48it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1527/17710 [03:43<35:55,  7.51it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1535/17710 [03:44<35:51,  7.52it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1543/17710 [03:45<35:52,  7.51it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1549/17710 [03:46<35:51,  7.51it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1551/17710 [03:46<38:31,  6.99it/s, loss=nan]Epoch 0 - train:   9%|██████▌                                                                   | 1559/17710 [03:47<37:41,  7.14it/s, loss=nan]Epoch 0 - train:   9%|██████▌                                                                   | 1567/17710 [03:48<37:05,  7.25it/s, loss=nan]Epoch 0 - train:   9%|██████▌                                                                   | 1575/17710 [03:49<36:32,  7.36it/s, loss=nan]Epoch 0 - train:   9%|██████▌                                                                   | 1583/17710 [03:50<36:26,  7.37it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1591/17710 [03:52<36:11,  7.42it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1599/17710 [03:53<35:45,  7.51it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1599/17710 [03:53<35:45,  7.51it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1607/17710 [03:54<35:32,  7.55it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1615/17710 [03:55<35:30,  7.55it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1623/17710 [03:56<35:22,  7.58it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1631/17710 [03:57<35:23,  7.57it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1639/17710 [03:58<35:16,  7.59it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1647/17710 [03:59<35:20,  7.58it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1649/17710 [03:59<35:20,  7.58it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1655/17710 [04:00<35:45,  7.48it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1663/17710 [04:01<35:31,  7.53it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1671/17710 [04:02<35:31,  7.52it/s, loss=nan]Epoch 0 - train:   9%|███████                                                                   | 1679/17710 [04:03<35:26,  7.54it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1687/17710 [04:04<35:34,  7.51it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1695/17710 [04:05<35:34,  7.50it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1699/17710 [04:06<35:33,  7.50it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1703/17710 [04:06<35:28,  7.52it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1711/17710 [04:07<35:34,  7.50it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1719/17710 [04:08<35:26,  7.52it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1727/17710 [04:10<35:31,  7.50it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1735/17710 [04:11<35:38,  7.47it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1743/17710 [04:12<35:57,  7.40it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1749/17710 [04:13<35:56,  7.40it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1751/17710 [04:13<36:12,  7.35it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1759/17710 [04:14<36:18,  7.32it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1767/17710 [04:15<36:06,  7.36it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1775/17710 [04:16<36:03,  7.37it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1783/17710 [04:17<36:26,  7.28it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1791/17710 [04:18<36:05,  7.35it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1799/17710 [04:19<36:18,  7.30it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1799/17710 [04:20<36:18,  7.30it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1807/17710 [04:20<35:59,  7.37it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1815/17710 [04:22<35:41,  7.42it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1823/17710 [04:23<35:48,  7.39it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1831/17710 [04:24<35:58,  7.36it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1839/17710 [04:25<35:51,  7.38it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1847/17710 [04:26<35:50,  7.38it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1849/17710 [04:26<35:50,  7.38it/s, loss=nan]Epoch 0 - train:  10%|███████▊                                                                  | 1855/17710 [04:27<35:40,  7.41it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1863/17710 [04:28<35:34,  7.42it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1871/17710 [04:29<35:33,  7.43it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1879/17710 [04:30<35:31,  7.43it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1887/17710 [04:31<35:22,  7.46it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1895/17710 [04:32<35:12,  7.49it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1899/17710 [04:33<35:11,  7.49it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1903/17710 [04:33<35:18,  7.46it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1911/17710 [04:34<35:07,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1919/17710 [04:36<35:05,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1927/17710 [04:37<35:05,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1935/17710 [04:38<34:56,  7.53it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1943/17710 [04:39<35:02,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1949/17710 [04:40<35:01,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1951/17710 [04:40<35:23,  7.42it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1959/17710 [04:41<34:59,  7.50it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1967/17710 [04:42<34:42,  7.56it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1975/17710 [04:43<34:52,  7.52it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1983/17710 [04:44<35:12,  7.45it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1991/17710 [04:45<37:01,  7.08it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1999/17710 [04:47<38:43,  6.76it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1999/17710 [04:47<38:43,  6.76it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2007/17710 [04:48<37:33,  6.97it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2015/17710 [04:49<36:51,  7.10it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2023/17710 [04:50<36:13,  7.22it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2031/17710 [04:51<35:44,  7.31it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2039/17710 [04:52<35:25,  7.37it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2047/17710 [04:53<35:06,  7.44it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2049/17710 [04:53<35:05,  7.44it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2055/17710 [04:54<34:57,  7.46it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2063/17710 [04:55<34:46,  7.50it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2071/17710 [04:56<34:39,  7.52it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2079/17710 [04:57<34:29,  7.55it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2087/17710 [04:58<34:26,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2095/17710 [04:59<34:23,  7.57it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2099/17710 [05:00<34:22,  7.57it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2103/17710 [05:00<34:26,  7.55it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2111/17710 [05:01<34:27,  7.54it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2119/17710 [05:03<34:28,  7.54it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2127/17710 [05:04<34:45,  7.47it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2135/17710 [05:05<34:53,  7.44it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2143/17710 [05:06<35:11,  7.37it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2149/17710 [05:07<35:10,  7.37it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2151/17710 [05:07<35:09,  7.38it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2159/17710 [05:08<35:19,  7.34it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2167/17710 [05:09<35:24,  7.32it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2175/17710 [05:10<35:07,  7.37it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2183/17710 [05:11<34:57,  7.40it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2191/17710 [05:12<34:56,  7.40it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2199/17710 [05:13<34:50,  7.42it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2199/17710 [05:14<34:50,  7.42it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2207/17710 [05:15<35:03,  7.37it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2215/17710 [05:16<34:58,  7.38it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2223/17710 [05:17<35:06,  7.35it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2231/17710 [05:18<35:15,  7.32it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2239/17710 [05:19<35:06,  7.34it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2247/17710 [05:20<34:58,  7.37it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2249/17710 [05:20<34:57,  7.37it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2255/17710 [05:21<34:53,  7.38it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2263/17710 [05:22<35:06,  7.33it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2271/17710 [05:23<35:23,  7.27it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2279/17710 [05:24<35:31,  7.24it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2287/17710 [05:25<35:31,  7.24it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2295/17710 [05:27<35:28,  7.24it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2299/17710 [05:27<35:27,  7.24it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2303/17710 [05:28<35:35,  7.21it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2311/17710 [05:29<35:21,  7.26it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2319/17710 [05:30<35:12,  7.29it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2327/17710 [05:31<35:20,  7.25it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2335/17710 [05:32<35:10,  7.28it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2343/17710 [05:33<35:00,  7.32it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2349/17710 [05:34<34:59,  7.32it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2351/17710 [05:34<34:58,  7.32it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2359/17710 [05:35<34:59,  7.31it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2367/17710 [05:36<34:58,  7.31it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2375/17710 [05:38<34:50,  7.34it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2383/17710 [05:39<34:46,  7.35it/s, loss=nan]Epoch 0 - train:  14%|█████████▉                                                                | 2391/17710 [05:40<34:38,  7.37it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2399/17710 [05:41<34:58,  7.30it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2399/17710 [05:41<34:58,  7.30it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2407/17710 [05:42<34:53,  7.31it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2415/17710 [05:43<34:51,  7.31it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2423/17710 [05:44<34:42,  7.34it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2431/17710 [05:46<41:45,  6.10it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2438/17710 [05:47<40:49,  6.24it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2446/17710 [05:48<38:53,  6.54it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2449/17710 [05:49<38:52,  6.54it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2454/17710 [05:49<37:37,  6.76it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2462/17710 [05:50<36:43,  6.92it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2470/17710 [05:51<35:59,  7.06it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2478/17710 [05:52<35:48,  7.09it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2486/17710 [05:53<35:06,  7.23it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2494/17710 [05:55<34:53,  7.27it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2499/17710 [05:55<34:52,  7.27it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2502/17710 [05:56<34:48,  7.28it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2510/17710 [05:57<34:32,  7.33it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2518/17710 [05:58<34:27,  7.35it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2526/17710 [05:59<34:27,  7.35it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2534/17710 [06:00<34:40,  7.30it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2542/17710 [06:01<34:35,  7.31it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2549/17710 [06:02<34:34,  7.31it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2550/17710 [06:02<34:25,  7.34it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2558/17710 [06:03<34:33,  7.31it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2566/17710 [06:04<34:15,  7.37it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2574/17710 [06:05<34:16,  7.36it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2582/17710 [06:07<34:18,  7.35it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2590/17710 [06:08<34:14,  7.36it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2598/17710 [06:09<34:12,  7.36it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2599/17710 [06:09<34:12,  7.36it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2606/17710 [06:10<34:17,  7.34it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2614/17710 [06:11<34:26,  7.30it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2622/17710 [06:12<34:17,  7.33it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2630/17710 [06:13<34:11,  7.35it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2638/17710 [06:14<34:27,  7.29it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2646/17710 [06:15<34:22,  7.30it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2649/17710 [06:16<34:21,  7.30it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2654/17710 [06:16<34:28,  7.28it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2662/17710 [06:18<34:27,  7.28it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2670/17710 [06:19<34:18,  7.31it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2678/17710 [06:20<34:23,  7.29it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2686/17710 [06:21<34:19,  7.29it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2694/17710 [06:22<35:02,  7.14it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2699/17710 [06:23<35:02,  7.14it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2702/17710 [06:23<34:48,  7.18it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2710/17710 [06:24<34:39,  7.21it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2718/17710 [06:25<35:11,  7.10it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2726/17710 [06:26<35:16,  7.08it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2734/17710 [06:28<35:30,  7.03it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2742/17710 [06:29<35:03,  7.12it/s, loss=nan]Epoch 0 - train:  16%|███████████▍                                                              | 2749/17710 [06:30<35:02,  7.12it/s, loss=nan]Epoch 0 - train:  16%|███████████▍                                                              | 2750/17710 [06:30<35:03,  7.11it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2758/17710 [06:31<35:01,  7.12it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2766/17710 [06:32<34:57,  7.12it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2774/17710 [06:33<35:06,  7.09it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2782/17710 [06:35<37:09,  6.69it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2789/17710 [06:36<36:45,  6.77it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2797/17710 [06:37<35:56,  6.91it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2799/17710 [06:37<35:56,  6.91it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2805/17710 [06:38<35:23,  7.02it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2813/17710 [06:39<35:01,  7.09it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2821/17710 [06:40<34:33,  7.18it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2829/17710 [06:41<34:12,  7.25it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2837/17710 [06:42<34:01,  7.28it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2845/17710 [06:43<33:46,  7.34it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2849/17710 [06:44<33:45,  7.34it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2853/17710 [06:44<33:26,  7.41it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2861/17710 [06:46<35:32,  6.96it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2869/17710 [06:47<35:16,  7.01it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2877/17710 [06:48<34:49,  7.10it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2885/17710 [06:49<34:20,  7.20it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2893/17710 [06:50<34:22,  7.19it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2899/17710 [06:51<34:21,  7.19it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2901/17710 [06:51<34:24,  7.17it/s, loss=nan]Epoch 0 - train:  16%|████████████▏                                                             | 2909/17710 [06:52<34:11,  7.22it/s, loss=nan]Epoch 0 - train:  16%|████████████▏                                                             | 2917/17710 [06:53<34:01,  7.25it/s, loss=nan]Epoch 0 - train:  17%|████████████▏                                                             | 2925/17710 [06:54<33:58,  7.25it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2933/17710 [06:55<33:53,  7.27it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2941/17710 [06:57<33:58,  7.25it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2949/17710 [06:58<33:56,  7.25it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2949/17710 [06:58<33:56,  7.25it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2957/17710 [06:59<33:40,  7.30it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2965/17710 [07:00<33:51,  7.26it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2973/17710 [07:01<33:39,  7.30it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2981/17710 [07:02<33:45,  7.27it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2989/17710 [07:03<33:45,  7.27it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 2997/17710 [07:04<33:56,  7.22it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 2999/17710 [07:05<33:56,  7.22it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3005/17710 [07:05<33:57,  7.22it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3013/17710 [07:07<33:57,  7.21it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3021/17710 [07:08<33:36,  7.28it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3029/17710 [07:09<33:16,  7.35it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3037/17710 [07:10<33:06,  7.39it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3045/17710 [07:11<33:02,  7.40it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3049/17710 [07:11<33:01,  7.40it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3053/17710 [07:12<32:50,  7.44it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3061/17710 [07:13<32:44,  7.46it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3069/17710 [07:14<32:36,  7.48it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3077/17710 [07:15<32:35,  7.48it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3085/17710 [07:16<32:40,  7.46it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3093/17710 [07:17<32:32,  7.49it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3099/17710 [07:18<32:31,  7.49it/s, loss=nan]Epoch 0 - train:  18%|████████████▉                                                             | 3101/17710 [07:18<32:32,  7.48it/s, loss=nan]Epoch 0 - train:  18%|████████████▉                                                             | 3109/17710 [07:19<32:43,  7.43it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3117/17710 [07:20<32:52,  7.40it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3125/17710 [07:22<32:51,  7.40it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3133/17710 [07:23<33:01,  7.36it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3141/17710 [07:24<33:04,  7.34it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3149/17710 [07:25<33:08,  7.32it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3149/17710 [07:25<33:08,  7.32it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3157/17710 [07:26<33:06,  7.33it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3165/17710 [07:27<33:01,  7.34it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3173/17710 [07:28<32:55,  7.36it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3181/17710 [07:29<33:02,  7.33it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3189/17710 [07:30<32:51,  7.37it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3197/17710 [07:31<32:37,  7.41it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3199/17710 [07:32<32:37,  7.41it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3205/17710 [07:32<32:52,  7.35it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3213/17710 [07:34<32:40,  7.39it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3221/17710 [07:35<32:34,  7.41it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3229/17710 [07:36<32:12,  7.49it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3237/17710 [07:37<32:09,  7.50it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3245/17710 [07:38<32:03,  7.52it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3249/17710 [07:38<32:02,  7.52it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3253/17710 [07:39<31:53,  7.56it/s, loss=nan]Epoch 0 - train:  18%|█████████████▋                                                            | 3261/17710 [07:40<31:47,  7.58it/s, loss=nan]Epoch 0 - train:  18%|█████████████▋                                                            | 3269/17710 [07:41<31:44,  7.58it/s, loss=nan]Epoch 0 - train:  19%|█████████████▋                                                            | 3277/17710 [07:42<31:47,  7.57it/s, loss=nan]Epoch 0 - train:  19%|█████████████▋                                                            | 3285/17710 [07:43<31:55,  7.53it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3293/17710 [07:44<31:46,  7.56it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3299/17710 [07:45<31:45,  7.56it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3301/17710 [07:45<31:56,  7.52it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3309/17710 [07:46<32:09,  7.46it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3317/17710 [07:47<31:54,  7.52it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3325/17710 [07:48<32:02,  7.48it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3333/17710 [07:49<32:17,  7.42it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3341/17710 [07:51<32:11,  7.44it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3349/17710 [07:52<32:12,  7.43it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3349/17710 [07:52<32:12,  7.43it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3357/17710 [07:53<32:16,  7.41it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3365/17710 [07:54<32:16,  7.41it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3373/17710 [07:55<32:08,  7.44it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3381/17710 [07:56<32:17,  7.40it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3389/17710 [07:57<32:09,  7.42it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3397/17710 [07:58<32:04,  7.44it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3399/17710 [07:59<32:04,  7.44it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3405/17710 [07:59<32:13,  7.40it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3413/17710 [08:00<32:01,  7.44it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3421/17710 [08:01<31:50,  7.48it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3429/17710 [08:02<31:39,  7.52it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3437/17710 [08:03<31:31,  7.54it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3445/17710 [08:04<31:30,  7.55it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3449/17710 [08:05<31:29,  7.55it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3453/17710 [08:06<31:50,  7.46it/s, loss=nan]Epoch 0 - train:  20%|██████████████▍                                                           | 3461/17710 [08:07<32:11,  7.38it/s, loss=nan]Epoch 0 - train:  20%|██████████████▍                                                           | 3469/17710 [08:08<32:44,  7.25it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3477/17710 [08:09<32:48,  7.23it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3485/17710 [08:10<32:32,  7.29it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3493/17710 [08:11<32:22,  7.32it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3499/17710 [08:12<32:21,  7.32it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3501/17710 [08:12<32:33,  7.27it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3509/17710 [08:13<32:28,  7.29it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3517/17710 [08:14<32:29,  7.28it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3525/17710 [08:16<32:46,  7.21it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3533/17710 [08:17<32:57,  7.17it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3541/17710 [08:18<32:44,  7.21it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3549/17710 [08:19<32:54,  7.17it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3549/17710 [08:19<32:54,  7.17it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3557/17710 [08:20<32:46,  7.20it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3565/17710 [08:21<32:46,  7.19it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3573/17710 [08:22<32:30,  7.25it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3581/17710 [08:23<32:20,  7.28it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3589/17710 [08:24<32:11,  7.31it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3597/17710 [08:25<32:03,  7.34it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3599/17710 [08:26<32:03,  7.34it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3605/17710 [08:27<32:02,  7.34it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3613/17710 [08:28<32:18,  7.27it/s, loss=nan]Epoch 0 - train:  20%|███████████████▏                                                          | 3621/17710 [08:29<32:10,  7.30it/s, loss=nan]Epoch 0 - train:  20%|███████████████▏                                                          | 3629/17710 [08:30<32:05,  7.31it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3637/17710 [08:31<32:04,  7.31it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3645/17710 [08:32<32:03,  7.31it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3649/17710 [08:33<32:02,  7.31it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3653/17710 [08:33<32:07,  7.29it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3661/17710 [08:34<32:04,  7.30it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3669/17710 [08:35<32:13,  7.26it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3677/17710 [08:36<32:12,  7.26it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3685/17710 [08:38<32:05,  7.28it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3693/17710 [08:39<32:13,  7.25it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3699/17710 [08:40<32:12,  7.25it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3701/17710 [08:40<32:49,  7.11it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3709/17710 [08:41<33:01,  7.07it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3717/17710 [08:42<32:50,  7.10it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3725/17710 [08:43<32:37,  7.14it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3733/17710 [08:44<32:52,  7.09it/s, loss=nan]Epoch 0 - train:  21%|███████████████▋                                                          | 3741/17710 [08:46<35:49,  6.50it/s, loss=nan]Epoch 0 - train:  21%|███████████████▋                                                          | 3748/17710 [08:47<35:39,  6.53it/s, loss=nan]Epoch 0 - train:  21%|███████████████▋                                                          | 3749/17710 [08:47<35:39,  6.53it/s, loss=nan]Epoch 0 - train:  21%|███████████████▋                                                          | 3756/17710 [08:48<34:39,  6.71it/s, loss=nan]Epoch 0 - train:  21%|███████████████▋                                                          | 3764/17710 [08:49<34:00,  6.83it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3772/17710 [08:50<33:22,  6.96it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3780/17710 [08:51<32:45,  7.09it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3788/17710 [08:52<32:33,  7.13it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3796/17710 [08:54<32:36,  7.11it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3799/17710 [08:54<32:35,  7.11it/s, loss=nan]Epoch 0 - train:  21%|███████████████▉                                                          | 3804/17710 [08:55<32:31,  7.13it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3812/17710 [08:56<32:27,  7.14it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3820/17710 [08:57<32:21,  7.15it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3828/17710 [08:58<32:24,  7.14it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3836/17710 [08:59<32:12,  7.18it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3844/17710 [09:00<32:10,  7.18it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3849/17710 [09:01<32:09,  7.18it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3852/17710 [09:01<32:18,  7.15it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3860/17710 [09:02<31:58,  7.22it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3868/17710 [09:04<31:43,  7.27it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3876/17710 [09:05<31:26,  7.33it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3884/17710 [09:06<31:17,  7.36it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3892/17710 [09:07<31:07,  7.40it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3899/17710 [09:08<31:06,  7.40it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3900/17710 [09:08<31:15,  7.37it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3908/17710 [09:09<31:18,  7.35it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3916/17710 [09:10<31:01,  7.41it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3924/17710 [09:11<30:53,  7.44it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3932/17710 [09:12<30:52,  7.44it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3940/17710 [09:13<30:57,  7.41it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3948/17710 [09:14<30:46,  7.45it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3949/17710 [09:15<30:46,  7.45it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3956/17710 [09:15<30:41,  7.47it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3964/17710 [09:16<30:37,  7.48it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3972/17710 [09:17<30:42,  7.46it/s, loss=nan]Epoch 0 - train:  22%|████████████████▋                                                         | 3980/17710 [09:19<30:43,  7.45it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3988/17710 [09:20<30:38,  7.46it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3996/17710 [09:21<30:38,  7.46it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3999/17710 [09:21<30:37,  7.46it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 4004/17710 [09:22<30:45,  7.42it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4012/17710 [09:23<30:41,  7.44it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4020/17710 [09:24<30:40,  7.44it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4028/17710 [09:25<30:47,  7.41it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4036/17710 [09:26<30:51,  7.39it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4044/17710 [09:27<30:52,  7.38it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4049/17710 [09:28<30:52,  7.38it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4052/17710 [09:28<31:02,  7.33it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4060/17710 [09:29<30:55,  7.36it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4068/17710 [09:30<30:49,  7.38it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4076/17710 [09:32<30:43,  7.40it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4084/17710 [09:33<30:33,  7.43it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4092/17710 [09:34<30:20,  7.48it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4099/17710 [09:35<30:19,  7.48it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4100/17710 [09:35<30:10,  7.52it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4108/17710 [09:36<30:10,  7.51it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4116/17710 [09:37<30:07,  7.52it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4124/17710 [09:38<30:10,  7.50it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4132/17710 [09:39<30:04,  7.53it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4140/17710 [09:40<29:54,  7.56it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4148/17710 [09:41<29:52,  7.57it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4149/17710 [09:41<29:52,  7.57it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4156/17710 [09:42<29:48,  7.58it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4164/17710 [09:43<29:50,  7.57it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4172/17710 [09:44<29:43,  7.59it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4180/17710 [09:45<30:26,  7.41it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4188/17710 [09:46<30:19,  7.43it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4196/17710 [09:48<30:15,  7.44it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4199/17710 [09:48<30:15,  7.44it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4204/17710 [09:49<30:09,  7.46it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4212/17710 [09:50<29:58,  7.50it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4220/17710 [09:51<29:50,  7.54it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4228/17710 [09:52<29:47,  7.54it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4236/17710 [09:53<29:44,  7.55it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4244/17710 [09:54<29:38,  7.57it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4249/17710 [09:55<29:37,  7.57it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4252/17710 [09:55<29:40,  7.56it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4260/17710 [09:56<29:37,  7.57it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4268/17710 [09:57<29:33,  7.58it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4276/17710 [09:58<29:28,  7.60it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4284/17710 [09:59<29:26,  7.60it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4292/17710 [10:00<29:23,  7.61it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4299/17710 [10:01<29:22,  7.61it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4300/17710 [10:01<29:16,  7.64it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4308/17710 [10:02<29:10,  7.65it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4316/17710 [10:03<29:06,  7.67it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4324/17710 [10:04<29:05,  7.67it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4332/17710 [10:05<29:12,  7.63it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4340/17710 [10:06<29:08,  7.65it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4348/17710 [10:07<29:04,  7.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4349/17710 [10:08<29:04,  7.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4356/17710 [10:09<29:03,  7.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4364/17710 [10:10<29:00,  7.67it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4372/17710 [10:11<29:13,  7.61it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4380/17710 [10:12<29:07,  7.63it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4388/17710 [10:13<29:03,  7.64it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4396/17710 [10:14<28:59,  7.65it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4399/17710 [10:14<28:59,  7.65it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4404/17710 [10:15<29:03,  7.63it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4412/17710 [10:16<29:00,  7.64it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4420/17710 [10:17<29:02,  7.63it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4428/17710 [10:18<28:56,  7.65it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4436/17710 [10:19<28:59,  7.63it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4444/17710 [10:20<29:04,  7.61it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4449/17710 [10:21<29:03,  7.61it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4452/17710 [10:21<29:06,  7.59it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4460/17710 [10:22<29:03,  7.60it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4468/17710 [10:23<29:02,  7.60it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4476/17710 [10:24<29:06,  7.58it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4484/17710 [10:25<28:55,  7.62it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4492/17710 [10:26<28:44,  7.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4499/17710 [10:27<28:44,  7.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4500/17710 [10:27<28:38,  7.69it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4508/17710 [10:28<28:30,  7.72it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4516/17710 [10:29<28:27,  7.73it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4524/17710 [10:30<28:22,  7.74it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4532/17710 [10:32<28:31,  7.70it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4540/17710 [10:33<28:26,  7.72it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4548/17710 [10:34<28:26,  7.71it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4549/17710 [10:34<28:26,  7.71it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4556/17710 [10:35<28:26,  7.71it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4564/17710 [10:36<28:26,  7.70it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4572/17710 [10:37<28:35,  7.66it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4580/17710 [10:38<28:30,  7.67it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4588/17710 [10:39<28:26,  7.69it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4596/17710 [10:40<28:25,  7.69it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4599/17710 [10:40<28:24,  7.69it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4604/17710 [10:41<28:20,  7.71it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4612/17710 [10:42<28:19,  7.71it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4620/17710 [10:43<28:12,  7.73it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4628/17710 [10:44<28:11,  7.73it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4636/17710 [10:45<28:12,  7.72it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4644/17710 [10:47<34:37,  6.29it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4649/17710 [10:48<34:36,  6.29it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4651/17710 [10:48<37:36,  5.79it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4658/17710 [10:50<39:31,  5.50it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4665/17710 [10:51<37:44,  5.76it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4672/17710 [10:52<35:56,  6.05it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4679/17710 [10:53<34:38,  6.27it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4687/17710 [10:54<32:29,  6.68it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▌                                                      | 4695/17710 [10:55<31:08,  6.97it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4699/17710 [10:56<31:07,  6.97it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4703/17710 [10:56<30:13,  7.17it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4711/17710 [10:57<29:35,  7.32it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4719/17710 [10:58<29:07,  7.43it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4727/17710 [10:59<28:51,  7.50it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4735/17710 [11:00<28:34,  7.57it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4743/17710 [11:01<28:23,  7.61it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4749/17710 [11:02<28:22,  7.61it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4751/17710 [11:02<28:17,  7.63it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4759/17710 [11:03<28:17,  7.63it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4767/17710 [11:04<28:31,  7.56it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4775/17710 [11:05<28:20,  7.61it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4783/17710 [11:06<28:12,  7.64it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4791/17710 [11:07<28:25,  7.57it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4799/17710 [11:09<28:25,  7.57it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4799/17710 [11:09<28:25,  7.57it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4807/17710 [11:10<28:19,  7.59it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4815/17710 [11:11<28:09,  7.63it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4823/17710 [11:12<28:01,  7.67it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4831/17710 [11:13<27:54,  7.69it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4839/17710 [11:14<27:50,  7.71it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4847/17710 [11:15<27:48,  7.71it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4849/17710 [11:15<27:48,  7.71it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4855/17710 [11:16<28:00,  7.65it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4863/17710 [11:17<28:38,  7.47it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▎                                                     | 4871/17710 [11:18<28:19,  7.56it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4879/17710 [11:19<28:07,  7.61it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4887/17710 [11:20<28:01,  7.63it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4895/17710 [11:21<27:58,  7.63it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4899/17710 [11:22<27:58,  7.63it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4903/17710 [11:22<28:08,  7.59it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4911/17710 [11:23<27:57,  7.63it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4919/17710 [11:24<27:50,  7.66it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4927/17710 [11:25<27:47,  7.67it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4935/17710 [11:26<27:53,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4943/17710 [11:27<27:50,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4949/17710 [11:28<27:49,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4951/17710 [11:28<27:42,  7.68it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4959/17710 [11:29<27:37,  7.69it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4967/17710 [11:30<27:39,  7.68it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4975/17710 [11:32<27:36,  7.69it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4983/17710 [11:33<27:44,  7.65it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4991/17710 [11:34<27:39,  7.66it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 4999/17710 [11:35<27:44,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 4999/17710 [11:35<27:44,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5007/17710 [11:36<27:39,  7.66it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5015/17710 [11:37<27:42,  7.64it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5023/17710 [11:38<27:44,  7.62it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5031/17710 [11:39<27:40,  7.63it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5039/17710 [11:40<27:48,  7.59it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5047/17710 [11:41<27:55,  7.56it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████                                                     | 5049/17710 [11:41<27:54,  7.56it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████                                                     | 5055/17710 [11:42<27:47,  7.59it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5063/17710 [11:43<27:47,  7.58it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5071/17710 [11:44<27:38,  7.62it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5079/17710 [11:45<27:34,  7.63it/s, loss=nan]Epoch 0 - train:  29%|████████████████████▋                                                   | 5087/17710 [11:51<1:07:16,  3.13it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5095/17710 [11:52<55:18,  3.80it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5099/17710 [11:53<55:17,  3.80it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5103/17710 [11:53<46:59,  4.47it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5111/17710 [11:54<41:02,  5.12it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5119/17710 [11:55<36:53,  5.69it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5127/17710 [11:57<34:03,  6.16it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5135/17710 [11:58<31:58,  6.55it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5143/17710 [11:59<30:31,  6.86it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5149/17710 [12:00<30:30,  6.86it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5151/17710 [12:00<29:36,  7.07it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5159/17710 [12:01<28:52,  7.25it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5167/17710 [12:02<28:21,  7.37it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5175/17710 [12:03<27:57,  7.47it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5183/17710 [12:04<27:40,  7.54it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5191/17710 [12:05<27:31,  7.58it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5199/17710 [12:06<27:24,  7.61it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5199/17710 [12:06<27:24,  7.61it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5207/17710 [12:07<27:19,  7.63it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5215/17710 [12:08<27:14,  7.65it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5223/17710 [12:09<27:11,  7.65it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▊                                                    | 5231/17710 [12:10<27:10,  7.65it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5239/17710 [12:11<27:09,  7.65it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5247/17710 [12:12<27:09,  7.65it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5249/17710 [12:13<27:09,  7.65it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5255/17710 [12:13<27:10,  7.64it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5263/17710 [12:14<27:12,  7.62it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5271/17710 [12:15<27:10,  7.63it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5279/17710 [12:16<27:04,  7.65it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5287/17710 [12:17<27:00,  7.66it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5295/17710 [12:18<26:56,  7.68it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5299/17710 [12:19<26:56,  7.68it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5303/17710 [12:19<26:59,  7.66it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5311/17710 [12:20<26:57,  7.67it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5319/17710 [12:22<27:00,  7.65it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5327/17710 [12:23<27:13,  7.58it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5335/17710 [12:24<27:21,  7.54it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5343/17710 [12:25<27:08,  7.59it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5349/17710 [12:26<27:07,  7.59it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5351/17710 [12:26<27:02,  7.62it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5359/17710 [12:27<27:00,  7.62it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5367/17710 [12:28<26:55,  7.64it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5375/17710 [12:29<26:53,  7.64it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5383/17710 [12:30<26:53,  7.64it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5391/17710 [12:31<26:56,  7.62it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5399/17710 [12:32<26:50,  7.65it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5399/17710 [12:32<26:50,  7.65it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▌                                                   | 5407/17710 [12:33<26:48,  7.65it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5415/17710 [12:34<26:40,  7.68it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5423/17710 [12:35<26:46,  7.65it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5431/17710 [12:36<26:41,  7.67it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5439/17710 [12:37<26:36,  7.68it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5447/17710 [12:38<26:38,  7.67it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5449/17710 [12:39<26:37,  7.67it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5455/17710 [12:39<26:36,  7.67it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5463/17710 [12:40<26:38,  7.66it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5471/17710 [12:41<26:38,  7.66it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5479/17710 [12:43<26:47,  7.61it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5487/17710 [12:44<26:41,  7.63it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5495/17710 [12:45<26:41,  7.63it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5499/17710 [12:45<26:41,  7.63it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5503/17710 [12:47<35:18,  5.76it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5510/17710 [12:48<34:03,  5.97it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5518/17710 [12:49<31:44,  6.40it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5526/17710 [12:50<30:11,  6.73it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5534/17710 [12:51<29:07,  6.97it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5542/17710 [12:52<28:15,  7.18it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5549/17710 [12:53<28:14,  7.18it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5550/17710 [12:53<27:44,  7.31it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5558/17710 [12:54<27:17,  7.42it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▎                                                  | 5566/17710 [12:55<27:01,  7.49it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▎                                                  | 5574/17710 [12:56<26:47,  7.55it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▎                                                  | 5582/17710 [12:57<26:39,  7.58it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▎                                                  | 5590/17710 [12:58<26:32,  7.61it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5598/17710 [12:59<26:24,  7.65it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5599/17710 [13:00<26:23,  7.65it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5606/17710 [13:00<26:17,  7.67it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5614/17710 [13:01<26:10,  7.70it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5622/17710 [13:02<26:06,  7.72it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5630/17710 [13:03<25:59,  7.74it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5638/17710 [13:04<26:01,  7.73it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5646/17710 [13:06<26:02,  7.72it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5649/17710 [13:06<26:02,  7.72it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5654/17710 [13:07<26:02,  7.71it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5662/17710 [13:08<25:59,  7.73it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5670/17710 [13:09<25:57,  7.73it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5678/17710 [13:10<25:55,  7.74it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5686/17710 [13:11<25:53,  7.74it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5694/17710 [13:12<25:53,  7.74it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5699/17710 [13:13<25:52,  7.74it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5702/17710 [13:13<25:49,  7.75it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5710/17710 [13:14<25:48,  7.75it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5718/17710 [13:15<25:47,  7.75it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5726/17710 [13:16<25:43,  7.77it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5734/17710 [13:17<25:49,  7.73it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5742/17710 [13:18<25:54,  7.70it/s, loss=nan]Epoch 0 - train:  32%|████████████████████████                                                  | 5749/17710 [13:19<25:53,  7.70it/s, loss=nan]Epoch 0 - train:  32%|████████████████████████                                                  | 5750/17710 [13:19<25:54,  7.69it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████                                                  | 5758/17710 [13:20<25:54,  7.69it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████                                                  | 5766/17710 [13:21<25:56,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5774/17710 [13:22<26:01,  7.64it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5782/17710 [13:23<25:58,  7.65it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5790/17710 [13:24<25:54,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5798/17710 [13:25<25:52,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5799/17710 [13:26<25:51,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5806/17710 [13:26<25:46,  7.70it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5814/17710 [13:27<25:47,  7.69it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5822/17710 [13:28<25:49,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5830/17710 [13:29<25:50,  7.66it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5838/17710 [13:30<25:46,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5846/17710 [13:32<25:44,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5849/17710 [13:32<25:44,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5854/17710 [13:33<25:45,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5862/17710 [13:34<25:45,  7.66it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5870/17710 [13:35<25:42,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5878/17710 [13:36<25:45,  7.65it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5886/17710 [13:37<25:41,  7.67it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5894/17710 [13:38<25:38,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5899/17710 [13:39<25:38,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5902/17710 [13:39<25:34,  7.69it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5910/17710 [13:40<25:36,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5918/17710 [13:41<25:35,  7.68it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▊                                                 | 5926/17710 [13:42<25:33,  7.69it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5934/17710 [13:43<25:40,  7.64it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5942/17710 [13:44<25:34,  7.67it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5949/17710 [13:45<25:33,  7.67it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5950/17710 [13:45<25:31,  7.68it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5958/17710 [13:47<28:57,  6.77it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5966/17710 [13:48<28:04,  6.97it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5974/17710 [13:49<27:14,  7.18it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5982/17710 [13:50<26:37,  7.34it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5990/17710 [13:51<26:11,  7.46it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5998/17710 [13:52<25:51,  7.55it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5999/17710 [13:52<25:51,  7.55it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 6006/17710 [13:53<25:37,  7.61it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6014/17710 [13:54<25:30,  7.64it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6022/17710 [13:55<25:23,  7.67it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6030/17710 [13:56<25:21,  7.67it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6038/17710 [13:57<25:13,  7.71it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6046/17710 [13:58<25:08,  7.73it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6049/17710 [13:58<25:08,  7.73it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6054/17710 [13:59<25:03,  7.75it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6062/17710 [14:00<25:11,  7.71it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6070/17710 [14:01<25:14,  7.69it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6078/17710 [14:02<25:12,  7.69it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6086/17710 [14:03<25:13,  7.68it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6094/17710 [14:04<25:06,  7.71it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6099/17710 [14:05<25:05,  7.71it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6102/17710 [14:05<25:01,  7.73it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6110/17710 [14:06<24:59,  7.74it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6118/17710 [14:07<25:01,  7.72it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6126/17710 [14:08<25:02,  7.71it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6134/17710 [14:09<25:02,  7.71it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6142/17710 [14:10<25:18,  7.62it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6149/17710 [14:12<25:17,  7.62it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6150/17710 [14:12<25:19,  7.61it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6158/17710 [14:13<25:14,  7.63it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6166/17710 [14:14<25:11,  7.64it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6174/17710 [14:15<25:08,  7.65it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6182/17710 [14:16<25:03,  7.67it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6190/17710 [14:17<24:59,  7.68it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6198/17710 [14:18<24:56,  7.69it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6199/17710 [14:18<24:56,  7.69it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6206/17710 [14:19<24:57,  7.68it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6214/17710 [14:20<24:55,  7.69it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6222/17710 [14:21<25:04,  7.64it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6230/17710 [14:22<25:02,  7.64it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6238/17710 [14:23<24:59,  7.65it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6246/17710 [14:24<25:04,  7.62it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6249/17710 [14:25<25:04,  7.62it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6254/17710 [14:25<25:20,  7.53it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6262/17710 [14:26<25:19,  7.54it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6270/17710 [14:27<25:09,  7.58it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6278/17710 [14:28<25:06,  7.59it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▎                                               | 6286/17710 [14:29<24:58,  7.62it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6294/17710 [14:30<24:51,  7.66it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6299/17710 [14:31<24:50,  7.66it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6302/17710 [14:31<24:55,  7.63it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6310/17710 [14:32<24:48,  7.66it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6318/17710 [14:34<24:51,  7.64it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6326/17710 [14:35<24:57,  7.60it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6334/17710 [14:36<24:55,  7.61it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6342/17710 [14:37<24:49,  7.63it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6349/17710 [14:38<24:48,  7.63it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6350/17710 [14:38<24:44,  7.65it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6358/17710 [14:39<24:38,  7.68it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6366/17710 [14:40<24:35,  7.69it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6374/17710 [14:41<24:42,  7.65it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6382/17710 [14:42<24:37,  7.67it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6390/17710 [14:43<24:30,  7.70it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6398/17710 [14:44<24:26,  7.72it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6399/17710 [14:44<24:25,  7.72it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6406/17710 [14:45<24:23,  7.72it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6414/17710 [14:50<51:05,  3.69it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6422/17710 [14:51<43:08,  4.36it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6429/17710 [14:52<39:27,  4.77it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6437/17710 [14:53<35:18,  5.32it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6445/17710 [14:54<31:57,  5.87it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6449/17710 [14:55<31:57,  5.87it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6453/17710 [14:55<29:33,  6.35it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6461/17710 [14:56<27:53,  6.72it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6469/17710 [14:57<26:47,  6.99it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6477/17710 [14:58<26:00,  7.20it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6485/17710 [14:59<25:25,  7.36it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6493/17710 [15:00<25:12,  7.42it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6499/17710 [15:01<25:11,  7.42it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6501/17710 [15:01<24:51,  7.51it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6509/17710 [15:02<24:45,  7.54it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6517/17710 [15:03<24:35,  7.59it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6525/17710 [15:04<24:26,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6533/17710 [15:06<24:19,  7.66it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6541/17710 [15:07<24:14,  7.68it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6549/17710 [15:08<24:11,  7.69it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6549/17710 [15:08<24:11,  7.69it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6557/17710 [15:09<24:07,  7.70it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6565/17710 [15:10<24:10,  7.68it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6573/17710 [15:11<24:09,  7.69it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6581/17710 [15:12<24:06,  7.70it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6589/17710 [15:13<24:00,  7.72it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6597/17710 [15:14<24:00,  7.71it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6599/17710 [15:14<24:00,  7.71it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6605/17710 [15:15<24:02,  7.70it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6613/17710 [15:16<23:58,  7.71it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6621/17710 [15:17<23:55,  7.73it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6629/17710 [15:18<23:55,  7.72it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6637/17710 [15:19<23:57,  7.70it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6645/17710 [15:20<23:54,  7.71it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6649/17710 [15:21<23:54,  7.71it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6653/17710 [15:21<23:58,  7.69it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6661/17710 [15:22<24:02,  7.66it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6669/17710 [15:23<24:01,  7.66it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6677/17710 [15:24<23:57,  7.67it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6685/17710 [15:25<23:54,  7.69it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6693/17710 [15:26<23:49,  7.71it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6699/17710 [15:27<23:48,  7.71it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6701/17710 [15:27<23:47,  7.71it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████                                              | 6709/17710 [15:28<23:44,  7.72it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████                                              | 6717/17710 [15:29<23:52,  7.68it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████                                              | 6725/17710 [15:30<23:50,  7.68it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6733/17710 [15:31<23:46,  7.70it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6741/17710 [15:33<23:53,  7.65it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6749/17710 [15:34<23:46,  7.69it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6749/17710 [15:34<23:46,  7.69it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6757/17710 [15:35<23:38,  7.72it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6765/17710 [15:36<23:33,  7.74it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6773/17710 [15:37<23:31,  7.75it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6781/17710 [15:38<23:28,  7.76it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6789/17710 [15:39<23:27,  7.76it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6797/17710 [15:40<23:25,  7.76it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6799/17710 [15:40<23:25,  7.76it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6805/17710 [15:41<23:25,  7.76it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6813/17710 [15:42<23:27,  7.74it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6821/17710 [15:43<23:22,  7.76it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6829/17710 [15:44<23:18,  7.78it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6837/17710 [15:45<23:18,  7.77it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6845/17710 [15:46<24:31,  7.39it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6849/17710 [15:47<24:30,  7.39it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6853/17710 [15:47<24:10,  7.48it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6861/17710 [15:48<23:51,  7.58it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6869/17710 [15:49<23:42,  7.62it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6877/17710 [15:50<23:35,  7.66it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6885/17710 [15:51<23:30,  7.68it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6893/17710 [15:52<23:22,  7.71it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6899/17710 [15:53<23:22,  7.71it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6901/17710 [15:53<23:19,  7.72it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6909/17710 [15:54<23:18,  7.72it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6917/17710 [15:55<23:16,  7.73it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6925/17710 [15:56<23:18,  7.71it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6933/17710 [15:57<23:19,  7.70it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6941/17710 [15:59<23:16,  7.71it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6949/17710 [16:00<23:17,  7.70it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6949/17710 [16:00<23:17,  7.70it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6957/17710 [16:01<23:19,  7.68it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6965/17710 [16:02<23:14,  7.71it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6973/17710 [16:03<23:15,  7.70it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6981/17710 [16:04<23:10,  7.71it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6989/17710 [16:05<23:12,  7.70it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▏                                            | 6997/17710 [16:06<23:08,  7.72it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▏                                            | 6999/17710 [16:06<23:08,  7.72it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7005/17710 [16:07<23:12,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7013/17710 [16:08<23:11,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7021/17710 [16:09<23:10,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7029/17710 [16:10<23:11,  7.68it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7037/17710 [16:11<23:17,  7.64it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7045/17710 [16:12<23:10,  7.67it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7049/17710 [16:13<23:09,  7.67it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7053/17710 [16:13<23:05,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7061/17710 [16:14<23:02,  7.70it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7069/17710 [16:15<23:01,  7.70it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7077/17710 [16:16<23:04,  7.68it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7085/17710 [16:17<22:59,  7.70it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7093/17710 [16:18<22:57,  7.71it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7099/17710 [16:19<22:56,  7.71it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7101/17710 [16:19<22:55,  7.71it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7109/17710 [16:20<22:54,  7.71it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7117/17710 [16:21<22:54,  7.71it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7125/17710 [16:22<23:01,  7.66it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7133/17710 [16:23<22:56,  7.68it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7141/17710 [16:25<22:57,  7.67it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7149/17710 [16:26<22:52,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7149/17710 [16:26<22:52,  7.69it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▉                                            | 7157/17710 [16:27<22:50,  7.70it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▉                                            | 7165/17710 [16:28<22:45,  7.72it/s, loss=nan]Epoch 0 - train:  41%|█████████████████████████████▉                                            | 7173/17710 [16:29<22:46,  7.71it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7181/17710 [16:30<22:46,  7.71it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7189/17710 [16:31<22:41,  7.73it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7197/17710 [16:32<22:44,  7.71it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7199/17710 [16:32<22:44,  7.71it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7205/17710 [16:33<22:46,  7.69it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7213/17710 [16:34<22:47,  7.68it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7221/17710 [16:35<22:41,  7.71it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7229/17710 [16:36<22:35,  7.73it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7237/17710 [16:37<22:30,  7.76it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7245/17710 [16:38<22:27,  7.77it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7249/17710 [16:39<22:27,  7.77it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7253/17710 [16:39<22:24,  7.78it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7261/17710 [16:40<22:24,  7.77it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7269/17710 [16:41<22:21,  7.78it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7277/17710 [16:42<22:20,  7.78it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7285/17710 [16:43<22:19,  7.78it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7293/17710 [16:44<22:17,  7.79it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7299/17710 [16:45<22:16,  7.79it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7301/17710 [16:45<22:14,  7.80it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7309/17710 [16:46<23:22,  7.42it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7317/17710 [16:47<22:58,  7.54it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7325/17710 [16:48<22:43,  7.61it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7333/17710 [16:49<22:34,  7.66it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7341/17710 [16:50<22:31,  7.67it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7349/17710 [16:52<22:32,  7.66it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7349/17710 [16:52<22:32,  7.66it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▋                                           | 7357/17710 [16:53<22:26,  7.69it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7365/17710 [16:54<22:33,  7.64it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7373/17710 [16:55<22:27,  7.67it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7381/17710 [16:56<22:22,  7.69it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7389/17710 [16:57<22:20,  7.70it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7397/17710 [16:58<22:19,  7.70it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7399/17710 [16:58<22:18,  7.70it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7405/17710 [16:59<22:20,  7.69it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7413/17710 [17:00<22:20,  7.68it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7421/17710 [17:01<22:16,  7.70it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7429/17710 [17:02<22:17,  7.69it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7437/17710 [17:03<22:13,  7.71it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7445/17710 [17:04<22:13,  7.70it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7449/17710 [17:05<22:12,  7.70it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7453/17710 [17:05<22:10,  7.71it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7461/17710 [17:06<22:07,  7.72it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7469/17710 [17:07<22:06,  7.72it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7477/17710 [17:08<22:01,  7.74it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7485/17710 [17:09<22:02,  7.73it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7493/17710 [17:10<22:05,  7.71it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7499/17710 [17:11<22:04,  7.71it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7501/17710 [17:11<22:03,  7.71it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▍                                          | 7509/17710 [17:12<21:59,  7.73it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▍                                          | 7517/17710 [17:13<21:56,  7.74it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▍                                          | 7525/17710 [17:14<21:53,  7.75it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▍                                          | 7533/17710 [17:15<21:51,  7.76it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7541/17710 [17:16<21:52,  7.75it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7549/17710 [17:17<21:49,  7.76it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7549/17710 [17:18<21:49,  7.76it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7557/17710 [17:18<21:47,  7.77it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7565/17710 [17:19<21:44,  7.78it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7573/17710 [17:21<21:45,  7.76it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7581/17710 [17:22<21:46,  7.76it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7589/17710 [17:23<21:56,  7.69it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7597/17710 [17:24<21:54,  7.70it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7599/17710 [17:24<21:53,  7.70it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7605/17710 [17:25<21:55,  7.68it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7613/17710 [17:26<21:55,  7.68it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7621/17710 [17:27<21:57,  7.66it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7629/17710 [17:28<21:57,  7.65it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7637/17710 [17:29<21:55,  7.65it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7645/17710 [17:30<21:50,  7.68it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7649/17710 [17:31<21:49,  7.68it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7653/17710 [17:31<21:51,  7.67it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7661/17710 [17:32<21:42,  7.71it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7669/17710 [17:33<21:37,  7.74it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7677/17710 [17:34<21:32,  7.76it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7685/17710 [17:35<21:30,  7.77it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7693/17710 [17:36<21:34,  7.74it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7699/17710 [17:37<21:33,  7.74it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7701/17710 [17:37<21:32,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▏                                         | 7709/17710 [17:38<21:30,  7.75it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▏                                         | 7717/17710 [17:39<21:28,  7.75it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7725/17710 [17:40<21:28,  7.75it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7733/17710 [17:41<21:28,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7741/17710 [17:42<21:28,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7749/17710 [17:43<21:23,  7.76it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7749/17710 [17:43<21:23,  7.76it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7757/17710 [17:44<21:23,  7.75it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7765/17710 [17:46<22:03,  7.51it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7773/17710 [17:47<23:23,  7.08it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7781/17710 [17:48<22:47,  7.26it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7789/17710 [17:49<22:24,  7.38it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7797/17710 [17:50<22:10,  7.45it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7799/17710 [17:50<22:09,  7.45it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7805/17710 [17:51<21:56,  7.52it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7813/17710 [17:52<21:48,  7.57it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7821/17710 [17:53<21:45,  7.58it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7829/17710 [17:54<21:40,  7.60it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7837/17710 [17:55<21:43,  7.57it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7845/17710 [17:56<21:40,  7.59it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7849/17710 [17:57<21:39,  7.59it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7853/17710 [17:57<21:33,  7.62it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7861/17710 [17:58<21:30,  7.63it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▉                                         | 7869/17710 [17:59<21:25,  7.66it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▉                                         | 7877/17710 [18:00<21:22,  7.67it/s, loss=nan]Epoch 0 - train:  45%|████████████████████████████████▉                                         | 7885/17710 [18:01<21:18,  7.69it/s, loss=nan]Epoch 0 - train:  45%|████████████████████████████████▉                                         | 7893/17710 [18:02<21:14,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7899/17710 [18:03<21:13,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7901/17710 [18:03<21:10,  7.72it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7909/17710 [18:05<21:07,  7.73it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7917/17710 [18:06<21:06,  7.73it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7925/17710 [18:07<21:04,  7.74it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7933/17710 [18:08<21:00,  7.76it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7941/17710 [18:09<20:59,  7.76it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7949/17710 [18:10<20:56,  7.77it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7949/17710 [18:10<20:56,  7.77it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7957/17710 [18:11<20:54,  7.77it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7965/17710 [18:12<20:53,  7.78it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7973/17710 [18:13<20:53,  7.77it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7981/17710 [18:14<21:00,  7.72it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7989/17710 [18:15<21:03,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7997/17710 [18:16<21:07,  7.66it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7999/17710 [18:16<21:07,  7.66it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 8005/17710 [18:17<21:05,  7.67it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 8013/17710 [18:18<21:00,  7.69it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8021/17710 [18:19<20:58,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8029/17710 [18:20<20:59,  7.69it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8037/17710 [18:21<20:57,  7.69it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8045/17710 [18:22<20:55,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▋                                        | 8049/17710 [18:23<20:54,  7.70it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▋                                        | 8053/17710 [18:23<20:51,  7.72it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8061/17710 [18:24<20:58,  7.67it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8069/17710 [18:25<20:58,  7.66it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8077/17710 [18:26<21:00,  7.64it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8085/17710 [18:27<20:54,  7.67it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8093/17710 [18:28<20:54,  7.67it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8099/17710 [18:29<20:53,  7.67it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8101/17710 [18:29<20:46,  7.71it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8109/17710 [18:30<20:44,  7.71it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8117/17710 [18:31<20:41,  7.73it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8125/17710 [18:33<20:38,  7.74it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8133/17710 [18:34<20:33,  7.76it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8141/17710 [18:35<20:33,  7.76it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8149/17710 [18:36<20:29,  7.78it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8149/17710 [18:36<20:29,  7.78it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8157/17710 [18:37<20:28,  7.78it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8165/17710 [18:38<20:26,  7.78it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8173/17710 [18:39<20:25,  7.78it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8181/17710 [18:40<20:26,  7.77it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8189/17710 [18:41<20:28,  7.75it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8197/17710 [18:42<20:30,  7.73it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8199/17710 [18:42<20:30,  7.73it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8205/17710 [18:43<20:28,  7.74it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8213/17710 [18:44<20:28,  7.73it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8221/17710 [18:45<20:25,  7.74it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▍                                       | 8229/17710 [18:46<22:20,  7.07it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8237/17710 [18:47<21:56,  7.19it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8245/17710 [18:48<21:28,  7.35it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8249/17710 [18:49<21:27,  7.35it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8253/17710 [18:49<21:08,  7.46it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8261/17710 [18:50<21:00,  7.49it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8269/17710 [18:51<20:47,  7.57it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8277/17710 [18:52<20:36,  7.63it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8285/17710 [18:54<20:27,  7.68it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8293/17710 [18:55<20:23,  7.70it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8299/17710 [18:55<20:22,  7.70it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8301/17710 [18:56<20:16,  7.73it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8309/17710 [18:57<20:14,  7.74it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8317/17710 [18:58<20:20,  7.70it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8325/17710 [18:59<20:14,  7.73it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8333/17710 [19:00<20:18,  7.69it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8341/17710 [19:01<20:12,  7.73it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8349/17710 [19:02<20:17,  7.69it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8349/17710 [19:02<20:17,  7.69it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8357/17710 [19:03<20:12,  7.71it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8365/17710 [19:04<20:10,  7.72it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8373/17710 [19:05<20:11,  7.70it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8381/17710 [19:06<20:20,  7.64it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8389/17710 [19:07<20:13,  7.68it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8397/17710 [19:08<20:11,  7.69it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8399/17710 [19:08<20:10,  7.69it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8405/17710 [19:09<20:09,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8413/17710 [19:10<20:15,  7.65it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8421/17710 [19:11<20:10,  7.68it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8429/17710 [19:12<20:05,  7.70it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8437/17710 [19:13<20:07,  7.68it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8445/17710 [19:14<20:04,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8449/17710 [19:15<20:04,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8453/17710 [19:15<20:08,  7.66it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8461/17710 [19:16<20:03,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8469/17710 [19:17<20:01,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8477/17710 [19:18<20:03,  7.67it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8485/17710 [19:20<20:02,  7.67it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8493/17710 [19:21<20:06,  7.64it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8499/17710 [19:22<20:05,  7.64it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8501/17710 [19:22<20:09,  7.62it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8509/17710 [19:23<20:02,  7.65it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8517/17710 [19:24<19:58,  7.67it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8525/17710 [19:25<19:59,  7.66it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8533/17710 [19:26<19:55,  7.68it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8541/17710 [19:27<19:52,  7.69it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8549/17710 [19:28<19:49,  7.70it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8549/17710 [19:28<19:49,  7.70it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8557/17710 [19:29<19:45,  7.72it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8565/17710 [19:30<19:43,  7.73it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8573/17710 [19:31<19:42,  7.73it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8581/17710 [19:32<19:39,  7.74it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▉                                      | 8589/17710 [19:33<19:36,  7.75it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8597/17710 [19:34<19:33,  7.77it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8599/17710 [19:34<19:33,  7.77it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8605/17710 [19:35<19:31,  7.77it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8613/17710 [19:36<19:43,  7.69it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8621/17710 [19:37<19:39,  7.71it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8629/17710 [19:38<19:37,  7.71it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8637/17710 [19:39<19:44,  7.66it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8645/17710 [19:40<19:41,  7.67it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8649/17710 [19:41<19:41,  7.67it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8653/17710 [19:41<19:42,  7.66it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8661/17710 [19:42<19:38,  7.68it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8669/17710 [19:43<19:34,  7.70it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8677/17710 [19:44<19:28,  7.73it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8685/17710 [19:46<20:14,  7.43it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8693/17710 [19:47<20:16,  7.41it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8699/17710 [19:48<20:15,  7.41it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8701/17710 [19:48<20:00,  7.50it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8709/17710 [19:49<19:47,  7.58it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8717/17710 [19:50<19:41,  7.61it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8725/17710 [19:51<19:37,  7.63it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8733/17710 [19:52<19:33,  7.65it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8741/17710 [19:53<19:28,  7.67it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8749/17710 [19:54<19:23,  7.70it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8749/17710 [19:54<19:23,  7.70it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8757/17710 [19:55<19:24,  7.69it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8765/17710 [19:56<19:21,  7.70it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8773/17710 [19:57<19:24,  7.68it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8781/17710 [19:58<19:18,  7.71it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8789/17710 [19:59<19:19,  7.69it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8797/17710 [20:00<19:18,  7.69it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8799/17710 [20:01<19:18,  7.69it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8805/17710 [20:01<19:21,  7.66it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8813/17710 [20:02<19:17,  7.69it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8821/17710 [20:03<19:14,  7.70it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8829/17710 [20:04<19:15,  7.69it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8837/17710 [20:05<19:17,  7.66it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8845/17710 [20:06<19:16,  7.67it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8849/17710 [20:07<19:15,  7.67it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8853/17710 [20:08<19:15,  7.67it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8861/17710 [20:09<19:09,  7.70it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8869/17710 [20:10<19:04,  7.72it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8877/17710 [20:11<19:07,  7.70it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8885/17710 [20:12<19:08,  7.69it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8893/17710 [20:13<19:02,  7.72it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8899/17710 [20:14<19:01,  7.72it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8901/17710 [20:14<18:58,  7.74it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8909/17710 [20:15<18:57,  7.74it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8917/17710 [20:16<18:54,  7.75it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8925/17710 [20:17<18:53,  7.75it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8933/17710 [20:18<18:51,  7.75it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8941/17710 [20:19<18:53,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8949/17710 [20:20<18:54,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8949/17710 [20:20<18:54,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8957/17710 [20:21<18:55,  7.71it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8965/17710 [20:22<18:55,  7.70it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8973/17710 [20:23<18:56,  7.69it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8981/17710 [20:24<18:57,  7.68it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8989/17710 [20:25<18:53,  7.70it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8997/17710 [20:26<18:48,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8999/17710 [20:27<18:48,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9005/17710 [20:27<18:47,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9013/17710 [20:28<18:45,  7.73it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9021/17710 [20:29<18:44,  7.72it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9029/17710 [20:30<18:43,  7.73it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9037/17710 [20:31<18:40,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9045/17710 [20:32<18:38,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9049/17710 [20:33<18:38,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9053/17710 [20:33<18:39,  7.73it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9061/17710 [20:34<18:37,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9069/17710 [20:35<18:35,  7.74it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9077/17710 [20:37<18:39,  7.71it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9085/17710 [20:38<18:39,  7.71it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9093/17710 [20:39<18:40,  7.69it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9099/17710 [20:39<18:39,  7.69it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9101/17710 [20:40<18:35,  7.72it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9109/17710 [20:41<18:32,  7.73it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9117/17710 [20:42<18:29,  7.74it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9125/17710 [20:43<18:28,  7.75it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9133/17710 [20:44<18:27,  7.75it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9141/17710 [20:45<18:28,  7.73it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9149/17710 [20:49<35:42,  4.00it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9149/17710 [20:49<35:42,  4.00it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9156/17710 [20:50<32:00,  4.45it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9164/17710 [20:51<27:54,  5.10it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9171/17710 [20:52<26:58,  5.28it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9178/17710 [20:54<25:56,  5.48it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9185/17710 [20:55<26:10,  5.43it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9192/17710 [20:56<24:51,  5.71it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9199/17710 [20:57<24:50,  5.71it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9200/17710 [20:57<22:53,  6.20it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9208/17710 [20:58<21:30,  6.59it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9216/17710 [20:59<20:33,  6.89it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9224/17710 [21:00<19:55,  7.10it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9232/17710 [21:01<19:24,  7.28it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9240/17710 [21:02<19:02,  7.41it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9248/17710 [21:03<18:48,  7.50it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9249/17710 [21:04<18:48,  7.50it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9256/17710 [21:04<18:36,  7.57it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9264/17710 [21:05<18:25,  7.64it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9272/17710 [21:06<18:24,  7.64it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9280/17710 [21:07<18:16,  7.69it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9288/17710 [21:08<18:10,  7.72it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9296/17710 [21:09<18:09,  7.72it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▊                                   | 9299/17710 [21:10<18:09,  7.72it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9304/17710 [21:10<18:04,  7.75it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9312/17710 [21:11<18:02,  7.76it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9320/17710 [21:13<18:03,  7.74it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9328/17710 [21:14<18:09,  7.70it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9336/17710 [21:15<18:09,  7.69it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9344/17710 [21:16<18:11,  7.67it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9349/17710 [21:16<18:10,  7.67it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9352/17710 [21:17<18:06,  7.69it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9360/17710 [21:18<18:02,  7.71it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9368/17710 [21:19<18:00,  7.72it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9376/17710 [21:20<18:01,  7.71it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9384/17710 [21:21<18:02,  7.69it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9392/17710 [21:22<18:00,  7.70it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9399/17710 [21:23<17:59,  7.70it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9400/17710 [21:23<17:57,  7.72it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9408/17710 [21:24<17:54,  7.73it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9416/17710 [21:25<17:53,  7.73it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9424/17710 [21:26<17:52,  7.73it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9432/17710 [21:27<17:49,  7.74it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9440/17710 [21:28<17:45,  7.76it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9448/17710 [21:29<17:44,  7.76it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9449/17710 [21:29<17:44,  7.76it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▌                                  | 9456/17710 [21:30<17:42,  7.77it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▌                                  | 9464/17710 [21:31<17:42,  7.76it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▌                                  | 9472/17710 [21:32<17:42,  7.76it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▌                                  | 9480/17710 [21:33<17:42,  7.75it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9488/17710 [21:34<17:39,  7.76it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9496/17710 [21:35<17:38,  7.76it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9499/17710 [21:36<17:38,  7.76it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9504/17710 [21:36<18:04,  7.57it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9512/17710 [21:37<17:56,  7.62it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9520/17710 [21:39<17:53,  7.63it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9528/17710 [21:40<17:49,  7.65it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9536/17710 [21:41<17:46,  7.67it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9544/17710 [21:42<17:42,  7.69it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9549/17710 [21:42<17:41,  7.69it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9552/17710 [21:43<17:40,  7.69it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9560/17710 [21:44<17:39,  7.69it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9568/17710 [21:45<17:39,  7.68it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9576/17710 [21:47<22:25,  6.05it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9583/17710 [21:48<21:57,  6.17it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9591/17710 [21:49<20:40,  6.55it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9599/17710 [21:50<19:42,  6.86it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9599/17710 [21:50<19:42,  6.86it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9607/17710 [21:51<19:07,  7.06it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9615/17710 [21:52<18:38,  7.24it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9623/17710 [21:53<18:20,  7.35it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9631/17710 [21:54<18:02,  7.46it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9639/17710 [21:55<17:51,  7.53it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9647/17710 [21:56<17:42,  7.59it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9649/17710 [21:57<17:42,  7.59it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▎                                 | 9655/17710 [21:57<17:34,  7.64it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9663/17710 [21:58<17:32,  7.64it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9671/17710 [21:59<17:26,  7.68it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9679/17710 [22:00<17:22,  7.70it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9687/17710 [22:01<17:20,  7.71it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9695/17710 [22:02<17:16,  7.73it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9699/17710 [22:03<17:15,  7.73it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9703/17710 [22:03<17:13,  7.75it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9711/17710 [22:04<17:12,  7.75it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9719/17710 [22:05<17:12,  7.74it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9727/17710 [22:06<17:12,  7.74it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9735/17710 [22:08<17:10,  7.74it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9743/17710 [22:09<17:11,  7.72it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9749/17710 [22:09<17:11,  7.72it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9751/17710 [22:10<17:06,  7.75it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9759/17710 [22:11<17:06,  7.75it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9767/17710 [22:12<17:09,  7.71it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9775/17710 [22:13<17:07,  7.72it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9783/17710 [22:14<17:11,  7.68it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9791/17710 [22:15<17:10,  7.69it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9799/17710 [22:16<17:06,  7.71it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9799/17710 [22:16<17:06,  7.71it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9807/17710 [22:17<17:06,  7.70it/s, loss=nan]Epoch 0 - train:  55%|█████████████████████████████████████████                                 | 9815/17710 [22:18<17:06,  7.69it/s, loss=nan]Epoch 0 - train:  55%|█████████████████████████████████████████                                 | 9823/17710 [22:19<17:03,  7.70it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████                                 | 9831/17710 [22:20<17:03,  7.69it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████                                 | 9839/17710 [22:21<17:05,  7.67it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9847/17710 [22:22<17:05,  7.67it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9849/17710 [22:22<17:05,  7.67it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9855/17710 [22:23<17:08,  7.63it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9863/17710 [22:24<17:12,  7.60it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9871/17710 [22:25<17:14,  7.58it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9879/17710 [22:26<17:12,  7.58it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9887/17710 [22:27<17:19,  7.53it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9895/17710 [22:28<17:27,  7.46it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9899/17710 [22:29<17:26,  7.46it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9903/17710 [22:30<17:26,  7.46it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9911/17710 [22:31<17:20,  7.50it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9919/17710 [22:32<17:15,  7.52it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9927/17710 [22:33<17:04,  7.60it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9935/17710 [22:34<16:54,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9943/17710 [22:35<16:51,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9949/17710 [22:36<16:50,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9951/17710 [22:36<16:48,  7.70it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9959/17710 [22:37<16:47,  7.69it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9967/17710 [22:38<16:49,  7.67it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9975/17710 [22:39<16:50,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9983/17710 [22:40<16:49,  7.65it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9991/17710 [22:41<16:51,  7.63it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▊                                | 9999/17710 [22:42<16:50,  7.63it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▊                                | 9999/17710 [22:42<16:50,  7.63it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▏                               | 10007/17710 [22:43<16:54,  7.59it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10015/17710 [22:44<16:51,  7.60it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10023/17710 [22:45<16:49,  7.61it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10031/17710 [22:49<30:17,  4.22it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10039/17710 [22:50<26:06,  4.90it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10047/17710 [22:51<23:12,  5.50it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10049/17710 [22:52<23:12,  5.50it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10055/17710 [22:52<21:20,  5.98it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10063/17710 [22:53<19:51,  6.42it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10071/17710 [22:54<18:54,  6.74it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10079/17710 [22:55<18:12,  6.99it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10087/17710 [22:56<17:42,  7.18it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10095/17710 [22:57<17:27,  7.27it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10099/17710 [22:58<17:26,  7.27it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10103/17710 [22:59<17:06,  7.41it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10111/17710 [23:00<16:54,  7.49it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10119/17710 [23:01<16:46,  7.54it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10127/17710 [23:02<16:41,  7.57it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10135/17710 [23:03<16:38,  7.59it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10143/17710 [23:04<16:32,  7.63it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10149/17710 [23:05<16:31,  7.63it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10151/17710 [23:05<16:29,  7.64it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10159/17710 [23:06<16:26,  7.66it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10167/17710 [23:07<16:21,  7.69it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10175/17710 [23:08<16:27,  7.63it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10183/17710 [23:09<16:25,  7.64it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10191/17710 [23:10<16:23,  7.65it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10199/17710 [23:11<16:21,  7.66it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10199/17710 [23:11<16:21,  7.66it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10207/17710 [23:12<16:16,  7.68it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10215/17710 [23:13<16:14,  7.69it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10223/17710 [23:14<16:17,  7.66it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10231/17710 [23:15<16:15,  7.67it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10239/17710 [23:16<16:12,  7.68it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10247/17710 [23:17<16:13,  7.67it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10249/17710 [23:18<16:13,  7.67it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10255/17710 [23:18<16:12,  7.67it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10263/17710 [23:19<16:14,  7.64it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10271/17710 [23:20<16:11,  7.66it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10279/17710 [23:21<16:07,  7.68it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10287/17710 [23:22<16:03,  7.71it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10295/17710 [23:24<16:03,  7.70it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10299/17710 [23:24<16:02,  7.70it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10303/17710 [23:25<16:02,  7.70it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10311/17710 [23:26<16:01,  7.70it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10319/17710 [23:27<15:58,  7.71it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10327/17710 [23:28<15:55,  7.72it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10335/17710 [23:29<15:53,  7.73it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10343/17710 [23:30<15:51,  7.74it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10349/17710 [23:31<15:50,  7.74it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10351/17710 [23:31<15:52,  7.73it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10359/17710 [23:32<15:50,  7.74it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▋                              | 10367/17710 [23:33<15:52,  7.71it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10375/17710 [23:34<15:49,  7.73it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10383/17710 [23:35<15:51,  7.70it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10391/17710 [23:36<15:49,  7.71it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10399/17710 [23:37<15:51,  7.68it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10399/17710 [23:37<15:51,  7.68it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▉                              | 10407/17710 [23:38<15:50,  7.68it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▉                              | 10415/17710 [23:39<15:50,  7.68it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▉                              | 10423/17710 [23:40<15:49,  7.68it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▉                              | 10431/17710 [23:41<15:48,  7.67it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10439/17710 [23:42<15:45,  7.69it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10447/17710 [23:43<15:44,  7.69it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10449/17710 [23:44<15:44,  7.69it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10455/17710 [23:44<15:45,  7.67it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10463/17710 [23:45<15:42,  7.69it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10471/17710 [23:46<16:10,  7.46it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10479/17710 [23:48<16:05,  7.49it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10487/17710 [23:49<15:55,  7.56it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10495/17710 [23:50<15:47,  7.62it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10499/17710 [23:50<15:46,  7.62it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10503/17710 [23:51<15:46,  7.62it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10511/17710 [23:52<15:44,  7.63it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10519/17710 [23:53<15:39,  7.66it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▍                             | 10527/17710 [23:54<15:34,  7.68it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▍                             | 10535/17710 [23:55<15:32,  7.69it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10543/17710 [23:56<15:35,  7.66it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10549/17710 [23:57<15:35,  7.66it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10551/17710 [23:57<15:40,  7.61it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10559/17710 [23:58<15:54,  7.49it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10567/17710 [23:59<15:54,  7.49it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10575/17710 [24:00<15:47,  7.53it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10583/17710 [24:01<15:44,  7.55it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10591/17710 [24:02<15:38,  7.58it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10599/17710 [24:03<15:35,  7.60it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10599/17710 [24:03<15:35,  7.60it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10607/17710 [24:04<15:31,  7.62it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10615/17710 [24:05<15:28,  7.64it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10623/17710 [24:06<15:27,  7.64it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10631/17710 [24:07<15:28,  7.62it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10639/17710 [24:09<15:26,  7.63it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10647/17710 [24:10<15:24,  7.64it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10649/17710 [24:10<15:24,  7.64it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10655/17710 [24:11<15:22,  7.64it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10663/17710 [24:12<15:31,  7.57it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10671/17710 [24:13<15:49,  7.41it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10679/17710 [24:14<15:44,  7.44it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10687/17710 [24:15<15:41,  7.46it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10695/17710 [24:16<15:34,  7.50it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10699/17710 [24:17<15:34,  7.50it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10703/17710 [24:17<15:26,  7.57it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████▏                            | 10711/17710 [24:18<15:20,  7.61it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10719/17710 [24:19<15:18,  7.61it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10727/17710 [24:20<15:13,  7.64it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10735/17710 [24:21<15:17,  7.61it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10743/17710 [24:22<15:13,  7.63it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10749/17710 [24:23<15:12,  7.63it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10751/17710 [24:23<15:39,  7.41it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10759/17710 [24:25<16:22,  7.08it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10767/17710 [24:26<16:21,  7.08it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10775/17710 [24:27<15:57,  7.25it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10783/17710 [24:28<15:38,  7.38it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10791/17710 [24:29<15:24,  7.49it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10799/17710 [24:30<15:15,  7.55it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10799/17710 [24:30<15:15,  7.55it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10807/17710 [24:31<15:09,  7.59it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10815/17710 [24:32<15:04,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10823/17710 [24:33<14:59,  7.65it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10831/17710 [24:34<14:57,  7.66it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10839/17710 [24:35<14:54,  7.68it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10847/17710 [24:36<15:05,  7.58it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10849/17710 [24:37<15:05,  7.58it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10855/17710 [24:37<15:03,  7.59it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10863/17710 [24:38<15:01,  7.60it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10871/17710 [24:39<14:57,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10879/17710 [24:40<14:56,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▉                            | 10887/17710 [24:41<14:55,  7.62it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10895/17710 [24:43<14:51,  7.65it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10899/17710 [24:43<14:50,  7.65it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10903/17710 [24:44<14:49,  7.65it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10911/17710 [24:45<14:46,  7.67it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10919/17710 [24:46<15:39,  7.22it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10927/17710 [24:47<15:27,  7.32it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10935/17710 [24:48<15:13,  7.41it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10943/17710 [24:49<15:04,  7.48it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10949/17710 [24:50<15:03,  7.48it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10951/17710 [24:50<14:58,  7.52it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10959/17710 [24:51<14:55,  7.54it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10967/17710 [24:52<14:53,  7.55it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10975/17710 [24:53<14:53,  7.54it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10983/17710 [24:54<14:48,  7.57it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10991/17710 [24:55<14:43,  7.60it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10999/17710 [24:56<14:42,  7.60it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10999/17710 [24:57<14:42,  7.60it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 11007/17710 [24:57<14:40,  7.62it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11015/17710 [24:59<14:48,  7.54it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11023/17710 [25:00<14:40,  7.59it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11031/17710 [25:01<14:36,  7.62it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11039/17710 [25:02<14:34,  7.63it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11047/17710 [25:03<14:32,  7.63it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11049/17710 [25:03<14:32,  7.63it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11055/17710 [25:04<14:34,  7.61it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11063/17710 [25:05<14:30,  7.64it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11071/17710 [25:06<14:26,  7.66it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11079/17710 [25:07<14:25,  7.66it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11087/17710 [25:08<14:21,  7.68it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11095/17710 [25:09<14:19,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11099/17710 [25:10<14:19,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11103/17710 [25:10<14:19,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11111/17710 [25:11<14:17,  7.70it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11119/17710 [25:12<14:17,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11127/17710 [25:13<14:15,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11135/17710 [25:14<14:15,  7.68it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11143/17710 [25:15<14:14,  7.68it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11149/17710 [25:16<14:13,  7.68it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11151/17710 [25:16<14:13,  7.69it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11159/17710 [25:17<14:11,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11167/17710 [25:18<14:09,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11175/17710 [25:19<14:07,  7.71it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11183/17710 [25:20<14:07,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11191/17710 [25:21<14:06,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11199/17710 [25:22<14:05,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11199/17710 [25:23<14:05,  7.70it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11207/17710 [25:23<14:03,  7.71it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11215/17710 [25:25<14:02,  7.71it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11223/17710 [25:26<14:03,  7.69it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11231/17710 [25:27<14:05,  7.67it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11239/17710 [25:28<14:04,  7.66it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▎                          | 11247/17710 [25:29<14:03,  7.66it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▎                          | 11249/17710 [25:29<14:03,  7.66it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11255/17710 [25:30<14:01,  7.67it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11263/17710 [25:31<14:00,  7.67it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11271/17710 [25:32<13:58,  7.68it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11279/17710 [25:33<13:57,  7.68it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11287/17710 [25:34<13:56,  7.68it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11295/17710 [25:35<13:54,  7.69it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11299/17710 [25:36<13:53,  7.69it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11303/17710 [25:36<13:53,  7.69it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11311/17710 [25:37<14:00,  7.61it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11319/17710 [25:38<14:02,  7.59it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11327/17710 [25:39<14:02,  7.58it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11335/17710 [25:40<13:59,  7.60it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11343/17710 [25:41<13:54,  7.63it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11349/17710 [25:42<13:53,  7.63it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11351/17710 [25:42<13:56,  7.60it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11359/17710 [25:43<13:51,  7.64it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11367/17710 [25:44<13:47,  7.66it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11375/17710 [25:45<13:44,  7.68it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11383/17710 [25:47<14:13,  7.41it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11391/17710 [25:48<14:07,  7.45it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11399/17710 [25:49<13:59,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11399/17710 [25:49<13:59,  7.52it/s, loss=nan]Epoch 0 - train:  64%|███████████████████████████████████████████████                          | 11407/17710 [25:50<13:55,  7.54it/s, loss=nan]Epoch 0 - train:  64%|███████████████████████████████████████████████                          | 11415/17710 [25:51<13:54,  7.54it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████                          | 11423/17710 [25:52<13:48,  7.59it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████                          | 11431/17710 [25:53<13:43,  7.62it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11439/17710 [25:54<13:40,  7.64it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11447/17710 [25:55<13:40,  7.64it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11449/17710 [25:55<13:39,  7.64it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11455/17710 [25:56<13:38,  7.64it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11463/17710 [25:57<13:36,  7.66it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11471/17710 [25:58<13:33,  7.67it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11479/17710 [25:59<13:33,  7.66it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11487/17710 [26:00<13:31,  7.67it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11495/17710 [26:01<13:30,  7.67it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11499/17710 [26:02<13:29,  7.67it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11503/17710 [26:02<13:28,  7.68it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11511/17710 [26:03<13:34,  7.61it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11519/17710 [26:04<13:30,  7.64it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11527/17710 [26:05<13:28,  7.65it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11535/17710 [26:06<13:26,  7.66it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11543/17710 [26:08<13:25,  7.66it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11549/17710 [26:08<13:24,  7.66it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11551/17710 [26:09<13:21,  7.68it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11559/17710 [26:10<13:18,  7.70it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11567/17710 [26:11<13:15,  7.72it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11575/17710 [26:12<13:16,  7.71it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11583/17710 [26:13<13:17,  7.68it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11591/17710 [26:14<13:16,  7.69it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11599/17710 [26:15<13:14,  7.69it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11599/17710 [26:15<13:14,  7.69it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▊                         | 11607/17710 [26:16<13:20,  7.62it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11615/17710 [26:17<13:19,  7.62it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11623/17710 [26:18<13:16,  7.64it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11631/17710 [26:19<13:13,  7.66it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11639/17710 [26:20<13:12,  7.66it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11647/17710 [26:21<13:15,  7.62it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11649/17710 [26:21<13:15,  7.62it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11655/17710 [26:22<13:15,  7.61it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11663/17710 [26:23<13:14,  7.61it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11671/17710 [26:24<13:12,  7.62it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11679/17710 [26:25<13:10,  7.62it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11687/17710 [26:26<13:10,  7.62it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11695/17710 [26:27<13:05,  7.66it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11699/17710 [26:28<13:05,  7.66it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11703/17710 [26:28<13:06,  7.64it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11711/17710 [26:29<13:03,  7.66it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11719/17710 [26:31<13:01,  7.67it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11727/17710 [26:32<12:58,  7.68it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11735/17710 [26:33<12:57,  7.69it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11743/17710 [26:34<12:55,  7.70it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11749/17710 [26:35<12:54,  7.70it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11751/17710 [26:35<12:54,  7.70it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11759/17710 [26:36<12:53,  7.69it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▌                        | 11767/17710 [26:37<12:53,  7.68it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▌                        | 11775/17710 [26:38<12:59,  7.61it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▌                        | 11783/17710 [26:39<12:56,  7.63it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▌                        | 11791/17710 [26:40<12:55,  7.63it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11799/17710 [26:41<12:54,  7.63it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11799/17710 [26:41<12:54,  7.63it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11807/17710 [26:42<12:52,  7.65it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11815/17710 [26:43<12:51,  7.64it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11823/17710 [26:44<12:54,  7.60it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11831/17710 [26:45<12:50,  7.63it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11839/17710 [26:46<13:34,  7.21it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11847/17710 [26:47<13:16,  7.36it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11849/17710 [26:48<13:16,  7.36it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11855/17710 [26:49<13:06,  7.44it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11863/17710 [26:50<12:56,  7.53it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11871/17710 [26:51<12:50,  7.57it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11879/17710 [26:52<12:45,  7.62it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11887/17710 [26:53<12:42,  7.64it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11895/17710 [26:54<12:39,  7.66it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11899/17710 [26:54<12:38,  7.66it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11903/17710 [26:55<12:42,  7.62it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11911/17710 [26:56<12:44,  7.59it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11919/17710 [26:57<12:39,  7.63it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11927/17710 [26:58<12:38,  7.63it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11935/17710 [26:59<12:35,  7.65it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11943/17710 [27:00<12:35,  7.64it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▎                       | 11949/17710 [27:01<12:34,  7.64it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▎                       | 11951/17710 [27:01<12:31,  7.66it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11959/17710 [27:02<12:30,  7.66it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11967/17710 [27:03<12:28,  7.67it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11975/17710 [27:04<12:24,  7.70it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11983/17710 [27:05<12:21,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11991/17710 [27:06<12:20,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11999/17710 [27:07<12:18,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11999/17710 [27:07<12:18,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 12007/17710 [27:08<12:17,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12015/17710 [27:09<12:16,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12023/17710 [27:10<12:15,  7.74it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12031/17710 [27:11<12:13,  7.74it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12039/17710 [27:12<12:11,  7.75it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12047/17710 [27:13<12:12,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12049/17710 [27:14<12:12,  7.73it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12055/17710 [27:14<12:12,  7.72it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12063/17710 [27:16<12:12,  7.71it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12071/17710 [27:17<12:13,  7.69it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12079/17710 [27:18<12:16,  7.65it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12087/17710 [27:19<12:12,  7.67it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12095/17710 [27:20<12:10,  7.68it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12099/17710 [27:20<12:10,  7.68it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12103/17710 [27:21<12:14,  7.63it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12111/17710 [27:22<12:13,  7.63it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12119/17710 [27:23<12:09,  7.66it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12127/17710 [27:24<12:07,  7.67it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12135/17710 [27:25<12:06,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12143/17710 [27:26<12:04,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12149/17710 [27:27<12:04,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12151/17710 [27:27<12:04,  7.67it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12159/17710 [27:28<12:04,  7.66it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12167/17710 [27:29<12:01,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12175/17710 [27:30<12:02,  7.66it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12183/17710 [27:31<11:59,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12191/17710 [27:32<11:58,  7.68it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12199/17710 [27:33<12:00,  7.65it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12199/17710 [27:33<12:00,  7.65it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12207/17710 [27:34<12:08,  7.55it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12215/17710 [27:35<12:04,  7.59it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12223/17710 [27:36<11:59,  7.62it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12231/17710 [27:38<11:58,  7.62it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12239/17710 [27:39<11:58,  7.61it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12247/17710 [27:40<11:57,  7.61it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12249/17710 [27:40<11:57,  7.61it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12255/17710 [27:41<11:53,  7.64it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12263/17710 [27:42<11:51,  7.66it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12271/17710 [27:43<11:55,  7.60it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12279/17710 [27:44<11:57,  7.57it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12287/17710 [27:45<11:54,  7.59it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12295/17710 [27:48<17:20,  5.21it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12299/17710 [27:48<17:19,  5.21it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12303/17710 [27:49<15:50,  5.69it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▋                      | 12311/17710 [27:50<14:38,  6.14it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12319/17710 [27:51<13:45,  6.53it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12327/17710 [27:52<13:09,  6.82it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12335/17710 [27:53<12:41,  7.06it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12343/17710 [27:54<12:22,  7.23it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12349/17710 [27:55<12:21,  7.23it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12351/17710 [27:55<12:07,  7.36it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12359/17710 [27:56<11:59,  7.44it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12367/17710 [27:57<11:51,  7.51it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12375/17710 [27:58<11:44,  7.57it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12383/17710 [27:59<11:39,  7.62it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12391/17710 [28:00<11:39,  7.60it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12399/17710 [28:01<11:35,  7.64it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12399/17710 [28:01<11:35,  7.64it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12407/17710 [28:02<11:33,  7.65it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12415/17710 [28:03<11:31,  7.66it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12423/17710 [28:04<11:27,  7.69it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12431/17710 [28:05<11:25,  7.70it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12439/17710 [28:06<11:23,  7.71it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12447/17710 [28:07<11:23,  7.70it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12449/17710 [28:08<11:23,  7.70it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12455/17710 [28:08<11:20,  7.72it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12463/17710 [28:09<11:20,  7.71it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▍                     | 12471/17710 [28:11<11:20,  7.70it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▍                     | 12479/17710 [28:12<11:19,  7.70it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▍                     | 12487/17710 [28:13<11:23,  7.64it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12495/17710 [28:14<11:23,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12499/17710 [28:14<11:22,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12503/17710 [28:15<11:20,  7.66it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12511/17710 [28:16<11:21,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12519/17710 [28:17<11:20,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12527/17710 [28:18<11:22,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12535/17710 [28:19<11:18,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12543/17710 [28:20<11:15,  7.65it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12549/17710 [28:21<11:14,  7.65it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12551/17710 [28:21<11:17,  7.61it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12559/17710 [28:22<11:14,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12567/17710 [28:23<11:17,  7.59it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12575/17710 [28:24<11:16,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12583/17710 [28:25<11:14,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12591/17710 [28:26<11:13,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12599/17710 [28:27<11:13,  7.59it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12599/17710 [28:27<11:13,  7.59it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12607/17710 [28:28<11:09,  7.62it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12615/17710 [28:29<11:07,  7.63it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12623/17710 [28:30<11:04,  7.65it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12631/17710 [28:32<11:05,  7.63it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12639/17710 [28:33<11:05,  7.62it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12647/17710 [28:34<11:04,  7.62it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12649/17710 [28:34<11:04,  7.62it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12655/17710 [28:35<11:02,  7.63it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▏                    | 12663/17710 [28:36<11:00,  7.64it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▏                    | 12671/17710 [28:37<10:58,  7.65it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12679/17710 [28:38<10:57,  7.65it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12687/17710 [28:39<10:56,  7.66it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12695/17710 [28:40<10:56,  7.64it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12699/17710 [28:41<10:55,  7.64it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12703/17710 [28:41<10:54,  7.65it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12711/17710 [28:42<10:55,  7.63it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12719/17710 [28:43<10:56,  7.60it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12727/17710 [28:44<10:54,  7.62it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12735/17710 [28:45<11:00,  7.53it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12743/17710 [28:47<13:34,  6.10it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12749/17710 [28:48<13:33,  6.10it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12751/17710 [28:48<12:50,  6.44it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12759/17710 [28:49<12:11,  6.77it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12767/17710 [28:50<11:44,  7.02it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12775/17710 [28:51<11:25,  7.20it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12783/17710 [28:52<11:17,  7.27it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12791/17710 [28:53<11:05,  7.39it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12799/17710 [28:54<10:55,  7.50it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12799/17710 [28:55<10:55,  7.50it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12807/17710 [28:55<10:48,  7.56it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12815/17710 [28:57<10:47,  7.56it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12823/17710 [28:58<10:41,  7.62it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▉                    | 12831/17710 [28:59<10:37,  7.65it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▉                    | 12839/17710 [29:00<10:35,  7.67it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12847/17710 [29:01<10:32,  7.69it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12849/17710 [29:01<10:32,  7.69it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12855/17710 [29:02<10:31,  7.68it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12863/17710 [29:03<10:30,  7.69it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12871/17710 [29:04<10:28,  7.70it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12879/17710 [29:05<10:26,  7.71it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12887/17710 [29:06<10:25,  7.71it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12895/17710 [29:07<10:24,  7.70it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12899/17710 [29:08<10:24,  7.70it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12903/17710 [29:08<10:24,  7.70it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12911/17710 [29:09<10:22,  7.71it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12919/17710 [29:10<10:21,  7.71it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12927/17710 [29:11<10:22,  7.68it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12935/17710 [29:12<10:23,  7.66it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12943/17710 [29:13<10:22,  7.66it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12949/17710 [29:14<10:21,  7.66it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12951/17710 [29:14<10:21,  7.66it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12959/17710 [29:15<10:22,  7.64it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12967/17710 [29:16<10:20,  7.64it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12975/17710 [29:17<10:20,  7.63it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12983/17710 [29:18<10:18,  7.65it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12991/17710 [29:19<10:15,  7.66it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12999/17710 [29:20<10:15,  7.65it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12999/17710 [29:21<10:15,  7.65it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 13007/17710 [29:22<10:14,  7.65it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▋                   | 13015/17710 [29:23<10:13,  7.65it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13023/17710 [29:24<10:12,  7.65it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13031/17710 [29:25<10:11,  7.65it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13039/17710 [29:26<10:09,  7.66it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13047/17710 [29:27<10:09,  7.66it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13049/17710 [29:27<10:08,  7.66it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13055/17710 [29:28<10:07,  7.66it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13063/17710 [29:29<10:08,  7.64it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13071/17710 [29:30<10:08,  7.62it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13079/17710 [29:31<10:15,  7.53it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13087/17710 [29:32<10:17,  7.49it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13095/17710 [29:33<10:12,  7.53it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13099/17710 [29:34<10:12,  7.53it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13103/17710 [29:34<10:06,  7.59it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13111/17710 [29:35<10:07,  7.56it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13119/17710 [29:36<10:04,  7.60it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13127/17710 [29:37<10:00,  7.63it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13135/17710 [29:38<09:57,  7.65it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13143/17710 [29:39<09:55,  7.66it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13149/17710 [29:40<09:55,  7.66it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13151/17710 [29:40<09:54,  7.67it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13159/17710 [29:41<09:52,  7.68it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13167/17710 [29:43<09:52,  7.67it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13175/17710 [29:44<09:51,  7.67it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13183/17710 [29:45<09:51,  7.66it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13191/17710 [29:46<09:49,  7.67it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13199/17710 [29:47<11:57,  6.29it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13199/17710 [29:48<11:57,  6.29it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13207/17710 [29:48<11:17,  6.65it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13215/17710 [29:50<10:52,  6.88it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13223/17710 [29:51<10:32,  7.09it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13231/17710 [29:52<10:20,  7.22it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13239/17710 [29:53<10:07,  7.36it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13247/17710 [29:54<09:59,  7.45it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13249/17710 [29:54<09:58,  7.45it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13255/17710 [29:55<09:52,  7.52it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13263/17710 [29:56<09:45,  7.59it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13271/17710 [29:57<09:41,  7.64it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13279/17710 [29:58<09:38,  7.66it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13287/17710 [29:59<09:35,  7.69it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13295/17710 [30:00<09:33,  7.70it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13299/17710 [30:01<09:32,  7.70it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13303/17710 [30:01<09:31,  7.71it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13311/17710 [30:02<09:30,  7.71it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13319/17710 [30:03<09:28,  7.73it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13327/17710 [30:04<09:29,  7.70it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13335/17710 [30:05<09:27,  7.71it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13343/17710 [30:06<09:26,  7.70it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13349/17710 [30:07<09:26,  7.70it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13351/17710 [30:07<09:25,  7.71it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13359/17710 [30:08<09:24,  7.70it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13367/17710 [30:09<09:28,  7.64it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13375/17710 [30:10<09:28,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13383/17710 [30:11<09:27,  7.63it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13391/17710 [30:12<09:25,  7.63it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13399/17710 [30:14<09:23,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13399/17710 [30:14<09:23,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13407/17710 [30:15<09:24,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13415/17710 [30:16<09:26,  7.59it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13423/17710 [30:17<09:22,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13431/17710 [30:18<09:19,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13439/17710 [30:19<09:21,  7.61it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13447/17710 [30:20<09:19,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13449/17710 [30:20<09:19,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13455/17710 [30:21<09:17,  7.63it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13463/17710 [30:22<09:16,  7.63it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13471/17710 [30:23<09:14,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13479/17710 [30:24<09:15,  7.61it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13487/17710 [30:25<09:14,  7.62it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13495/17710 [30:26<09:11,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13499/17710 [30:27<09:10,  7.65it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13503/17710 [30:27<09:08,  7.66it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13511/17710 [30:28<09:06,  7.68it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13519/17710 [30:29<09:08,  7.64it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13527/17710 [30:30<09:06,  7.66it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13535/17710 [30:31<09:03,  7.67it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13543/17710 [30:32<09:02,  7.68it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▊                 | 13549/17710 [30:33<09:01,  7.68it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▊                 | 13551/17710 [30:33<09:01,  7.68it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13559/17710 [30:34<08:59,  7.70it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13567/17710 [30:35<08:59,  7.68it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13575/17710 [30:37<08:57,  7.69it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13583/17710 [30:38<08:56,  7.70it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13591/17710 [30:39<08:56,  7.68it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13599/17710 [30:40<08:54,  7.68it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13599/17710 [30:40<08:54,  7.68it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13607/17710 [30:41<08:53,  7.70it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13615/17710 [30:42<08:53,  7.67it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13623/17710 [30:43<08:53,  7.66it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13631/17710 [30:44<08:51,  7.68it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13639/17710 [30:45<08:53,  7.63it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13647/17710 [30:47<10:22,  6.52it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13649/17710 [30:47<10:22,  6.52it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13655/17710 [30:48<09:56,  6.80it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13663/17710 [30:49<09:42,  6.94it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13671/17710 [30:50<09:26,  7.13it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13679/17710 [30:51<09:13,  7.28it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13687/17710 [30:52<09:03,  7.40it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13695/17710 [30:53<08:56,  7.49it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13699/17710 [30:54<08:55,  7.49it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13703/17710 [30:54<08:51,  7.53it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▌                | 13711/17710 [30:55<08:46,  7.59it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▌                | 13719/17710 [30:56<08:44,  7.61it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▌                | 13727/17710 [30:57<08:40,  7.65it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▌                | 13735/17710 [30:58<08:37,  7.68it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13743/17710 [30:59<08:35,  7.70it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13749/17710 [31:00<08:34,  7.70it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13751/17710 [31:00<08:32,  7.72it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13759/17710 [31:01<08:30,  7.74it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13767/17710 [31:02<08:30,  7.72it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13775/17710 [31:03<08:33,  7.66it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13783/17710 [31:04<08:34,  7.63it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13791/17710 [31:05<08:33,  7.63it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13799/17710 [31:06<08:36,  7.58it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13799/17710 [31:07<08:36,  7.58it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13807/17710 [31:07<08:35,  7.58it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13815/17710 [31:09<08:31,  7.62it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13823/17710 [31:10<08:27,  7.66it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13831/17710 [31:11<08:24,  7.69it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13839/17710 [31:12<08:23,  7.69it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13847/17710 [31:13<08:23,  7.68it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13849/17710 [31:13<08:22,  7.68it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13855/17710 [31:14<08:21,  7.69it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13863/17710 [31:15<08:18,  7.71it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13871/17710 [31:16<08:19,  7.68it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13879/17710 [31:17<08:20,  7.65it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13887/17710 [31:18<08:18,  7.68it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▎               | 13895/17710 [31:19<08:14,  7.71it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▎               | 13899/17710 [31:20<08:14,  7.71it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▎               | 13903/17710 [31:20<08:14,  7.70it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▎               | 13911/17710 [31:21<08:13,  7.69it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▎               | 13919/17710 [31:22<08:12,  7.69it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13927/17710 [31:23<08:11,  7.70it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13935/17710 [31:24<08:14,  7.63it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13943/17710 [31:25<08:12,  7.64it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13949/17710 [31:26<08:12,  7.64it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13951/17710 [31:26<08:15,  7.58it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13959/17710 [31:27<08:17,  7.54it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13967/17710 [31:28<08:13,  7.58it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13975/17710 [31:29<08:10,  7.61it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13983/17710 [31:30<08:09,  7.61it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13991/17710 [31:32<08:11,  7.57it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13999/17710 [31:33<08:11,  7.56it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13999/17710 [31:33<08:11,  7.56it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 14007/17710 [31:34<08:37,  7.16it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14015/17710 [31:35<08:37,  7.14it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14023/17710 [31:36<08:38,  7.12it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14031/17710 [31:37<08:41,  7.05it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14039/17710 [31:38<08:37,  7.09it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14047/17710 [31:39<08:28,  7.20it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14049/17710 [31:40<08:28,  7.20it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14055/17710 [31:41<08:19,  7.31it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14063/17710 [31:42<08:11,  7.42it/s, loss=nan]Epoch 0 - train:  79%|██████████████████████████████████████████████████████████               | 14071/17710 [31:43<08:05,  7.49it/s, loss=nan]Epoch 0 - train:  79%|██████████████████████████████████████████████████████████               | 14079/17710 [31:44<08:01,  7.54it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14087/17710 [31:45<07:57,  7.59it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14095/17710 [31:46<07:55,  7.60it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14099/17710 [31:47<07:55,  7.60it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14103/17710 [31:47<08:48,  6.82it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14111/17710 [31:48<08:29,  7.06it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14119/17710 [31:49<08:14,  7.26it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14127/17710 [31:50<08:05,  7.38it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14135/17710 [31:51<07:58,  7.47it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14143/17710 [31:52<07:53,  7.53it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14149/17710 [31:53<07:52,  7.53it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14151/17710 [31:53<07:49,  7.58it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14159/17710 [31:54<07:46,  7.61it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14167/17710 [31:55<07:44,  7.64it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14175/17710 [31:57<07:42,  7.64it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14183/17710 [31:58<07:40,  7.65it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14191/17710 [31:59<07:40,  7.65it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14199/17710 [32:00<07:38,  7.65it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14199/17710 [32:00<07:38,  7.65it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14207/17710 [32:01<07:37,  7.65it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14215/17710 [32:02<07:36,  7.66it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14223/17710 [32:03<07:33,  7.69it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14231/17710 [32:04<07:32,  7.68it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14239/17710 [32:05<07:31,  7.70it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14247/17710 [32:06<07:30,  7.69it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14249/17710 [32:06<07:29,  7.69it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▊              | 14255/17710 [32:07<07:31,  7.65it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14263/17710 [32:08<07:29,  7.68it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14271/17710 [32:09<07:27,  7.69it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14279/17710 [32:10<07:30,  7.61it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14287/17710 [32:11<07:34,  7.53it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14295/17710 [32:12<07:32,  7.55it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14299/17710 [32:13<07:31,  7.55it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14303/17710 [32:13<07:28,  7.60it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14311/17710 [32:14<07:26,  7.61it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14319/17710 [32:15<07:27,  7.57it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14327/17710 [32:16<07:26,  7.57it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14335/17710 [32:18<07:24,  7.60it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14343/17710 [32:19<07:21,  7.62it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14349/17710 [32:19<07:20,  7.62it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14351/17710 [32:20<07:19,  7.64it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14359/17710 [32:21<07:17,  7.65it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14367/17710 [32:22<07:17,  7.65it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14375/17710 [32:23<07:18,  7.61it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14383/17710 [32:24<07:16,  7.61it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14391/17710 [32:25<07:15,  7.63it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14399/17710 [32:26<07:12,  7.66it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14399/17710 [32:26<07:12,  7.66it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14407/17710 [32:27<07:12,  7.65it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14415/17710 [32:28<07:09,  7.67it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14423/17710 [32:29<07:08,  7.68it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14431/17710 [32:30<07:06,  7.69it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14439/17710 [32:31<07:06,  7.67it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14447/17710 [32:32<07:06,  7.65it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14449/17710 [32:33<07:06,  7.65it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14455/17710 [32:33<07:05,  7.65it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14463/17710 [32:34<07:04,  7.65it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14471/17710 [32:35<07:05,  7.61it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14479/17710 [32:36<07:04,  7.62it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14487/17710 [32:37<07:01,  7.64it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14495/17710 [32:38<06:59,  7.66it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14499/17710 [32:39<06:59,  7.66it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14503/17710 [32:39<06:59,  7.65it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14511/17710 [32:40<06:56,  7.67it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14519/17710 [32:42<06:56,  7.67it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14527/17710 [32:43<06:54,  7.69it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14535/17710 [32:44<06:53,  7.69it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14543/17710 [32:45<06:51,  7.70it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14549/17710 [32:46<06:50,  7.70it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14551/17710 [32:46<06:49,  7.72it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14559/17710 [32:47<08:04,  6.51it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14567/17710 [32:48<07:40,  6.83it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14575/17710 [32:49<07:27,  7.01it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14583/17710 [32:51<07:14,  7.19it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14591/17710 [32:52<07:04,  7.34it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14599/17710 [32:53<06:57,  7.45it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14599/17710 [32:53<06:57,  7.45it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14607/17710 [32:54<06:53,  7.51it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▏            | 14615/17710 [32:55<06:50,  7.54it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14623/17710 [32:56<06:47,  7.57it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14631/17710 [32:57<06:46,  7.58it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14639/17710 [32:58<06:45,  7.58it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14647/17710 [32:59<06:42,  7.60it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14649/17710 [32:59<06:42,  7.60it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14655/17710 [33:00<06:40,  7.63it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14663/17710 [33:01<06:39,  7.63it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14671/17710 [33:02<06:37,  7.64it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14679/17710 [33:03<06:36,  7.64it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14687/17710 [33:04<06:35,  7.65it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14695/17710 [33:05<06:35,  7.62it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14699/17710 [33:06<06:35,  7.62it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14703/17710 [33:06<06:33,  7.64it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14711/17710 [33:07<06:33,  7.63it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14719/17710 [33:08<06:32,  7.63it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14727/17710 [33:09<06:31,  7.62it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14735/17710 [33:10<06:29,  7.64it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14743/17710 [33:11<06:27,  7.67it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14749/17710 [33:12<06:26,  7.67it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14751/17710 [33:12<06:24,  7.70it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14759/17710 [33:13<06:22,  7.71it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14767/17710 [33:15<06:21,  7.70it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▉            | 14775/17710 [33:16<06:20,  7.71it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▉            | 14783/17710 [33:17<06:20,  7.70it/s, loss=nan]Epoch 0 - train:  84%|████████████████████████████████████████████████████████████▉            | 14791/17710 [33:18<06:19,  7.70it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14799/17710 [33:19<06:19,  7.66it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14799/17710 [33:19<06:19,  7.66it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14807/17710 [33:20<06:18,  7.67it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14815/17710 [33:21<06:18,  7.66it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14823/17710 [33:22<06:18,  7.63it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14831/17710 [33:23<06:17,  7.64it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14839/17710 [33:24<06:18,  7.59it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14847/17710 [33:25<06:15,  7.62it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14849/17710 [33:25<06:15,  7.62it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14855/17710 [33:26<06:13,  7.65it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14863/17710 [33:27<06:12,  7.65it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14871/17710 [33:28<06:14,  7.57it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14879/17710 [33:29<06:12,  7.59it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14887/17710 [33:30<06:10,  7.62it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14895/17710 [33:31<06:08,  7.63it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14899/17710 [33:32<06:08,  7.63it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14903/17710 [33:32<06:08,  7.62it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14911/17710 [33:33<06:06,  7.64it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14919/17710 [33:34<06:06,  7.62it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14927/17710 [33:35<06:03,  7.65it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14935/17710 [33:37<06:03,  7.64it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14943/17710 [33:38<06:00,  7.68it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14949/17710 [33:38<05:59,  7.68it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▋           | 14951/17710 [33:39<05:58,  7.70it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▋           | 14959/17710 [33:40<05:56,  7.71it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▋           | 14967/17710 [33:41<05:55,  7.71it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▋           | 14975/17710 [33:42<05:54,  7.71it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14983/17710 [33:43<05:53,  7.71it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14991/17710 [33:44<05:52,  7.71it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14999/17710 [33:45<05:51,  7.72it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14999/17710 [33:45<05:51,  7.72it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 15007/17710 [33:46<05:50,  7.72it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15015/17710 [33:47<06:27,  6.95it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15023/17710 [33:48<06:15,  7.15it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15031/17710 [33:49<06:06,  7.30it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15039/17710 [33:50<06:00,  7.41it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15047/17710 [33:51<05:56,  7.48it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15049/17710 [33:52<05:55,  7.48it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15055/17710 [33:52<05:51,  7.55it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15063/17710 [33:54<05:48,  7.60it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15071/17710 [33:55<05:46,  7.63it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15079/17710 [33:56<05:44,  7.63it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15087/17710 [33:57<05:43,  7.63it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15095/17710 [33:58<05:41,  7.66it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15099/17710 [33:58<05:40,  7.66it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15103/17710 [33:59<05:40,  7.65it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15111/17710 [34:00<05:39,  7.65it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15119/17710 [34:01<05:38,  7.65it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15127/17710 [34:02<05:36,  7.67it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▍          | 15135/17710 [34:03<05:36,  7.66it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15143/17710 [34:04<05:34,  7.68it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15149/17710 [34:05<05:33,  7.68it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15151/17710 [34:05<05:32,  7.69it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15159/17710 [34:06<05:32,  7.68it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15167/17710 [34:07<05:34,  7.60it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15175/17710 [34:08<05:33,  7.61it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15183/17710 [34:09<05:32,  7.61it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15191/17710 [34:10<05:32,  7.57it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15199/17710 [34:11<05:30,  7.60it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15199/17710 [34:11<05:30,  7.60it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15207/17710 [34:12<05:29,  7.59it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15215/17710 [34:13<05:27,  7.62it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15223/17710 [34:14<05:25,  7.64it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15231/17710 [34:16<05:24,  7.64it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15239/17710 [34:17<05:22,  7.65it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15247/17710 [34:18<05:21,  7.66it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15249/17710 [34:18<05:21,  7.66it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15255/17710 [34:19<05:20,  7.66it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15263/17710 [34:20<05:18,  7.68it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15271/17710 [34:21<05:17,  7.67it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15279/17710 [34:22<05:17,  7.66it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15287/17710 [34:23<05:16,  7.66it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15295/17710 [34:24<05:15,  7.65it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15299/17710 [34:25<05:15,  7.65it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15303/17710 [34:25<05:15,  7.63it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15311/17710 [34:26<05:14,  7.63it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████▏         | 15319/17710 [34:27<05:13,  7.63it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15327/17710 [34:28<05:12,  7.62it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15335/17710 [34:29<05:10,  7.64it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15343/17710 [34:30<05:09,  7.65it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15349/17710 [34:31<05:08,  7.65it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15351/17710 [34:31<05:08,  7.65it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15359/17710 [34:32<05:06,  7.66it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15367/17710 [34:33<05:05,  7.68it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15375/17710 [34:34<05:03,  7.69it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15383/17710 [34:35<05:02,  7.70it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15391/17710 [34:36<05:00,  7.71it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15399/17710 [34:37<04:59,  7.73it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15399/17710 [34:38<04:59,  7.73it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15407/17710 [34:38<04:58,  7.73it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15415/17710 [34:39<04:57,  7.72it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15423/17710 [34:41<04:56,  7.72it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15431/17710 [34:42<04:55,  7.72it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15439/17710 [34:43<04:53,  7.73it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15447/17710 [34:44<04:52,  7.74it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15449/17710 [34:44<04:52,  7.74it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15455/17710 [34:45<04:51,  7.72it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15463/17710 [34:46<04:52,  7.68it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15471/17710 [34:53<12:57,  2.88it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15479/17710 [34:54<10:33,  3.52it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15487/17710 [34:55<08:49,  4.20it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15495/17710 [34:56<07:37,  4.85it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15499/17710 [34:56<07:36,  4.85it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15503/17710 [34:57<06:46,  5.43it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15511/17710 [34:58<06:11,  5.92it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15519/17710 [34:59<05:44,  6.36it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15527/17710 [35:00<05:26,  6.70it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15535/17710 [35:01<05:13,  6.93it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15543/17710 [35:02<05:03,  7.13it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15549/17710 [35:03<05:02,  7.13it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15551/17710 [35:03<04:55,  7.30it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15559/17710 [35:04<04:50,  7.40it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15567/17710 [35:05<04:47,  7.46it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15575/17710 [35:06<04:45,  7.47it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15583/17710 [35:07<04:42,  7.53it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15591/17710 [35:08<04:40,  7.56it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15599/17710 [35:09<04:38,  7.59it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15599/17710 [35:10<04:38,  7.59it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15607/17710 [35:10<04:36,  7.60it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15615/17710 [35:11<04:35,  7.61it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15623/17710 [35:13<04:34,  7.61it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15631/17710 [35:14<04:33,  7.61it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15639/17710 [35:15<04:32,  7.61it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15647/17710 [35:16<04:30,  7.64it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15649/17710 [35:16<04:29,  7.64it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15655/17710 [35:17<04:29,  7.63it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15663/17710 [35:18<04:29,  7.61it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15671/17710 [35:19<04:28,  7.60it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15679/17710 [35:20<04:26,  7.61it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15687/17710 [35:21<04:24,  7.64it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15695/17710 [35:22<04:23,  7.66it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15699/17710 [35:23<04:22,  7.66it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15703/17710 [35:23<04:21,  7.66it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15711/17710 [35:24<04:21,  7.63it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15719/17710 [35:25<04:20,  7.65it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15727/17710 [35:26<04:19,  7.64it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15735/17710 [35:27<04:17,  7.66it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15743/17710 [35:28<04:17,  7.63it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15749/17710 [35:29<04:17,  7.63it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15751/17710 [35:29<04:16,  7.64it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15759/17710 [35:30<04:17,  7.58it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15767/17710 [35:31<04:18,  7.53it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15775/17710 [35:33<04:15,  7.57it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15783/17710 [35:34<04:14,  7.56it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15791/17710 [35:35<04:13,  7.56it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15799/17710 [35:36<04:12,  7.57it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15799/17710 [35:36<04:12,  7.57it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15807/17710 [35:37<04:11,  7.56it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15815/17710 [35:38<04:10,  7.56it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15823/17710 [35:39<04:08,  7.59it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15831/17710 [35:40<04:06,  7.63it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15839/17710 [35:41<04:04,  7.66it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15847/17710 [35:42<04:02,  7.68it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15849/17710 [35:42<04:02,  7.68it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▎       | 15855/17710 [35:43<04:00,  7.70it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15863/17710 [35:44<03:59,  7.72it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15871/17710 [35:45<03:57,  7.73it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15879/17710 [35:50<08:16,  3.69it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15885/17710 [35:53<09:47,  3.11it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15893/17710 [35:54<07:58,  3.80it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15899/17710 [35:55<07:56,  3.80it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15901/17710 [35:55<06:43,  4.48it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15908/17710 [35:56<06:07,  4.91it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15915/17710 [35:57<05:35,  5.34it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15923/17710 [35:58<05:06,  5.82it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15931/17710 [35:59<04:44,  6.26it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15939/17710 [36:00<04:27,  6.61it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15947/17710 [36:01<04:15,  6.91it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15949/17710 [36:02<04:14,  6.91it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15955/17710 [36:02<04:05,  7.14it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15963/17710 [36:03<03:59,  7.28it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15971/17710 [36:04<03:55,  7.38it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15979/17710 [36:05<03:52,  7.44it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15987/17710 [36:07<03:49,  7.50it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15995/17710 [36:08<03:47,  7.53it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15999/17710 [36:08<03:47,  7.53it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 16003/17710 [36:09<03:46,  7.54it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 16011/17710 [36:10<03:44,  7.57it/s, loss=nan]Epoch 0 - train:  90%|██████████████████████████████████████████████████████████████████       | 16019/17710 [36:11<03:44,  7.54it/s, loss=nan]Epoch 0 - train:  90%|██████████████████████████████████████████████████████████████████       | 16027/17710 [36:12<03:42,  7.57it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████       | 16035/17710 [36:13<03:39,  7.62it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16043/17710 [36:14<03:38,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16049/17710 [36:15<03:37,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16051/17710 [36:15<03:37,  7.62it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16059/17710 [36:16<03:36,  7.63it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16067/17710 [36:17<03:35,  7.63it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16075/17710 [36:18<03:33,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16083/17710 [36:19<03:32,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16091/17710 [36:20<03:31,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16099/17710 [36:21<03:30,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16099/17710 [36:21<03:30,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16107/17710 [36:22<03:29,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16115/17710 [36:23<03:28,  7.66it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16123/17710 [36:24<03:26,  7.67it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16131/17710 [36:25<03:26,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16139/17710 [36:26<03:25,  7.64it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16147/17710 [36:27<03:24,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16149/17710 [36:28<03:23,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16155/17710 [36:29<03:23,  7.63it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16163/17710 [36:30<03:22,  7.63it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16171/17710 [36:31<03:21,  7.65it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16179/17710 [36:32<03:20,  7.63it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16187/17710 [36:33<03:18,  7.66it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▊      | 16195/17710 [36:34<03:17,  7.66it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▊      | 16199/17710 [36:34<03:17,  7.66it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▊      | 16203/17710 [36:35<03:16,  7.67it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▊      | 16211/17710 [36:36<03:15,  7.68it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▊      | 16219/17710 [36:37<03:13,  7.69it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16227/17710 [36:38<03:12,  7.70it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16235/17710 [36:39<03:11,  7.68it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16243/17710 [36:40<03:10,  7.69it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16249/17710 [36:41<03:10,  7.69it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16251/17710 [36:41<03:09,  7.68it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16259/17710 [36:42<03:08,  7.71it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16267/17710 [36:43<03:06,  7.72it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16275/17710 [36:44<03:05,  7.73it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16283/17710 [36:45<03:04,  7.73it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16291/17710 [36:46<03:13,  7.33it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16299/17710 [36:47<03:13,  7.30it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16299/17710 [36:48<03:13,  7.30it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16307/17710 [36:49<03:08,  7.44it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16315/17710 [36:50<03:07,  7.43it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16323/17710 [36:51<03:04,  7.50it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16331/17710 [36:52<03:02,  7.54it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16339/17710 [36:53<03:00,  7.59it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16347/17710 [36:54<02:59,  7.61it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16349/17710 [36:54<02:58,  7.61it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16355/17710 [36:55<02:57,  7.64it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16363/17710 [36:56<02:55,  7.66it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16371/17710 [36:57<02:55,  7.63it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▌     | 16379/17710 [36:58<02:54,  7.64it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16387/17710 [36:59<02:52,  7.65it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16395/17710 [37:00<02:51,  7.67it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16399/17710 [37:01<02:50,  7.67it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16403/17710 [37:01<02:51,  7.62it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16411/17710 [37:02<02:50,  7.62it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16419/17710 [37:03<02:49,  7.63it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16427/17710 [37:04<02:48,  7.62it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16435/17710 [37:05<02:47,  7.60it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16443/17710 [37:06<02:45,  7.63it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16449/17710 [37:07<02:45,  7.63it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16451/17710 [37:07<02:44,  7.64it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16459/17710 [37:08<02:43,  7.66it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16467/17710 [37:09<02:42,  7.66it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16475/17710 [37:10<02:40,  7.67it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16483/17710 [37:12<02:39,  7.68it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16491/17710 [37:13<02:38,  7.68it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16499/17710 [37:14<02:37,  7.69it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16499/17710 [37:14<02:37,  7.69it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16507/17710 [37:15<02:36,  7.68it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16515/17710 [37:16<02:36,  7.66it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16523/17710 [37:17<02:34,  7.66it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16531/17710 [37:18<02:33,  7.66it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16539/17710 [37:19<02:32,  7.66it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16547/17710 [37:20<02:31,  7.67it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16549/17710 [37:20<02:31,  7.67it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16555/17710 [37:21<02:30,  7.66it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16563/17710 [37:22<02:29,  7.67it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16571/17710 [37:23<02:28,  7.68it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16579/17710 [37:24<02:27,  7.66it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16587/17710 [37:25<02:27,  7.63it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16595/17710 [37:26<02:25,  7.65it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16599/17710 [37:27<02:25,  7.65it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16603/17710 [37:27<02:25,  7.63it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16611/17710 [37:28<02:26,  7.52it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16619/17710 [37:29<02:24,  7.57it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16627/17710 [37:30<02:22,  7.60it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16635/17710 [37:31<02:21,  7.60it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16643/17710 [37:32<02:20,  7.62it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16649/17710 [37:33<02:19,  7.62it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16651/17710 [37:34<02:19,  7.61it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16659/17710 [37:35<02:17,  7.63it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16667/17710 [37:36<02:16,  7.64it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16675/17710 [37:37<02:15,  7.62it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16683/17710 [37:38<02:15,  7.56it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16691/17710 [37:39<02:14,  7.56it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16699/17710 [37:40<02:13,  7.58it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16699/17710 [37:40<02:13,  7.58it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16707/17710 [37:41<02:12,  7.59it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16715/17710 [37:42<02:10,  7.62it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16723/17710 [37:43<02:09,  7.61it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16731/17710 [37:44<02:11,  7.44it/s, loss=nan]Epoch 0 - train:  95%|████████████████████████████████████████████████████████████████████▉    | 16739/17710 [37:45<02:09,  7.50it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16747/17710 [37:46<02:10,  7.41it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16749/17710 [37:47<02:09,  7.41it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16755/17710 [37:47<02:11,  7.25it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16763/17710 [37:49<02:09,  7.31it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16771/17710 [37:50<02:06,  7.40it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16779/17710 [37:51<02:05,  7.45it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16787/17710 [37:52<02:03,  7.49it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16795/17710 [37:53<02:01,  7.54it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16799/17710 [37:53<02:00,  7.54it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16803/17710 [37:54<01:59,  7.56it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16811/17710 [37:55<01:59,  7.54it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16819/17710 [37:56<01:57,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16827/17710 [37:57<01:56,  7.56it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16835/17710 [37:58<01:55,  7.55it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16843/17710 [37:59<01:54,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16849/17710 [38:00<01:53,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16851/17710 [38:00<01:53,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16859/17710 [38:01<01:52,  7.55it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16867/17710 [38:02<01:51,  7.55it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16875/17710 [38:03<01:50,  7.55it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16883/17710 [38:04<01:49,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16891/17710 [38:05<01:48,  7.58it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16899/17710 [38:07<01:48,  7.48it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16899/17710 [38:07<01:48,  7.48it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16907/17710 [38:08<01:47,  7.46it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▋   | 16915/17710 [38:09<01:45,  7.51it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16923/17710 [38:10<01:44,  7.54it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16931/17710 [38:11<01:42,  7.56it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16939/17710 [38:12<01:42,  7.50it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16947/17710 [38:13<01:41,  7.50it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16949/17710 [38:13<01:41,  7.50it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16955/17710 [38:14<01:40,  7.50it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16963/17710 [38:15<01:39,  7.52it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16971/17710 [38:16<01:38,  7.51it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16979/17710 [38:17<01:36,  7.55it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16987/17710 [38:18<01:35,  7.55it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16995/17710 [38:19<01:34,  7.57it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16999/17710 [38:20<01:33,  7.57it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 17003/17710 [38:20<01:33,  7.53it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 17011/17710 [38:21<01:32,  7.54it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17019/17710 [38:22<01:31,  7.55it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17027/17710 [38:23<01:30,  7.56it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17035/17710 [38:25<01:29,  7.56it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17043/17710 [38:26<01:28,  7.57it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17049/17710 [38:27<01:27,  7.57it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17051/17710 [38:27<01:27,  7.55it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17059/17710 [38:28<01:25,  7.58it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17067/17710 [38:29<01:24,  7.60it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▍  | 17075/17710 [38:30<01:23,  7.62it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▍  | 17083/17710 [38:31<01:22,  7.60it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▍  | 17091/17710 [38:32<01:21,  7.60it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▍  | 17099/17710 [38:33<01:20,  7.57it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▍  | 17099/17710 [38:33<01:20,  7.57it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17107/17710 [38:34<01:19,  7.57it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17115/17710 [38:35<01:18,  7.61it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17123/17710 [38:36<01:16,  7.63it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17131/17710 [38:37<01:15,  7.64it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17139/17710 [38:38<01:14,  7.63it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17147/17710 [38:39<01:13,  7.64it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17149/17710 [38:40<01:13,  7.64it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17155/17710 [38:40<01:12,  7.62it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17163/17710 [38:41<01:11,  7.63it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17171/17710 [38:42<01:10,  7.60it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17179/17710 [38:43<01:09,  7.60it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17187/17710 [38:45<01:08,  7.61it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17195/17710 [38:46<01:08,  7.53it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17199/17710 [38:46<01:07,  7.53it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17203/17710 [38:47<01:09,  7.31it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17211/17710 [38:48<01:07,  7.41it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17219/17710 [38:49<01:05,  7.49it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17227/17710 [38:50<01:03,  7.55it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17235/17710 [38:51<01:02,  7.54it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17243/17710 [38:52<01:01,  7.57it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17249/17710 [38:53<01:00,  7.57it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17251/17710 [38:53<01:00,  7.60it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████▏ | 17259/17710 [38:54<00:59,  7.62it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████▏ | 17267/17710 [38:55<00:58,  7.63it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▏ | 17275/17710 [38:56<00:57,  7.63it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▏ | 17283/17710 [38:57<00:55,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17291/17710 [38:58<00:54,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17299/17710 [38:59<00:53,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17299/17710 [38:59<00:53,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17307/17710 [39:00<00:52,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17315/17710 [39:01<00:51,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17323/17710 [39:02<00:50,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17331/17710 [39:04<00:49,  7.66it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17339/17710 [39:05<00:48,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17347/17710 [39:06<00:47,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17349/17710 [39:06<00:47,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17355/17710 [39:07<00:46,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17363/17710 [39:08<00:45,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17371/17710 [39:09<00:44,  7.66it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17379/17710 [39:10<00:43,  7.67it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17387/17710 [39:11<00:42,  7.67it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17395/17710 [39:12<00:40,  7.69it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17399/17710 [39:13<00:40,  7.69it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17403/17710 [39:13<00:39,  7.69it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17411/17710 [39:14<00:39,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17419/17710 [39:15<00:38,  7.64it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17427/17710 [39:16<00:37,  7.65it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17435/17710 [39:17<00:38,  7.19it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▉ | 17443/17710 [39:18<00:37,  7.15it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17449/17710 [39:19<00:36,  7.15it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17451/17710 [39:20<00:35,  7.26it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17459/17710 [39:21<00:34,  7.36it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17467/17710 [39:22<00:33,  7.26it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17475/17710 [39:23<00:32,  7.22it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17483/17710 [39:24<00:31,  7.29it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17491/17710 [39:25<00:30,  7.23it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17499/17710 [39:26<00:28,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17499/17710 [39:26<00:28,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17507/17710 [39:27<00:27,  7.45it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17515/17710 [39:28<00:25,  7.52it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17523/17710 [39:29<00:24,  7.55it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17531/17710 [39:30<00:23,  7.58it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17539/17710 [39:31<00:22,  7.55it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17547/17710 [39:32<00:21,  7.60it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17549/17710 [39:33<00:21,  7.60it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17555/17710 [39:33<00:20,  7.66it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17563/17710 [39:34<00:19,  7.68it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17571/17710 [39:35<00:18,  7.66it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17579/17710 [39:37<00:17,  7.64it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17587/17710 [39:38<00:16,  7.63it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17595/17710 [39:39<00:15,  7.62it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17599/17710 [39:39<00:14,  7.62it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17603/17710 [39:40<00:14,  7.63it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17611/17710 [39:41<00:12,  7.62it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17619/17710 [39:42<00:12,  7.48it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17627/17710 [39:43<00:11,  7.53it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17635/17710 [39:44<00:10,  7.49it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17643/17710 [39:45<00:08,  7.49it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17649/17710 [39:46<00:08,  7.49it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17651/17710 [39:46<00:08,  7.32it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17659/17710 [39:48<00:07,  6.88it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17667/17710 [39:49<00:06,  7.10it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17675/17710 [39:50<00:04,  7.26it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17683/17710 [39:51<00:03,  7.36it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17691/17710 [39:52<00:02,  7.44it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17699/17710 [39:53<00:01,  7.47it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17699/17710 [39:53<00:01,  7.47it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17707/17710 [39:54<00:00,  7.28it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17709/17710 [39:54<00:00,  7.28it/s, loss=nan]Epoch 0 - train: 100%|█████████████████████████████████████████████████████████████████████████| 17710/17710 [39:54<00:00,  7.39it/s, loss=nan]
训练损失: nan
Epoch 0 - validation:   0%|                                                                                            | 0/782 [00:00<?, ?it/s]Epoch 0 - validation:   0%|                                                                                    | 1/782 [00:01<16:43,  1.28s/it]Epoch 0 - validation:   1%|▊                                                                                   | 7/782 [00:02<03:40,  3.51it/s]Epoch 0 - validation:   2%|█▍                                                                                 | 13/782 [00:03<02:56,  4.36it/s]Epoch 0 - validation:   2%|██                                                                                 | 19/782 [00:04<02:34,  4.94it/s]Epoch 0 - validation:   3%|██▋                                                                                | 25/782 [00:05<02:23,  5.28it/s]Epoch 0 - validation:   4%|███▎                                                                               | 31/782 [00:06<02:16,  5.49it/s]Epoch 0 - validation:   5%|███▉                                                                               | 37/782 [00:07<02:12,  5.62it/s]Epoch 0 - validation:   5%|████▌                                                                              | 43/782 [00:08<02:09,  5.71it/s]Epoch 0 - validation:   6%|█████▏                                                                             | 49/782 [00:09<02:07,  5.76it/s]Epoch 0 - validation:   6%|████▌                                                                    | 49/782 [00:09<02:07,  5.76it/s, loss=137]Epoch 0 - validation:   7%|█████▏                                                                   | 55/782 [00:10<02:05,  5.80it/s, loss=137]Epoch 0 - validation:   8%|█████▋                                                                   | 61/782 [00:11<02:03,  5.82it/s, loss=137]Epoch 0 - validation:   9%|██████▎                                                                  | 67/782 [00:12<02:02,  5.85it/s, loss=137]Epoch 0 - validation:   9%|██████▊                                                                  | 73/782 [00:13<02:00,  5.86it/s, loss=137]Epoch 0 - validation:  10%|███████▎                                                                 | 79/782 [00:14<01:59,  5.88it/s, loss=137]Epoch 0 - validation:  11%|███████▉                                                                 | 85/782 [00:15<01:58,  5.86it/s, loss=137]Epoch 0 - validation:  12%|████████▍                                                                | 91/782 [00:16<01:57,  5.87it/s, loss=137]Epoch 0 - validation:  12%|█████████                                                                | 97/782 [00:17<01:56,  5.88it/s, loss=137]Epoch 0 - validation:  13%|█████████▏                                                               | 99/782 [00:18<01:56,  5.88it/s, loss=137]Epoch 0 - validation:  13%|█████████▍                                                              | 103/782 [00:18<01:55,  5.89it/s, loss=137]Epoch 0 - validation:  14%|██████████                                                              | 109/782 [00:19<01:54,  5.90it/s, loss=137]Epoch 0 - validation:  15%|██████████▌                                                             | 115/782 [00:20<01:53,  5.89it/s, loss=137]Epoch 0 - validation:  15%|███████████▏                                                            | 121/782 [00:21<01:53,  5.83it/s, loss=137]Epoch 0 - validation:  16%|███████████▋                                                            | 127/782 [00:22<01:53,  5.80it/s, loss=137]Epoch 0 - validation:  17%|████████████▏                                                           | 133/782 [00:23<01:51,  5.83it/s, loss=137]Epoch 0 - validation:  18%|████████████▊                                                           | 139/782 [00:24<01:49,  5.85it/s, loss=137]Epoch 0 - validation:  19%|█████████████▎                                                          | 145/782 [00:25<01:48,  5.86it/s, loss=137]Epoch 0 - validation:  19%|█████████████▋                                                          | 149/782 [00:26<01:48,  5.86it/s, loss=137]Epoch 0 - validation:  19%|█████████████▉                                                          | 151/782 [00:26<01:47,  5.87it/s, loss=137]Epoch 0 - validation:  20%|██████████████▍                                                         | 157/782 [00:27<01:46,  5.88it/s, loss=137]Epoch 0 - validation:  21%|███████████████                                                         | 163/782 [00:28<01:45,  5.88it/s, loss=137]Epoch 0 - validation:  22%|███████████████▌                                                        | 169/782 [00:29<01:44,  5.87it/s, loss=137]Epoch 0 - validation:  22%|████████████████                                                        | 175/782 [00:30<01:43,  5.88it/s, loss=137]Epoch 0 - validation:  23%|████████████████▋                                                       | 181/782 [00:31<01:42,  5.89it/s, loss=137]Epoch 0 - validation:  24%|█████████████████▏                                                      | 187/782 [00:32<01:40,  5.89it/s, loss=137]Epoch 0 - validation:  25%|█████████████████▊                                                      | 193/782 [00:34<01:39,  5.90it/s, loss=137]Epoch 0 - validation:  25%|██████████████████▎                                                     | 199/782 [00:35<01:38,  5.90it/s, loss=137]Epoch 0 - validation:  25%|██████████████████▎                                                     | 199/782 [00:35<01:38,  5.90it/s, loss=137]Epoch 0 - validation:  26%|██████████████████▊                                                     | 205/782 [00:36<01:37,  5.90it/s, loss=137]Epoch 0 - validation:  27%|███████████████████▍                                                    | 211/782 [00:37<01:36,  5.90it/s, loss=137]Epoch 0 - validation:  28%|███████████████████▉                                                    | 217/782 [00:38<01:35,  5.90it/s, loss=137]Epoch 0 - validation:  29%|████████████████████▌                                                   | 223/782 [00:39<01:34,  5.91it/s, loss=137]Epoch 0 - validation:  29%|█████████████████████                                                   | 229/782 [00:40<01:33,  5.91it/s, loss=137]Epoch 0 - validation:  30%|█████████████████████▋                                                  | 235/782 [00:41<01:32,  5.91it/s, loss=137]Epoch 0 - validation:  31%|██████████████████████▏                                                 | 241/782 [00:42<01:31,  5.91it/s, loss=137]Epoch 0 - validation:  32%|██████████████████████▋                                                 | 247/782 [00:43<01:30,  5.91it/s, loss=137]Epoch 0 - validation:  32%|██████████████████████▉                                                 | 249/782 [00:43<01:30,  5.91it/s, loss=137]Epoch 0 - validation:  32%|███████████████████████▎                                                | 253/782 [00:44<01:29,  5.90it/s, loss=137]Epoch 0 - validation:  33%|███████████████████████▊                                                | 259/782 [00:45<01:28,  5.90it/s, loss=137]Epoch 0 - validation:  34%|████████████████████████▍                                               | 265/782 [00:46<01:27,  5.89it/s, loss=137]Epoch 0 - validation:  35%|████████████████████████▉                                               | 271/782 [00:47<01:26,  5.89it/s, loss=137]Epoch 0 - validation:  35%|█████████████████████████▌                                              | 277/782 [00:48<01:25,  5.90it/s, loss=137]Epoch 0 - validation:  36%|██████████████████████████                                              | 283/782 [00:49<01:24,  5.88it/s, loss=137]Epoch 0 - validation:  37%|██████████████████████████▌                                             | 289/782 [00:50<01:23,  5.87it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▏                                            | 295/782 [00:51<01:22,  5.88it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▌                                            | 299/782 [01:00<01:22,  5.88it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▋                                            | 301/782 [01:00<04:34,  1.75it/s, loss=137]Epoch 0 - validation:  39%|████████████████████████████▏                                           | 306/782 [01:01<03:47,  2.09it/s, loss=137]Epoch 0 - validation:  40%|████████████████████████████▋                                           | 312/782 [01:02<02:59,  2.62it/s, loss=137]Epoch 0 - validation:  41%|█████████████████████████████▎                                          | 318/782 [01:03<02:26,  3.16it/s, loss=137]Epoch 0 - validation:  41%|█████████████████████████████▊                                          | 324/782 [01:04<02:04,  3.68it/s, loss=137]Epoch 0 - validation:  42%|██████████████████████████████▍                                         | 330/782 [01:05<01:48,  4.15it/s, loss=137]Epoch 0 - validation:  43%|██████████████████████████████▉                                         | 336/782 [01:06<01:37,  4.56it/s, loss=137]Epoch 0 - validation:  44%|███████████████████████████████▍                                        | 342/782 [01:07<01:29,  4.90it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████                                        | 348/782 [01:08<01:24,  5.16it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████▏                                       | 349/782 [01:08<01:23,  5.16it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████▌                                       | 354/782 [01:09<01:19,  5.36it/s, loss=137]Epoch 0 - validation:  46%|█████████████████████████████████▏                                      | 360/782 [01:10<01:16,  5.52it/s, loss=137]Epoch 0 - validation:  47%|█████████████████████████████████▋                                      | 366/782 [01:11<01:13,  5.62it/s, loss=137]Epoch 0 - validation:  48%|██████████████████████████████████▎                                     | 372/782 [01:12<01:12,  5.69it/s, loss=137]Epoch 0 - validation:  48%|██████████████████████████████████▊                                     | 378/782 [01:13<01:10,  5.74it/s, loss=137]Epoch 0 - validation:  49%|███████████████████████████████████▎                                    | 384/782 [01:14<01:08,  5.79it/s, loss=137]Epoch 0 - validation:  50%|███████████████████████████████████▉                                    | 390/782 [01:15<01:07,  5.83it/s, loss=137]Epoch 0 - validation:  51%|████████████████████████████████████▍                                   | 396/782 [01:16<01:05,  5.85it/s, loss=137]Epoch 0 - validation:  51%|████████████████████████████████████▋                                   | 399/782 [01:17<01:05,  5.85it/s, loss=137]Epoch 0 - validation:  51%|█████████████████████████████████████                                   | 402/782 [01:17<01:04,  5.87it/s, loss=137]Epoch 0 - validation:  52%|█████████████████████████████████████▌                                  | 408/782 [01:18<01:03,  5.89it/s, loss=137]Epoch 0 - validation:  53%|██████████████████████████████████████                                  | 414/782 [01:19<01:02,  5.91it/s, loss=137]Epoch 0 - validation:  54%|██████████████████████████████████████▋                                 | 420/782 [01:20<01:01,  5.91it/s, loss=137]Epoch 0 - validation:  54%|███████████████████████████████████████▏                                | 426/782 [01:21<01:00,  5.92it/s, loss=137]Epoch 0 - validation:  55%|███████████████████████████████████████▊                                | 432/782 [01:22<00:59,  5.90it/s, loss=137]Epoch 0 - validation:  56%|████████████████████████████████████████▎                               | 438/782 [01:23<00:58,  5.91it/s, loss=137]Epoch 0 - validation:  57%|████████████████████████████████████████▉                               | 444/782 [01:24<00:57,  5.91it/s, loss=137]Epoch 0 - validation:  57%|█████████████████████████████████████████▎                              | 449/782 [01:25<00:56,  5.91it/s, loss=137]Epoch 0 - validation:  58%|█████████████████████████████████████████▍                              | 450/782 [01:25<00:56,  5.91it/s, loss=137]Epoch 0 - validation:  58%|█████████████████████████████████████████▉                              | 456/782 [01:26<00:55,  5.91it/s, loss=137]Epoch 0 - validation:  59%|██████████████████████████████████████████▌                             | 462/782 [01:27<00:54,  5.92it/s, loss=137]Epoch 0 - validation:  60%|███████████████████████████████████████████                             | 468/782 [01:28<00:53,  5.91it/s, loss=137]Epoch 0 - validation:  61%|███████████████████████████████████████████▋                            | 474/782 [01:29<00:52,  5.91it/s, loss=137]Epoch 0 - validation:  61%|████████████████████████████████████████████▏                           | 480/782 [01:30<00:51,  5.92it/s, loss=137]Epoch 0 - validation:  62%|████████████████████████████████████████████▋                           | 486/782 [01:31<00:50,  5.91it/s, loss=137]Epoch 0 - validation:  63%|█████████████████████████████████████████████▎                          | 492/782 [01:32<00:49,  5.91it/s, loss=137]Epoch 0 - validation:  64%|█████████████████████████████████████████████▊                          | 498/782 [01:33<00:48,  5.91it/s, loss=137]Epoch 0 - validation:  64%|█████████████████████████████████████████████▉                          | 499/782 [01:34<00:47,  5.91it/s, loss=137]Epoch 0 - validation:  64%|██████████████████████████████████████████████▍                         | 504/782 [01:34<00:46,  5.92it/s, loss=137]Epoch 0 - validation:  65%|██████████████████████████████████████████████▉                         | 510/782 [01:35<00:45,  5.92it/s, loss=137]Epoch 0 - validation:  66%|███████████████████████████████████████████████▌                        | 516/782 [01:36<00:44,  5.92it/s, loss=137]Epoch 0 - validation:  67%|████████████████████████████████████████████████                        | 522/782 [01:38<00:43,  5.92it/s, loss=137]Epoch 0 - validation:  68%|████████████████████████████████████████████████▌                       | 528/782 [01:39<00:42,  5.91it/s, loss=137]Epoch 0 - validation:  68%|█████████████████████████████████████████████████▏                      | 534/782 [01:40<00:41,  5.92it/s, loss=137]Epoch 0 - validation:  69%|█████████████████████████████████████████████████▋                      | 540/782 [01:41<00:40,  5.92it/s, loss=137]Epoch 0 - validation:  70%|██████████████████████████████████████████████████▎                     | 546/782 [01:42<00:39,  5.91it/s, loss=137]Epoch 0 - validation:  70%|██████████████████████████████████████████████████▌                     | 549/782 [01:42<00:39,  5.91it/s, loss=137]Epoch 0 - validation:  71%|██████████████████████████████████████████████████▊                     | 552/782 [01:43<00:38,  5.92it/s, loss=137]Epoch 0 - validation:  71%|███████████████████████████████████████████████████▍                    | 558/782 [01:44<00:37,  5.91it/s, loss=137]Epoch 0 - validation:  72%|███████████████████████████████████████████████████▉                    | 564/782 [01:45<00:36,  5.92it/s, loss=137]Epoch 0 - validation:  73%|████████████████████████████████████████████████████▍                   | 570/782 [01:46<00:35,  5.92it/s, loss=137]Epoch 0 - validation:  74%|█████████████████████████████████████████████████████                   | 576/782 [01:47<00:34,  5.91it/s, loss=137]Epoch 0 - validation:  74%|█████████████████████████████████████████████████████▌                  | 582/782 [01:48<00:33,  5.91it/s, loss=137]Epoch 0 - validation:  75%|██████████████████████████████████████████████████████▏                 | 588/782 [01:49<00:32,  5.91it/s, loss=137]Epoch 0 - validation:  76%|██████████████████████████████████████████████████████▋                 | 594/782 [01:50<00:31,  5.91it/s, loss=137]Epoch 0 - validation:  77%|███████████████████████████████████████████████████████▏                | 599/782 [01:51<00:30,  5.91it/s, loss=137]Epoch 0 - validation:  77%|███████████████████████████████████████████████████████▏                | 600/782 [01:51<00:30,  5.90it/s, loss=137]Epoch 0 - validation:  77%|███████████████████████████████████████████████████████▊                | 606/782 [01:53<00:36,  4.76it/s, loss=137]Epoch 0 - validation:  78%|████████████████████████████████████████████████████████▎               | 612/782 [01:54<00:35,  4.74it/s, loss=137]Epoch 0 - validation:  79%|████████████████████████████████████████████████████████▉               | 618/782 [01:55<00:32,  5.03it/s, loss=137]Epoch 0 - validation:  80%|█████████████████████████████████████████████████████████▍              | 624/782 [01:56<00:30,  5.14it/s, loss=137]Epoch 0 - validation:  81%|██████████████████████████████████████████████████████████              | 630/782 [01:57<00:29,  5.23it/s, loss=137]Epoch 0 - validation:  81%|██████████████████████████████████████████████████████████▌             | 636/782 [01:58<00:26,  5.42it/s, loss=137]Epoch 0 - validation:  82%|███████████████████████████████████████████████████████████             | 642/782 [01:59<00:25,  5.56it/s, loss=137]Epoch 0 - validation:  83%|███████████████████████████████████████████████████████████▋            | 648/782 [02:00<00:23,  5.65it/s, loss=137]Epoch 0 - validation:  83%|███████████████████████████████████████████████████████████▊            | 649/782 [02:00<00:23,  5.65it/s, loss=137]Epoch 0 - validation:  84%|████████████████████████████████████████████████████████████▏           | 654/782 [02:01<00:22,  5.72it/s, loss=137]Epoch 0 - validation:  84%|████████████████████████████████████████████████████████████▊           | 660/782 [02:02<00:21,  5.77it/s, loss=137]Epoch 0 - validation:  85%|█████████████████████████████████████████████████████████████▎          | 666/782 [02:03<00:19,  5.81it/s, loss=137]Epoch 0 - validation:  86%|█████████████████████████████████████████████████████████████▊          | 672/782 [02:04<00:18,  5.83it/s, loss=137]Epoch 0 - validation:  87%|██████████████████████████████████████████████████████████████▍         | 678/782 [02:05<00:17,  5.85it/s, loss=137]Epoch 0 - validation:  87%|██████████████████████████████████████████████████████████████▉         | 684/782 [02:06<00:16,  5.86it/s, loss=137]Epoch 0 - validation:  88%|███████████████████████████████████████████████████████████████▌        | 690/782 [02:07<00:15,  5.87it/s, loss=137]Epoch 0 - validation:  89%|████████████████████████████████████████████████████████████████        | 696/782 [02:08<00:14,  5.88it/s, loss=137]Epoch 0 - validation:  89%|████████████████████████████████████████████████████████████████▎       | 699/782 [02:09<00:14,  5.88it/s, loss=137]Epoch 0 - validation:  90%|████████████████████████████████████████████████████████████████▋       | 702/782 [02:09<00:13,  5.88it/s, loss=137]Epoch 0 - validation:  91%|█████████████████████████████████████████████████████████████████▏      | 708/782 [02:10<00:12,  5.87it/s, loss=137]Epoch 0 - validation:  91%|█████████████████████████████████████████████████████████████████▋      | 714/782 [02:11<00:11,  5.88it/s, loss=137]Epoch 0 - validation:  92%|██████████████████████████████████████████████████████████████████▎     | 720/782 [02:12<00:10,  5.88it/s, loss=137]Epoch 0 - validation:  93%|██████████████████████████████████████████████████████████████████▊     | 726/782 [02:13<00:09,  5.88it/s, loss=137]Epoch 0 - validation:  94%|███████████████████████████████████████████████████████████████████▍    | 732/782 [02:14<00:08,  5.88it/s, loss=137]Epoch 0 - validation:  94%|███████████████████████████████████████████████████████████████████▉    | 738/782 [02:15<00:07,  5.89it/s, loss=137]Epoch 0 - validation:  95%|████████████████████████████████████████████████████████████████████▌   | 744/782 [02:16<00:06,  5.90it/s, loss=137]Epoch 0 - validation:  96%|████████████████████████████████████████████████████████████████████▉   | 749/782 [02:17<00:05,  5.90it/s, loss=137]Epoch 0 - validation:  96%|█████████████████████████████████████████████████████████████████████   | 750/782 [02:17<00:05,  5.90it/s, loss=137]Epoch 0 - validation:  97%|█████████████████████████████████████████████████████████████████████▌  | 756/782 [02:18<00:04,  5.90it/s, loss=137]Epoch 0 - validation:  97%|██████████████████████████████████████████████████████████████████████▏ | 762/782 [02:19<00:03,  5.89it/s, loss=137]Epoch 0 - validation:  98%|██████████████████████████████████████████████████████████████████████▋ | 768/782 [02:20<00:02,  5.88it/s, loss=137]Epoch 0 - validation:  99%|███████████████████████████████████████████████████████████████████████▎| 774/782 [02:21<00:01,  5.89it/s, loss=137]Epoch 0 - validation: 100%|███████████████████████████████████████████████████████████████████████▊| 780/782 [02:22<00:00,  5.91it/s, loss=137]Epoch 0 - validation: 100%|███████████████████████████████████████████████████████████████████████▉| 781/782 [02:23<00:00,  5.91it/s, loss=137]Epoch 0 - validation: 100%|████████████████████████████████████████████████████████████████████████| 782/782 [02:23<00:00,  5.45it/s, loss=137]
验证损失: 136.8897
Epoch 0 - evaluation:   0%|                                                                                            | 0/834 [00:00<?, ?it/s]Epoch 0 - evaluation:   0%|                                                                                            | 0/834 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "train_transformer.py", line 379, in <module>
    scores_val = evaluate_metrics(model, dict_dataloader_val, text_field, e, device)
  File "train_transformer.py", line 76, in evaluate_metrics
    for it, ((detections, _), caps_gt) in enumerate(iter(dataloader)):
ValueError: too many values to unpack (expected 2)
使用设备: cuda
实验参数: exp_name=fsgr_fix, batch_size=32, xe_base_lr=0.0002
加载已有词汇表...
词汇表大小: 10201
===Missing keys: ['visual.prompt_embeddings', 'visual.deep_prompt_embeddings', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.6.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.7.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.8.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.9.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.10.S_Adapter.D_fc2.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc1.bias', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.weight', 'visual.transformer.resblocks.11.S_Adapter.D_fc2.bias', 'visual.prompt_proj.weight', 'visual.prompt_proj.bias', 'visual.prompt_norm.weight', 'visual.prompt_norm.bias', 'transformer.resblocks.0.S_Adapter.D_fc1.weight', 'transformer.resblocks.0.S_Adapter.D_fc1.bias', 'transformer.resblocks.0.S_Adapter.D_fc2.weight', 'transformer.resblocks.0.S_Adapter.D_fc2.bias', 'transformer.resblocks.1.S_Adapter.D_fc1.weight', 'transformer.resblocks.1.S_Adapter.D_fc1.bias', 'transformer.resblocks.1.S_Adapter.D_fc2.weight', 'transformer.resblocks.1.S_Adapter.D_fc2.bias', 'transformer.resblocks.2.S_Adapter.D_fc1.weight', 'transformer.resblocks.2.S_Adapter.D_fc1.bias', 'transformer.resblocks.2.S_Adapter.D_fc2.weight', 'transformer.resblocks.2.S_Adapter.D_fc2.bias', 'transformer.resblocks.3.S_Adapter.D_fc1.weight', 'transformer.resblocks.3.S_Adapter.D_fc1.bias', 'transformer.resblocks.3.S_Adapter.D_fc2.weight', 'transformer.resblocks.3.S_Adapter.D_fc2.bias', 'transformer.resblocks.4.S_Adapter.D_fc1.weight', 'transformer.resblocks.4.S_Adapter.D_fc1.bias', 'transformer.resblocks.4.S_Adapter.D_fc2.weight', 'transformer.resblocks.4.S_Adapter.D_fc2.bias', 'transformer.resblocks.5.S_Adapter.D_fc1.weight', 'transformer.resblocks.5.S_Adapter.D_fc1.bias', 'transformer.resblocks.5.S_Adapter.D_fc2.weight', 'transformer.resblocks.5.S_Adapter.D_fc2.bias', 'transformer.resblocks.6.S_Adapter.D_fc1.weight', 'transformer.resblocks.6.S_Adapter.D_fc1.bias', 'transformer.resblocks.6.S_Adapter.D_fc2.weight', 'transformer.resblocks.6.S_Adapter.D_fc2.bias', 'transformer.resblocks.7.S_Adapter.D_fc1.weight', 'transformer.resblocks.7.S_Adapter.D_fc1.bias', 'transformer.resblocks.7.S_Adapter.D_fc2.weight', 'transformer.resblocks.7.S_Adapter.D_fc2.bias', 'transformer.resblocks.8.S_Adapter.D_fc1.weight', 'transformer.resblocks.8.S_Adapter.D_fc1.bias', 'transformer.resblocks.8.S_Adapter.D_fc2.weight', 'transformer.resblocks.8.S_Adapter.D_fc2.bias', 'transformer.resblocks.9.S_Adapter.D_fc1.weight', 'transformer.resblocks.9.S_Adapter.D_fc1.bias', 'transformer.resblocks.9.S_Adapter.D_fc2.weight', 'transformer.resblocks.9.S_Adapter.D_fc2.bias', 'transformer.resblocks.10.S_Adapter.D_fc1.weight', 'transformer.resblocks.10.S_Adapter.D_fc1.bias', 'transformer.resblocks.10.S_Adapter.D_fc2.weight', 'transformer.resblocks.10.S_Adapter.D_fc2.bias', 'transformer.resblocks.11.S_Adapter.D_fc1.weight', 'transformer.resblocks.11.S_Adapter.D_fc1.bias', 'transformer.resblocks.11.S_Adapter.D_fc2.weight', 'transformer.resblocks.11.S_Adapter.D_fc2.bias']
===Unexpected keys: []
load pretrained weights!
开始训练...

===== Epoch 0 =====
Backbone lr = 0.025000, Dec lr = 0.250000
Epoch 0 - train:   0%|                                                                                               | 0/17710 [00:00<?, ?it/s]Epoch 0 - train:   0%|                                                                                    | 1/17710 [00:10<50:02:36, 10.17s/it]Epoch 0 - train:   0%|                                                                                     | 8/17710 [00:11<5:13:49,  1.06s/it]Epoch 0 - train:   0%|                                                                                    | 16/17710 [00:12<2:29:19,  1.97it/s]Epoch 0 - train:   0%|                                                                                    | 24/17710 [00:13<1:38:00,  3.01it/s]Epoch 0 - train:   0%|▏                                                                                   | 32/17710 [00:14<1:16:07,  3.87it/s]Epoch 0 - train:   0%|▏                                                                                   | 40/17710 [00:15<1:02:56,  4.68it/s]Epoch 0 - train:   0%|▏                                                                                     | 48/17710 [00:16<54:40,  5.38it/s]Epoch 0 - train:   0%|▏                                                                           | 49/17710 [00:16<54:39,  5.38it/s, loss=nan]Epoch 0 - train:   0%|▏                                                                           | 56/17710 [00:17<49:26,  5.95it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 64/17710 [00:18<46:08,  6.37it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 72/17710 [00:19<44:34,  6.59it/s, loss=nan]Epoch 0 - train:   0%|▎                                                                           | 80/17710 [00:20<43:34,  6.74it/s, loss=nan]Epoch 0 - train:   0%|▍                                                                           | 88/17710 [00:22<43:15,  6.79it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                           | 96/17710 [00:23<42:55,  6.84it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                           | 99/17710 [00:23<42:55,  6.84it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 104/17710 [00:24<43:53,  6.68it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 111/17710 [00:25<43:45,  6.70it/s, loss=nan]Epoch 0 - train:   1%|▍                                                                          | 118/17710 [00:26<45:39,  6.42it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 126/17710 [00:27<44:19,  6.61it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 134/17710 [00:29<42:54,  6.83it/s, loss=nan]Epoch 0 - train:   1%|▌                                                                          | 142/17710 [00:30<41:28,  7.06it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 149/17710 [00:31<41:27,  7.06it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 150/17710 [00:31<40:26,  7.24it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 158/17710 [00:32<39:45,  7.36it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 166/17710 [00:33<39:27,  7.41it/s, loss=nan]Epoch 0 - train:   1%|▋                                                                          | 174/17710 [00:34<39:02,  7.49it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 182/17710 [00:35<38:45,  7.54it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 190/17710 [00:36<38:31,  7.58it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 198/17710 [00:37<38:23,  7.60it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 199/17710 [00:37<38:22,  7.60it/s, loss=nan]Epoch 0 - train:   1%|▊                                                                          | 206/17710 [00:38<38:13,  7.63it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 214/17710 [00:39<38:05,  7.65it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 222/17710 [00:40<38:00,  7.67it/s, loss=nan]Epoch 0 - train:   1%|▉                                                                          | 230/17710 [00:41<37:52,  7.69it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 238/17710 [00:42<37:48,  7.70it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 246/17710 [00:43<37:51,  7.69it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 249/17710 [00:44<37:51,  7.69it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 254/17710 [00:45<43:21,  6.71it/s, loss=nan]Epoch 0 - train:   1%|█                                                                          | 262/17710 [00:46<42:11,  6.89it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 270/17710 [00:48<54:50,  5.30it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 276/17710 [00:50<59:07,  4.91it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 282/17710 [00:51<56:28,  5.14it/s, loss=nan]Epoch 0 - train:   2%|█▏                                                                         | 289/17710 [00:52<53:12,  5.46it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 297/17710 [00:53<48:07,  6.03it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 299/17710 [00:53<48:06,  6.03it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 305/17710 [00:54<45:02,  6.44it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 313/17710 [00:55<42:49,  6.77it/s, loss=nan]Epoch 0 - train:   2%|█▎                                                                         | 321/17710 [00:56<41:13,  7.03it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 329/17710 [00:57<40:03,  7.23it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 337/17710 [00:58<39:18,  7.37it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 345/17710 [00:59<38:47,  7.46it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 349/17710 [01:00<38:47,  7.46it/s, loss=nan]Epoch 0 - train:   2%|█▍                                                                         | 353/17710 [01:00<38:29,  7.52it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 361/17710 [01:01<38:43,  7.47it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 369/17710 [01:02<38:18,  7.54it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                         | 377/17710 [01:03<38:28,  7.51it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                         | 385/17710 [01:04<38:18,  7.54it/s, loss=nan]Epoch 0 - train:   2%|█▌                                                                       | 393/17710 [01:08<1:05:06,  4.43it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 399/17710 [01:10<1:13:25,  3.93it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 399/17710 [01:11<1:13:25,  3.93it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 405/17710 [01:13<1:37:58,  2.94it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 410/17710 [01:15<1:36:11,  3.00it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 414/17710 [01:16<1:31:11,  3.16it/s, loss=nan]Epoch 0 - train:   2%|█▋                                                                       | 421/17710 [01:17<1:16:18,  3.78it/s, loss=nan]Epoch 0 - train:   2%|█▊                                                                       | 429/17710 [01:18<1:02:40,  4.60it/s, loss=nan]Epoch 0 - train:   2%|█▊                                                                         | 437/17710 [01:19<54:12,  5.31it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 445/17710 [01:20<48:54,  5.88it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 449/17710 [01:21<48:54,  5.88it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 453/17710 [01:21<45:30,  6.32it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 461/17710 [01:22<43:05,  6.67it/s, loss=nan]Epoch 0 - train:   3%|█▉                                                                         | 469/17710 [01:24<41:28,  6.93it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 477/17710 [01:25<40:20,  7.12it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 485/17710 [01:26<40:24,  7.11it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 493/17710 [01:27<39:29,  7.27it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 499/17710 [01:28<39:28,  7.27it/s, loss=nan]Epoch 0 - train:   3%|██                                                                         | 501/17710 [01:28<39:09,  7.33it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 509/17710 [01:29<38:42,  7.41it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 517/17710 [01:30<38:25,  7.46it/s, loss=nan]Epoch 0 - train:   3%|██▏                                                                        | 525/17710 [01:31<38:07,  7.51it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 533/17710 [01:32<37:51,  7.56it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 541/17710 [01:33<37:38,  7.60it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 549/17710 [01:35<48:38,  5.88it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 549/17710 [01:35<48:38,  5.88it/s, loss=nan]Epoch 0 - train:   3%|██▎                                                                        | 557/17710 [01:36<45:13,  6.32it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 565/17710 [01:37<42:46,  6.68it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 573/17710 [01:38<41:00,  6.96it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 581/17710 [01:39<39:54,  7.15it/s, loss=nan]Epoch 0 - train:   3%|██▍                                                                        | 589/17710 [01:40<39:24,  7.24it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 597/17710 [01:41<38:47,  7.35it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 599/17710 [01:42<38:46,  7.35it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 605/17710 [01:42<38:11,  7.46it/s, loss=nan]Epoch 0 - train:   3%|██▌                                                                        | 613/17710 [01:43<37:47,  7.54it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 621/17710 [01:45<37:32,  7.59it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 629/17710 [01:46<37:34,  7.58it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 637/17710 [01:47<37:27,  7.60it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 645/17710 [01:48<37:38,  7.55it/s, loss=nan]Epoch 0 - train:   4%|██▋                                                                        | 649/17710 [01:48<37:38,  7.55it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 653/17710 [01:49<37:25,  7.59it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 661/17710 [01:50<37:20,  7.61it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 669/17710 [01:51<37:19,  7.61it/s, loss=nan]Epoch 0 - train:   4%|██▊                                                                        | 677/17710 [01:52<37:22,  7.60it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 685/17710 [01:53<37:28,  7.57it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 693/17710 [01:54<37:30,  7.56it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 699/17710 [01:55<37:29,  7.56it/s, loss=nan]Epoch 0 - train:   4%|██▉                                                                        | 701/17710 [01:55<37:20,  7.59it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 709/17710 [01:56<37:09,  7.63it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 717/17710 [01:57<37:01,  7.65it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 725/17710 [01:58<36:55,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███                                                                        | 733/17710 [01:59<36:53,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 741/17710 [02:00<36:53,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 749/17710 [02:01<36:51,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 749/17710 [02:01<36:51,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 757/17710 [02:02<36:50,  7.67it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                       | 765/17710 [02:03<37:05,  7.61it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                       | 773/17710 [02:04<37:04,  7.61it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                     | 781/17710 [02:11<1:36:12,  2.93it/s, loss=nan]Epoch 0 - train:   4%|███▏                                                                     | 787/17710 [02:12<1:25:28,  3.30it/s, loss=nan]Epoch 0 - train:   4%|███▎                                                                     | 793/17710 [02:14<1:26:41,  3.25it/s, loss=nan]Epoch 0 - train:   5%|███▎                                                                     | 798/17710 [02:15<1:23:29,  3.38it/s, loss=nan]Epoch 0 - train:   5%|███▎                                                                     | 799/17710 [02:17<1:23:29,  3.38it/s, loss=nan]Epoch 0 - train:   5%|███▎                                                                     | 803/17710 [02:17<1:27:42,  3.21it/s, loss=nan]Epoch 0 - train:   5%|███▎                                                                     | 808/17710 [02:19<1:24:36,  3.33it/s, loss=nan]Epoch 0 - train:   5%|███▎                                                                     | 815/17710 [02:20<1:09:33,  4.05it/s, loss=nan]Epoch 0 - train:   5%|███▍                                                                     | 822/17710 [02:21<1:00:50,  4.63it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 829/17710 [02:22<54:33,  5.16it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 837/17710 [02:23<48:53,  5.75it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 845/17710 [02:24<45:38,  6.16it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 849/17710 [02:25<45:37,  6.16it/s, loss=nan]Epoch 0 - train:   5%|███▌                                                                       | 853/17710 [02:25<42:51,  6.55it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 861/17710 [02:26<41:12,  6.81it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 869/17710 [02:27<40:05,  7.00it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 877/17710 [02:28<38:53,  7.21it/s, loss=nan]Epoch 0 - train:   5%|███▋                                                                       | 885/17710 [02:29<38:00,  7.38it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 893/17710 [02:30<37:30,  7.47it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 899/17710 [02:31<37:29,  7.47it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 901/17710 [02:31<37:27,  7.48it/s, loss=nan]Epoch 0 - train:   5%|███▊                                                                       | 909/17710 [02:32<37:21,  7.49it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 917/17710 [02:33<36:56,  7.58it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 925/17710 [02:34<36:36,  7.64it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 933/17710 [02:35<36:30,  7.66it/s, loss=nan]Epoch 0 - train:   5%|███▉                                                                       | 941/17710 [02:36<36:24,  7.68it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 949/17710 [02:37<36:24,  7.67it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 949/17710 [02:38<36:24,  7.67it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 957/17710 [02:39<36:56,  7.56it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 965/17710 [02:40<36:49,  7.58it/s, loss=nan]Epoch 0 - train:   5%|████                                                                       | 973/17710 [02:41<36:37,  7.62it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 981/17710 [02:42<36:32,  7.63it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 989/17710 [02:43<36:27,  7.64it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 997/17710 [02:44<36:25,  7.65it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                      | 999/17710 [02:44<36:25,  7.65it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                     | 1005/17710 [02:45<37:49,  7.36it/s, loss=nan]Epoch 0 - train:   6%|████▏                                                                     | 1013/17710 [02:46<37:31,  7.42it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1021/17710 [02:47<37:02,  7.51it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1029/17710 [02:48<36:44,  7.57it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1037/17710 [02:49<36:44,  7.56it/s, loss=nan]Epoch 0 - train:   6%|████▎                                                                     | 1045/17710 [02:50<36:40,  7.57it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1049/17710 [02:51<36:39,  7.57it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1053/17710 [02:51<36:35,  7.59it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1061/17710 [02:52<36:41,  7.56it/s, loss=nan]Epoch 0 - train:   6%|████▍                                                                     | 1069/17710 [02:53<36:28,  7.60it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1077/17710 [02:54<36:21,  7.63it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1085/17710 [02:55<36:17,  7.64it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1093/17710 [02:57<36:14,  7.64it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1099/17710 [02:57<36:13,  7.64it/s, loss=nan]Epoch 0 - train:   6%|████▌                                                                     | 1101/17710 [02:58<36:23,  7.61it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1109/17710 [02:59<36:24,  7.60it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1117/17710 [03:00<36:15,  7.63it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1125/17710 [03:01<36:10,  7.64it/s, loss=nan]Epoch 0 - train:   6%|████▋                                                                     | 1133/17710 [03:02<36:02,  7.67it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1141/17710 [03:03<35:56,  7.68it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1149/17710 [03:04<35:57,  7.68it/s, loss=nan]Epoch 0 - train:   6%|████▊                                                                     | 1149/17710 [03:04<35:57,  7.68it/s, loss=nan]Epoch 0 - train:   7%|████▊                                                                     | 1157/17710 [03:05<36:07,  7.64it/s, loss=nan]Epoch 0 - train:   7%|████▊                                                                     | 1165/17710 [03:08<59:42,  4.62it/s, loss=nan]Epoch 0 - train:   7%|████▊                                                                   | 1172/17710 [03:10<1:06:33,  4.14it/s, loss=nan]Epoch 0 - train:   7%|████▊                                                                   | 1178/17710 [03:11<1:01:35,  4.47it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1185/17710 [03:12<55:16,  4.98it/s, loss=nan]Epoch 0 - train:   7%|████▉                                                                     | 1193/17710 [03:14<49:39,  5.54it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1199/17710 [03:14<49:38,  5.54it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1201/17710 [03:15<45:37,  6.03it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1209/17710 [03:16<42:58,  6.40it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1217/17710 [03:17<41:21,  6.65it/s, loss=nan]Epoch 0 - train:   7%|█████                                                                     | 1225/17710 [03:18<41:08,  6.68it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1232/17710 [03:19<43:19,  6.34it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1239/17710 [03:20<44:11,  6.21it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1247/17710 [03:21<41:53,  6.55it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1249/17710 [03:22<41:53,  6.55it/s, loss=nan]Epoch 0 - train:   7%|█████▏                                                                    | 1254/17710 [03:23<41:37,  6.59it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1262/17710 [03:24<39:52,  6.87it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1270/17710 [03:25<38:39,  7.09it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1278/17710 [03:26<37:47,  7.25it/s, loss=nan]Epoch 0 - train:   7%|█████▎                                                                    | 1286/17710 [03:27<37:14,  7.35it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1294/17710 [03:28<37:36,  7.28it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1299/17710 [03:29<37:35,  7.28it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1302/17710 [03:29<37:09,  7.36it/s, loss=nan]Epoch 0 - train:   7%|█████▍                                                                    | 1310/17710 [03:30<36:46,  7.43it/s, loss=nan]Epoch 0 - train:   7%|█████▌                                                                    | 1318/17710 [03:32<42:40,  6.40it/s, loss=nan]Epoch 0 - train:   7%|█████▌                                                                    | 1326/17710 [03:33<41:14,  6.62it/s, loss=nan]Epoch 0 - train:   8%|█████▌                                                                    | 1334/17710 [03:34<39:51,  6.85it/s, loss=nan]Epoch 0 - train:   8%|█████▌                                                                    | 1342/17710 [03:35<38:40,  7.05it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1349/17710 [03:36<38:39,  7.05it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1350/17710 [03:36<38:18,  7.12it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1358/17710 [03:37<37:28,  7.27it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1366/17710 [03:38<37:08,  7.33it/s, loss=nan]Epoch 0 - train:   8%|█████▋                                                                    | 1374/17710 [03:39<37:13,  7.31it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1382/17710 [03:40<38:11,  7.13it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1390/17710 [03:42<46:53,  5.80it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1397/17710 [03:43<45:00,  6.04it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1399/17710 [03:44<45:00,  6.04it/s, loss=nan]Epoch 0 - train:   8%|█████▊                                                                    | 1405/17710 [03:45<47:35,  5.71it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1413/17710 [03:46<43:57,  6.18it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1421/17710 [03:47<41:22,  6.56it/s, loss=nan]Epoch 0 - train:   8%|█████▉                                                                    | 1429/17710 [03:48<40:04,  6.77it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1437/17710 [03:49<38:45,  7.00it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1445/17710 [03:50<37:48,  7.17it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1449/17710 [03:51<37:47,  7.17it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1453/17710 [03:51<37:05,  7.30it/s, loss=nan]Epoch 0 - train:   8%|██████                                                                    | 1461/17710 [03:52<36:50,  7.35it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1469/17710 [03:53<36:33,  7.40it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1477/17710 [03:55<36:43,  7.37it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1485/17710 [03:56<37:23,  7.23it/s, loss=nan]Epoch 0 - train:   8%|██████▏                                                                   | 1493/17710 [03:57<37:50,  7.14it/s, loss=nan]Epoch 0 - train:   8%|██████▎                                                                   | 1499/17710 [03:58<37:49,  7.14it/s, loss=nan]Epoch 0 - train:   8%|██████▎                                                                   | 1501/17710 [03:58<37:52,  7.13it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                   | 1509/17710 [03:59<37:36,  7.18it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                   | 1517/17710 [04:00<36:59,  7.30it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                   | 1525/17710 [04:01<36:31,  7.39it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1533/17710 [04:02<36:14,  7.44it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1541/17710 [04:03<36:08,  7.46it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1549/17710 [04:04<36:01,  7.48it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                   | 1549/17710 [04:04<36:01,  7.48it/s, loss=nan]Epoch 0 - train:   9%|██████▌                                                                   | 1557/17710 [04:06<46:52,  5.74it/s, loss=nan]Epoch 0 - train:   9%|██████▎                                                                 | 1564/17710 [04:11<1:18:01,  3.45it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                 | 1570/17710 [04:12<1:09:47,  3.85it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                 | 1576/17710 [04:13<1:05:30,  4.11it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                 | 1582/17710 [04:14<1:06:07,  4.07it/s, loss=nan]Epoch 0 - train:   9%|██████▍                                                                 | 1588/17710 [04:15<1:00:28,  4.44it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1594/17710 [04:16<56:19,  4.77it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1599/17710 [04:17<56:18,  4.77it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1601/17710 [04:17<50:42,  5.29it/s, loss=nan]Epoch 0 - train:   9%|██████▋                                                                   | 1609/17710 [04:19<46:18,  5.79it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1617/17710 [04:20<43:01,  6.23it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1625/17710 [04:21<40:29,  6.62it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1633/17710 [04:22<38:50,  6.90it/s, loss=nan]Epoch 0 - train:   9%|██████▊                                                                   | 1641/17710 [04:23<37:45,  7.09it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1649/17710 [04:24<37:02,  7.23it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1649/17710 [04:24<37:02,  7.23it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1657/17710 [04:25<36:27,  7.34it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1665/17710 [04:26<35:59,  7.43it/s, loss=nan]Epoch 0 - train:   9%|██████▉                                                                   | 1673/17710 [04:27<35:43,  7.48it/s, loss=nan]Epoch 0 - train:   9%|███████                                                                   | 1681/17710 [04:28<35:41,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1689/17710 [04:29<35:35,  7.50it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1697/17710 [04:30<35:22,  7.54it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1699/17710 [04:31<35:22,  7.54it/s, loss=nan]Epoch 0 - train:  10%|███████                                                                   | 1705/17710 [04:31<35:28,  7.52it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1713/17710 [04:32<35:13,  7.57it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1721/17710 [04:33<34:58,  7.62it/s, loss=nan]Epoch 0 - train:  10%|███████▏                                                                  | 1729/17710 [04:34<34:53,  7.63it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1737/17710 [04:35<34:57,  7.61it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1745/17710 [04:37<35:03,  7.59it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1749/17710 [04:37<35:03,  7.59it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1753/17710 [04:38<34:59,  7.60it/s, loss=nan]Epoch 0 - train:  10%|███████▎                                                                  | 1761/17710 [04:39<34:52,  7.62it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1769/17710 [04:40<34:56,  7.60it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1777/17710 [04:41<35:26,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1785/17710 [04:42<35:29,  7.48it/s, loss=nan]Epoch 0 - train:  10%|███████▍                                                                  | 1793/17710 [04:43<35:25,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1799/17710 [04:44<35:25,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1801/17710 [04:44<35:23,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1809/17710 [04:45<35:23,  7.49it/s, loss=nan]Epoch 0 - train:  10%|███████▌                                                                  | 1817/17710 [04:46<35:07,  7.54it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1825/17710 [04:47<35:13,  7.51it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1833/17710 [04:48<35:06,  7.54it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1841/17710 [04:49<35:00,  7.55it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1849/17710 [04:50<34:57,  7.56it/s, loss=nan]Epoch 0 - train:  10%|███████▋                                                                  | 1849/17710 [04:50<34:57,  7.56it/s, loss=nan]Epoch 0 - train:  10%|███████▊                                                                  | 1857/17710 [04:51<34:59,  7.55it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1865/17710 [04:52<34:53,  7.57it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1873/17710 [04:54<34:52,  7.57it/s, loss=nan]Epoch 0 - train:  11%|███████▊                                                                  | 1881/17710 [04:55<34:44,  7.59it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1889/17710 [04:56<34:41,  7.60it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1897/17710 [04:57<34:44,  7.59it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1899/17710 [04:57<34:43,  7.59it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1905/17710 [04:58<34:37,  7.61it/s, loss=nan]Epoch 0 - train:  11%|███████▉                                                                  | 1913/17710 [04:59<34:37,  7.60it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1921/17710 [05:00<34:37,  7.60it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1929/17710 [05:01<34:38,  7.59it/s, loss=nan]Epoch 0 - train:  11%|████████                                                                  | 1937/17710 [05:02<34:39,  7.59it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1945/17710 [05:03<34:34,  7.60it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1949/17710 [05:04<34:33,  7.60it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1953/17710 [05:04<34:38,  7.58it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1961/17710 [05:05<34:34,  7.59it/s, loss=nan]Epoch 0 - train:  11%|████████▏                                                                 | 1969/17710 [05:07<41:38,  6.30it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1976/17710 [05:09<46:46,  5.61it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1982/17710 [05:10<46:35,  5.63it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1989/17710 [05:11<45:21,  5.78it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1997/17710 [05:12<41:48,  6.26it/s, loss=nan]Epoch 0 - train:  11%|████████▎                                                                 | 1999/17710 [05:12<41:48,  6.26it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2005/17710 [05:13<39:31,  6.62it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2013/17710 [05:14<37:59,  6.89it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2021/17710 [05:15<37:02,  7.06it/s, loss=nan]Epoch 0 - train:  11%|████████▍                                                                 | 2029/17710 [05:16<36:42,  7.12it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2037/17710 [05:17<35:58,  7.26it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2045/17710 [05:18<35:35,  7.34it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2049/17710 [05:19<35:34,  7.34it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2053/17710 [05:19<35:13,  7.41it/s, loss=nan]Epoch 0 - train:  12%|████████▌                                                                 | 2061/17710 [05:20<34:47,  7.50it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2069/17710 [05:21<34:33,  7.54it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2077/17710 [05:22<34:26,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2085/17710 [05:23<34:29,  7.55it/s, loss=nan]Epoch 0 - train:  12%|████████▋                                                                 | 2093/17710 [05:24<34:33,  7.53it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2099/17710 [05:25<34:32,  7.53it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2101/17710 [05:26<34:25,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2109/17710 [05:27<34:23,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▊                                                                 | 2117/17710 [05:28<34:31,  7.53it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2125/17710 [05:29<34:22,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2133/17710 [05:30<34:19,  7.56it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2141/17710 [05:31<34:13,  7.58it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2149/17710 [05:32<34:13,  7.58it/s, loss=nan]Epoch 0 - train:  12%|████████▉                                                                 | 2149/17710 [05:32<34:13,  7.58it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2157/17710 [05:33<34:09,  7.59it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2165/17710 [05:34<34:16,  7.56it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2173/17710 [05:35<34:09,  7.58it/s, loss=nan]Epoch 0 - train:  12%|█████████                                                                 | 2181/17710 [05:36<34:08,  7.58it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2189/17710 [05:37<34:00,  7.61it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2197/17710 [05:38<34:13,  7.55it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2199/17710 [05:39<34:13,  7.55it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2205/17710 [05:39<34:10,  7.56it/s, loss=nan]Epoch 0 - train:  12%|█████████▏                                                                | 2213/17710 [05:40<34:02,  7.59it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2221/17710 [05:41<34:00,  7.59it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2229/17710 [05:42<34:40,  7.44it/s, loss=nan]Epoch 0 - train:  13%|█████████▎                                                                | 2237/17710 [05:44<34:38,  7.44it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2245/17710 [05:45<34:24,  7.49it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2249/17710 [05:45<34:23,  7.49it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2253/17710 [05:46<34:13,  7.53it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2261/17710 [05:47<34:01,  7.57it/s, loss=nan]Epoch 0 - train:  13%|█████████▍                                                                | 2269/17710 [05:48<34:00,  7.57it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2277/17710 [05:49<34:02,  7.56it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2285/17710 [05:50<34:06,  7.54it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2293/17710 [05:51<34:06,  7.53it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2299/17710 [05:52<34:05,  7.53it/s, loss=nan]Epoch 0 - train:  13%|█████████▌                                                                | 2301/17710 [05:52<33:58,  7.56it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2309/17710 [05:53<33:51,  7.58it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2317/17710 [05:54<33:56,  7.56it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2325/17710 [05:55<33:53,  7.57it/s, loss=nan]Epoch 0 - train:  13%|█████████▋                                                                | 2333/17710 [05:56<33:38,  7.62it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2341/17710 [05:57<33:42,  7.60it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2349/17710 [05:58<33:31,  7.64it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2349/17710 [05:58<33:31,  7.64it/s, loss=nan]Epoch 0 - train:  13%|█████████▊                                                                | 2357/17710 [05:59<33:26,  7.65it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2365/17710 [06:00<33:31,  7.63it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2373/17710 [06:01<33:26,  7.64it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2381/17710 [06:02<33:19,  7.67it/s, loss=nan]Epoch 0 - train:  13%|█████████▉                                                                | 2389/17710 [06:04<33:16,  7.67it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2397/17710 [06:05<33:10,  7.69it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2399/17710 [06:05<33:09,  7.69it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2405/17710 [06:06<40:43,  6.26it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2412/17710 [06:07<39:50,  6.40it/s, loss=nan]Epoch 0 - train:  14%|██████████                                                                | 2420/17710 [06:08<37:59,  6.71it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2428/17710 [06:10<36:47,  6.92it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2436/17710 [06:11<35:43,  7.13it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2444/17710 [06:12<35:05,  7.25it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2449/17710 [06:12<35:04,  7.25it/s, loss=nan]Epoch 0 - train:  14%|██████████▏                                                               | 2452/17710 [06:13<34:35,  7.35it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2460/17710 [06:14<34:09,  7.44it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2468/17710 [06:15<33:47,  7.52it/s, loss=nan]Epoch 0 - train:  14%|██████████▎                                                               | 2476/17710 [06:16<33:48,  7.51it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2484/17710 [06:17<33:35,  7.55it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2492/17710 [06:18<33:27,  7.58it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2499/17710 [06:19<33:26,  7.58it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2500/17710 [06:19<33:19,  7.61it/s, loss=nan]Epoch 0 - train:  14%|██████████▍                                                               | 2508/17710 [06:20<33:20,  7.60it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2516/17710 [06:21<33:13,  7.62it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2524/17710 [06:22<33:14,  7.61it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2532/17710 [06:23<33:10,  7.63it/s, loss=nan]Epoch 0 - train:  14%|██████████▌                                                               | 2540/17710 [06:24<33:09,  7.62it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2548/17710 [06:25<33:01,  7.65it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2549/17710 [06:26<33:01,  7.65it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2556/17710 [06:26<32:59,  7.65it/s, loss=nan]Epoch 0 - train:  14%|██████████▋                                                               | 2564/17710 [06:27<32:57,  7.66it/s, loss=nan]Epoch 0 - train:  15%|██████████▋                                                               | 2572/17710 [06:28<33:03,  7.63it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2580/17710 [06:29<33:04,  7.63it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2588/17710 [06:31<33:06,  7.61it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2596/17710 [06:32<33:26,  7.53it/s, loss=nan]Epoch 0 - train:  15%|██████████▊                                                               | 2599/17710 [06:32<33:26,  7.53it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2604/17710 [06:33<33:44,  7.46it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2612/17710 [06:34<33:36,  7.49it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2620/17710 [06:35<33:30,  7.51it/s, loss=nan]Epoch 0 - train:  15%|██████████▉                                                               | 2628/17710 [06:36<33:28,  7.51it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2636/17710 [06:37<33:16,  7.55it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2644/17710 [06:38<33:13,  7.56it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2649/17710 [06:39<33:13,  7.56it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2652/17710 [06:39<33:24,  7.51it/s, loss=nan]Epoch 0 - train:  15%|███████████                                                               | 2660/17710 [06:40<33:24,  7.51it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2668/17710 [06:41<33:18,  7.53it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2676/17710 [06:42<33:16,  7.53it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2684/17710 [06:43<33:12,  7.54it/s, loss=nan]Epoch 0 - train:  15%|███████████▏                                                              | 2692/17710 [06:44<33:02,  7.58it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2699/17710 [06:45<33:01,  7.58it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2700/17710 [06:45<32:52,  7.61it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2708/17710 [06:46<32:53,  7.60it/s, loss=nan]Epoch 0 - train:  15%|███████████▎                                                              | 2716/17710 [06:47<32:44,  7.63it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2724/17710 [06:49<32:40,  7.64it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2732/17710 [06:50<32:36,  7.66it/s, loss=nan]Epoch 0 - train:  15%|███████████▍                                                              | 2740/17710 [06:51<32:34,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▍                                                              | 2748/17710 [06:52<32:30,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▍                                                              | 2749/17710 [06:52<32:30,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2756/17710 [06:53<32:28,  7.68it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2764/17710 [06:54<32:27,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2772/17710 [06:55<32:25,  7.68it/s, loss=nan]Epoch 0 - train:  16%|███████████▌                                                              | 2780/17710 [06:56<32:24,  7.68it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2788/17710 [06:57<32:27,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2796/17710 [06:58<32:24,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2799/17710 [06:58<32:23,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2804/17710 [06:59<32:26,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▋                                                              | 2812/17710 [07:00<32:21,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2820/17710 [07:01<32:20,  7.67it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2828/17710 [07:02<32:22,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▊                                                              | 2836/17710 [07:03<32:22,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2844/17710 [07:04<32:25,  7.64it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2849/17710 [07:05<32:24,  7.64it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2852/17710 [07:05<32:18,  7.66it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2860/17710 [07:08<45:47,  5.40it/s, loss=nan]Epoch 0 - train:  16%|███████████▉                                                              | 2868/17710 [07:09<42:00,  5.89it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2876/17710 [07:10<39:18,  6.29it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2884/17710 [07:11<37:15,  6.63it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2892/17710 [07:12<36:00,  6.86it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2899/17710 [07:13<35:59,  6.86it/s, loss=nan]Epoch 0 - train:  16%|████████████                                                              | 2900/17710 [07:13<34:53,  7.07it/s, loss=nan]Epoch 0 - train:  16%|████████████▏                                                             | 2908/17710 [07:14<33:59,  7.26it/s, loss=nan]Epoch 0 - train:  16%|████████████▏                                                             | 2916/17710 [07:15<33:26,  7.37it/s, loss=nan]Epoch 0 - train:  17%|████████████▏                                                             | 2924/17710 [07:16<32:59,  7.47it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2932/17710 [07:17<32:36,  7.55it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2940/17710 [07:18<32:20,  7.61it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2948/17710 [07:19<32:19,  7.61it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2949/17710 [07:20<32:19,  7.61it/s, loss=nan]Epoch 0 - train:  17%|████████████▎                                                             | 2956/17710 [07:20<32:13,  7.63it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2964/17710 [07:21<32:08,  7.65it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2972/17710 [07:22<32:00,  7.67it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2980/17710 [07:23<32:11,  7.63it/s, loss=nan]Epoch 0 - train:  17%|████████████▍                                                             | 2988/17710 [07:25<32:07,  7.64it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 2996/17710 [07:26<32:04,  7.65it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 2999/17710 [07:26<32:03,  7.65it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3004/17710 [07:27<31:58,  7.67it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3012/17710 [07:28<31:56,  7.67it/s, loss=nan]Epoch 0 - train:  17%|████████████▌                                                             | 3020/17710 [07:29<32:00,  7.65it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3028/17710 [07:30<32:04,  7.63it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3036/17710 [07:31<32:09,  7.60it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3044/17710 [07:32<32:23,  7.55it/s, loss=nan]Epoch 0 - train:  17%|████████████▋                                                             | 3049/17710 [07:33<32:23,  7.55it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3052/17710 [07:33<32:27,  7.52it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3060/17710 [07:34<32:31,  7.51it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3068/17710 [07:35<32:26,  7.52it/s, loss=nan]Epoch 0 - train:  17%|████████████▊                                                             | 3076/17710 [07:36<32:19,  7.55it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3084/17710 [07:37<32:09,  7.58it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3092/17710 [07:38<32:11,  7.57it/s, loss=nan]Epoch 0 - train:  17%|████████████▉                                                             | 3099/17710 [07:39<32:10,  7.57it/s, loss=nan]Epoch 0 - train:  18%|████████████▉                                                             | 3100/17710 [07:39<32:01,  7.60it/s, loss=nan]Epoch 0 - train:  18%|████████████▉                                                             | 3108/17710 [07:40<31:56,  7.62it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3116/17710 [07:41<31:57,  7.61it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3124/17710 [07:42<32:11,  7.55it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3132/17710 [07:44<32:27,  7.48it/s, loss=nan]Epoch 0 - train:  18%|█████████████                                                             | 3140/17710 [07:45<32:20,  7.51it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3148/17710 [07:46<32:19,  7.51it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3149/17710 [07:46<32:19,  7.51it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3156/17710 [07:47<32:21,  7.50it/s, loss=nan]Epoch 0 - train:  18%|█████████████▏                                                            | 3164/17710 [07:48<32:07,  7.55it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3172/17710 [07:49<32:13,  7.52it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3180/17710 [07:50<32:12,  7.52it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3188/17710 [07:51<32:13,  7.51it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3196/17710 [07:52<32:07,  7.53it/s, loss=nan]Epoch 0 - train:  18%|█████████████▎                                                            | 3199/17710 [07:53<32:07,  7.53it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3204/17710 [07:53<32:00,  7.55it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3212/17710 [07:54<31:58,  7.56it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3220/17710 [07:55<31:57,  7.56it/s, loss=nan]Epoch 0 - train:  18%|█████████████▍                                                            | 3228/17710 [07:56<31:53,  7.57it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3236/17710 [07:57<31:47,  7.59it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3244/17710 [07:58<31:53,  7.56it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3249/17710 [07:59<31:52,  7.56it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3252/17710 [07:59<31:59,  7.53it/s, loss=nan]Epoch 0 - train:  18%|█████████████▌                                                            | 3260/17710 [08:01<31:54,  7.55it/s, loss=nan]Epoch 0 - train:  18%|█████████████▋                                                            | 3268/17710 [08:02<31:47,  7.57it/s, loss=nan]Epoch 0 - train:  18%|█████████████▋                                                            | 3276/17710 [08:03<31:49,  7.56it/s, loss=nan]Epoch 0 - train:  19%|█████████████▋                                                            | 3284/17710 [08:04<31:47,  7.56it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3292/17710 [08:05<31:33,  7.61it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3299/17710 [08:07<31:32,  7.61it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3300/17710 [08:07<43:50,  5.48it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3308/17710 [08:08<40:28,  5.93it/s, loss=nan]Epoch 0 - train:  19%|█████████████▊                                                            | 3316/17710 [08:09<37:55,  6.32it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3324/17710 [08:10<35:58,  6.66it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3332/17710 [08:11<34:31,  6.94it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3340/17710 [08:12<33:26,  7.16it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3348/17710 [08:13<32:51,  7.28it/s, loss=nan]Epoch 0 - train:  19%|█████████████▉                                                            | 3349/17710 [08:14<32:51,  7.28it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3356/17710 [08:15<32:23,  7.39it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3364/17710 [08:16<32:12,  7.42it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3372/17710 [08:17<31:55,  7.49it/s, loss=nan]Epoch 0 - train:  19%|██████████████                                                            | 3380/17710 [08:18<31:38,  7.55it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3388/17710 [08:19<31:32,  7.57it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3396/17710 [08:20<31:30,  7.57it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3399/17710 [08:20<31:29,  7.57it/s, loss=nan]Epoch 0 - train:  19%|██████████████▏                                                           | 3404/17710 [08:21<31:22,  7.60it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3412/17710 [08:22<32:02,  7.44it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3420/17710 [08:23<32:45,  7.27it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3428/17710 [08:24<34:56,  6.81it/s, loss=nan]Epoch 0 - train:  19%|██████████████▎                                                           | 3435/17710 [08:26<35:50,  6.64it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3443/17710 [08:27<34:24,  6.91it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3449/17710 [08:28<34:23,  6.91it/s, loss=nan]Epoch 0 - train:  19%|██████████████▍                                                           | 3451/17710 [08:28<33:21,  7.12it/s, loss=nan]Epoch 0 - train:  20%|██████████████▍                                                           | 3459/17710 [08:29<32:44,  7.26it/s, loss=nan]Epoch 0 - train:  20%|██████████████▍                                                           | 3467/17710 [08:30<32:27,  7.31it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3475/17710 [08:31<32:00,  7.41it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3483/17710 [08:32<31:36,  7.50it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3491/17710 [08:33<31:18,  7.57it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3499/17710 [08:34<31:15,  7.58it/s, loss=nan]Epoch 0 - train:  20%|██████████████▌                                                           | 3499/17710 [08:34<31:15,  7.58it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3507/17710 [08:35<31:17,  7.57it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3515/17710 [08:36<31:15,  7.57it/s, loss=nan]Epoch 0 - train:  20%|██████████████▋                                                           | 3523/17710 [08:37<31:10,  7.58it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3531/17710 [08:38<31:04,  7.60it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3539/17710 [08:39<31:25,  7.52it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3547/17710 [08:40<31:18,  7.54it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3549/17710 [08:41<31:17,  7.54it/s, loss=nan]Epoch 0 - train:  20%|██████████████▊                                                           | 3555/17710 [08:41<31:21,  7.52it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3563/17710 [08:42<31:17,  7.53it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3571/17710 [08:44<31:15,  7.54it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3579/17710 [08:45<31:22,  7.51it/s, loss=nan]Epoch 0 - train:  20%|██████████████▉                                                           | 3587/17710 [08:46<31:45,  7.41it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3595/17710 [08:47<31:36,  7.44it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3599/17710 [08:47<31:35,  7.44it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3603/17710 [08:48<31:28,  7.47it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3611/17710 [08:49<31:16,  7.51it/s, loss=nan]Epoch 0 - train:  20%|███████████████                                                           | 3619/17710 [08:50<31:07,  7.55it/s, loss=nan]Epoch 0 - train:  20%|███████████████▏                                                          | 3627/17710 [08:51<31:23,  7.48it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3635/17710 [08:52<31:19,  7.49it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3643/17710 [08:53<31:15,  7.50it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                          | 3649/17710 [08:54<31:14,  7.50it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3651/17710 [08:54<31:17,  7.49it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3659/17710 [08:55<31:12,  7.51it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3667/17710 [08:56<31:08,  7.51it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                          | 3675/17710 [08:57<30:53,  7.57it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3683/17710 [08:58<30:52,  7.57it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3691/17710 [08:59<30:44,  7.60it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3699/17710 [09:01<30:42,  7.61it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3699/17710 [09:01<30:42,  7.61it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                          | 3707/17710 [09:02<30:29,  7.65it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3715/17710 [09:03<30:24,  7.67it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3723/17710 [09:04<30:39,  7.61it/s, loss=nan]Epoch 0 - train:  21%|███████████████▌                                                          | 3731/17710 [09:05<30:40,  7.60it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                        | 3739/17710 [09:18<2:19:32,  1.67it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                        | 3740/17710 [09:20<2:28:03,  1.57it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                        | 3746/17710 [09:24<2:31:25,  1.54it/s, loss=nan]Epoch 0 - train:  21%|███████████████▏                                                        | 3749/17710 [09:24<2:31:24,  1.54it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3753/17710 [09:25<1:55:40,  2.01it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3758/17710 [09:27<1:44:40,  2.22it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3763/17710 [09:29<1:45:38,  2.20it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3767/17710 [09:30<1:35:21,  2.44it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3771/17710 [09:31<1:29:35,  2.59it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3775/17710 [09:32<1:22:36,  2.81it/s, loss=nan]Epoch 0 - train:  21%|███████████████▎                                                        | 3780/17710 [09:33<1:11:32,  3.25it/s, loss=nan]Epoch 0 - train:  21%|███████████████▍                                                        | 3785/17710 [09:34<1:03:51,  3.63it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3792/17710 [09:35<52:07,  4.45it/s, loss=nan]Epoch 0 - train:  21%|███████████████▊                                                          | 3799/17710 [09:36<52:06,  4.45it/s, loss=nan]Epoch 0 - train:  21%|███████████████▉                                                          | 3800/17710 [09:36<44:24,  5.22it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3808/17710 [09:38<40:11,  5.77it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3815/17710 [09:39<38:09,  6.07it/s, loss=nan]Epoch 0 - train:  22%|███████████████▉                                                          | 3822/17710 [09:40<36:59,  6.26it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3830/17710 [09:41<35:19,  6.55it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3838/17710 [09:42<34:04,  6.78it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3846/17710 [09:43<32:46,  7.05it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3849/17710 [09:43<32:45,  7.05it/s, loss=nan]Epoch 0 - train:  22%|████████████████                                                          | 3854/17710 [09:44<32:09,  7.18it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3862/17710 [09:45<31:29,  7.33it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3870/17710 [09:46<31:00,  7.44it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3878/17710 [09:47<30:34,  7.54it/s, loss=nan]Epoch 0 - train:  22%|████████████████▏                                                         | 3886/17710 [09:48<30:18,  7.60it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3894/17710 [09:49<30:19,  7.59it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3899/17710 [09:50<30:18,  7.59it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3902/17710 [09:50<30:08,  7.63it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3910/17710 [09:51<30:05,  7.64it/s, loss=nan]Epoch 0 - train:  22%|████████████████▎                                                         | 3918/17710 [09:52<30:02,  7.65it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3926/17710 [09:53<30:10,  7.61it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3934/17710 [09:54<30:39,  7.49it/s, loss=nan]Epoch 0 - train:  22%|████████████████▍                                                         | 3942/17710 [09:56<31:59,  7.17it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3949/17710 [09:57<31:58,  7.17it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3950/17710 [09:57<31:59,  7.17it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3958/17710 [09:58<32:31,  7.05it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3966/17710 [09:59<32:43,  7.00it/s, loss=nan]Epoch 0 - train:  22%|████████████████▌                                                         | 3974/17710 [10:00<31:56,  7.17it/s, loss=nan]Epoch 0 - train:  22%|████████████████▋                                                         | 3982/17710 [10:01<31:21,  7.29it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3990/17710 [10:02<30:59,  7.38it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3998/17710 [10:03<30:50,  7.41it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 3999/17710 [10:04<30:50,  7.41it/s, loss=nan]Epoch 0 - train:  23%|████████████████▋                                                         | 4006/17710 [10:04<30:44,  7.43it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4014/17710 [10:06<30:33,  7.47it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4022/17710 [10:07<36:22,  6.27it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4029/17710 [10:08<35:42,  6.39it/s, loss=nan]Epoch 0 - train:  23%|████████████████▊                                                         | 4036/17710 [10:09<36:34,  6.23it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4043/17710 [10:11<35:52,  6.35it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4049/17710 [10:12<35:51,  6.35it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4050/17710 [10:12<35:09,  6.48it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4058/17710 [10:13<33:25,  6.81it/s, loss=nan]Epoch 0 - train:  23%|████████████████▉                                                         | 4066/17710 [10:14<32:39,  6.96it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4074/17710 [10:15<31:48,  7.14it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4082/17710 [10:16<31:07,  7.30it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4090/17710 [10:17<30:36,  7.42it/s, loss=nan]Epoch 0 - train:  23%|█████████████████                                                         | 4098/17710 [10:18<30:15,  7.50it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4099/17710 [10:18<30:15,  7.50it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4106/17710 [10:19<30:08,  7.52it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4114/17710 [10:20<30:01,  7.55it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▏                                                        | 4122/17710 [10:21<30:04,  7.53it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4130/17710 [10:22<29:54,  7.57it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4138/17710 [10:23<29:55,  7.56it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4146/17710 [10:24<29:46,  7.59it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4149/17710 [10:25<29:45,  7.59it/s, loss=nan]Epoch 0 - train:  23%|█████████████████▎                                                        | 4154/17710 [10:25<29:30,  7.66it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4162/17710 [10:26<29:25,  7.67it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4170/17710 [10:27<29:19,  7.69it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4178/17710 [10:28<29:13,  7.72it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▍                                                        | 4186/17710 [10:29<29:17,  7.69it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4194/17710 [10:30<29:14,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4199/17710 [10:31<29:14,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4202/17710 [10:31<29:07,  7.73it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4210/17710 [10:32<29:05,  7.73it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▌                                                        | 4218/17710 [10:34<29:07,  7.72it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4226/17710 [10:35<29:13,  7.69it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4234/17710 [10:36<29:10,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▋                                                        | 4242/17710 [10:37<29:09,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4249/17710 [10:38<29:08,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4250/17710 [10:38<29:08,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4258/17710 [10:39<29:04,  7.71it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4266/17710 [10:40<29:04,  7.70it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▊                                                        | 4274/17710 [10:41<29:01,  7.72it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4282/17710 [10:42<28:59,  7.72it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4290/17710 [10:43<29:00,  7.71it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4298/17710 [10:44<29:24,  7.60it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4299/17710 [10:44<29:24,  7.60it/s, loss=nan]Epoch 0 - train:  24%|█████████████████▉                                                        | 4306/17710 [10:45<29:27,  7.58it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4314/17710 [10:46<29:26,  7.58it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4322/17710 [10:47<29:38,  7.53it/s, loss=nan]Epoch 0 - train:  24%|██████████████████                                                        | 4330/17710 [10:48<29:49,  7.48it/s, loss=nan]Epoch 0 - train:  24%|██████████████████▏                                                       | 4338/17710 [10:49<29:56,  7.44it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4346/17710 [10:50<29:41,  7.50it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4349/17710 [10:51<29:40,  7.50it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4354/17710 [10:51<29:45,  7.48it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▏                                                       | 4362/17710 [10:53<29:44,  7.48it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4370/17710 [10:54<30:31,  7.29it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4378/17710 [10:55<30:05,  7.38it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4386/17710 [10:56<29:45,  7.46it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▎                                                       | 4394/17710 [10:57<29:35,  7.50it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4399/17710 [10:58<29:34,  7.50it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4402/17710 [10:58<30:01,  7.39it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4410/17710 [10:59<29:58,  7.40it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4418/17710 [11:00<30:00,  7.38it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▍                                                       | 4426/17710 [11:01<29:52,  7.41it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4434/17710 [11:02<30:19,  7.30it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4442/17710 [11:04<31:09,  7.10it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4449/17710 [11:05<31:08,  7.10it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▌                                                       | 4450/17710 [11:05<31:01,  7.12it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4458/17710 [11:06<30:40,  7.20it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4466/17710 [11:08<36:58,  5.97it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4473/17710 [11:09<37:37,  5.86it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▋                                                       | 4480/17710 [11:10<36:52,  5.98it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4488/17710 [11:11<34:25,  6.40it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4495/17710 [11:12<34:41,  6.35it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4499/17710 [11:13<34:40,  6.35it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4503/17710 [11:13<33:02,  6.66it/s, loss=nan]Epoch 0 - train:  25%|██████████████████▊                                                       | 4511/17710 [11:14<31:48,  6.91it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4519/17710 [11:15<30:58,  7.10it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4527/17710 [11:16<30:43,  7.15it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4535/17710 [11:18<31:22,  7.00it/s, loss=nan]Epoch 0 - train:  26%|██████████████████▉                                                       | 4543/17710 [11:19<31:33,  6.96it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4549/17710 [11:20<31:32,  6.96it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4551/17710 [11:20<30:40,  7.15it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4559/17710 [11:21<30:05,  7.28it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4567/17710 [11:22<29:37,  7.39it/s, loss=nan]Epoch 0 - train:  26%|███████████████████                                                       | 4575/17710 [11:23<29:26,  7.44it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4583/17710 [11:24<29:14,  7.48it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4591/17710 [11:25<29:08,  7.50it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4599/17710 [11:26<29:01,  7.53it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▏                                                      | 4599/17710 [11:26<29:01,  7.53it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4607/17710 [11:27<29:05,  7.51it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4615/17710 [11:28<29:29,  7.40it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4623/17710 [11:29<29:17,  7.45it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▎                                                      | 4631/17710 [11:30<29:03,  7.50it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4639/17710 [11:32<28:54,  7.54it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4647/17710 [11:33<28:54,  7.53it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4649/17710 [11:33<28:54,  7.53it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4655/17710 [11:34<28:38,  7.60it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▍                                                      | 4663/17710 [11:35<28:35,  7.61it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4671/17710 [11:36<28:23,  7.66it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4679/17710 [11:37<28:15,  7.68it/s, loss=nan]Epoch 0 - train:  26%|███████████████████▌                                                      | 4687/17710 [11:38<28:12,  7.70it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▌                                                      | 4695/17710 [11:39<28:16,  7.67it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4699/17710 [11:39<28:16,  7.67it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4703/17710 [11:40<28:18,  7.66it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4711/17710 [11:41<28:13,  7.68it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▋                                                      | 4719/17710 [11:42<28:09,  7.69it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4727/17710 [11:43<28:03,  7.71it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4735/17710 [11:44<28:00,  7.72it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4743/17710 [11:45<27:55,  7.74it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4749/17710 [11:46<27:54,  7.74it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▊                                                      | 4751/17710 [11:46<27:52,  7.75it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4759/17710 [11:47<28:02,  7.70it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4767/17710 [11:48<28:12,  7.65it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4775/17710 [11:49<28:15,  7.63it/s, loss=nan]Epoch 0 - train:  27%|███████████████████▉                                                      | 4783/17710 [11:50<28:14,  7.63it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4791/17710 [11:51<28:15,  7.62it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4799/17710 [11:52<28:14,  7.62it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4799/17710 [11:53<28:14,  7.62it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4807/17710 [11:53<28:18,  7.60it/s, loss=nan]Epoch 0 - train:  27%|████████████████████                                                      | 4815/17710 [11:54<28:17,  7.60it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4823/17710 [11:56<28:25,  7.56it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4831/17710 [11:57<28:21,  7.57it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▏                                                     | 4839/17710 [11:58<28:30,  7.53it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4847/17710 [11:59<28:33,  7.51it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4849/17710 [11:59<28:32,  7.51it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4855/17710 [12:00<28:31,  7.51it/s, loss=nan]Epoch 0 - train:  27%|████████████████████▎                                                     | 4863/17710 [12:01<28:30,  7.51it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▎                                                     | 4871/17710 [12:02<28:41,  7.46it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4879/17710 [12:03<28:26,  7.52it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4887/17710 [12:04<28:17,  7.55it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4895/17710 [12:05<28:16,  7.56it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4899/17710 [12:06<28:15,  7.56it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▍                                                     | 4903/17710 [12:06<30:05,  7.09it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4911/17710 [12:08<30:05,  7.09it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4919/17710 [12:09<29:32,  7.22it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4927/17710 [12:10<29:06,  7.32it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▌                                                     | 4935/17710 [12:11<28:41,  7.42it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4943/17710 [12:12<28:30,  7.46it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4949/17710 [12:13<28:30,  7.46it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4951/17710 [12:13<28:38,  7.42it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▋                                                     | 4959/17710 [12:14<28:31,  7.45it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4967/17710 [12:15<28:18,  7.50it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4975/17710 [12:16<28:22,  7.48it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4983/17710 [12:17<28:09,  7.53it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▊                                                     | 4991/17710 [12:18<28:03,  7.55it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 4999/17710 [12:19<27:57,  7.58it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 4999/17710 [12:19<27:57,  7.58it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5007/17710 [12:20<27:48,  7.61it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5015/17710 [12:21<27:39,  7.65it/s, loss=nan]Epoch 0 - train:  28%|████████████████████▉                                                     | 5023/17710 [12:22<27:34,  7.67it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5031/17710 [12:23<27:28,  7.69it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5039/17710 [12:24<27:26,  7.69it/s, loss=nan]Epoch 0 - train:  28%|█████████████████████                                                     | 5047/17710 [12:25<27:27,  7.69it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████                                                     | 5049/17710 [12:26<27:26,  7.69it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████                                                     | 5055/17710 [12:26<27:18,  7.72it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5063/17710 [12:27<27:14,  7.74it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5071/17710 [12:29<27:10,  7.75it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▏                                                    | 5079/17710 [12:30<27:09,  7.75it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5087/17710 [12:31<27:09,  7.75it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5095/17710 [12:32<27:12,  7.73it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5099/17710 [12:32<27:12,  7.73it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5103/17710 [12:33<27:18,  7.70it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▎                                                    | 5111/17710 [12:34<27:13,  7.71it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5119/17710 [12:35<27:07,  7.73it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5127/17710 [12:36<27:05,  7.74it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5135/17710 [12:37<27:04,  7.74it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▍                                                    | 5143/17710 [12:38<27:05,  7.73it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5149/17710 [12:39<27:04,  7.73it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5151/17710 [12:39<27:06,  7.72it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5159/17710 [12:40<27:30,  7.60it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5167/17710 [12:41<27:40,  7.55it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▌                                                    | 5175/17710 [12:42<27:30,  7.59it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5183/17710 [12:43<27:24,  7.62it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5191/17710 [12:44<27:22,  7.62it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5199/17710 [12:45<27:29,  7.58it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▋                                                    | 5199/17710 [12:45<27:29,  7.58it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5207/17710 [12:46<27:30,  7.58it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5215/17710 [12:47<27:32,  7.56it/s, loss=nan]Epoch 0 - train:  29%|█████████████████████▊                                                    | 5223/17710 [12:48<27:27,  7.58it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▊                                                    | 5231/17710 [12:49<27:21,  7.60it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5239/17710 [12:50<27:17,  7.62it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5247/17710 [12:52<27:15,  7.62it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5249/17710 [12:52<27:15,  7.62it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5255/17710 [12:53<27:12,  7.63it/s, loss=nan]Epoch 0 - train:  30%|█████████████████████▉                                                    | 5263/17710 [12:54<27:13,  7.62it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5271/17710 [12:55<27:19,  7.59it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5279/17710 [12:56<27:16,  7.59it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5287/17710 [12:57<27:20,  7.57it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████                                                    | 5295/17710 [12:58<27:29,  7.53it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5299/17710 [12:59<27:29,  7.53it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5303/17710 [12:59<27:22,  7.55it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5311/17710 [13:00<27:22,  7.55it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▏                                                   | 5319/17710 [13:01<27:22,  7.55it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5327/17710 [13:02<27:21,  7.54it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5335/17710 [13:03<27:18,  7.55it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5343/17710 [13:04<27:16,  7.56it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5349/17710 [13:05<27:15,  7.56it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▎                                                   | 5351/17710 [13:05<27:12,  7.57it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5359/17710 [13:07<29:18,  7.02it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5367/17710 [13:08<28:44,  7.16it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5375/17710 [13:09<28:11,  7.29it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▍                                                   | 5383/17710 [13:10<27:52,  7.37it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5391/17710 [13:11<27:34,  7.45it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5399/17710 [13:12<27:19,  7.51it/s, loss=nan]Epoch 0 - train:  30%|██████████████████████▌                                                   | 5399/17710 [13:12<27:19,  7.51it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▌                                                   | 5407/17710 [13:13<27:06,  7.57it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5415/17710 [13:14<27:01,  7.58it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5423/17710 [13:15<26:49,  7.63it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5431/17710 [13:16<26:43,  7.66it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▋                                                   | 5439/17710 [13:17<26:39,  7.67it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5447/17710 [13:18<26:33,  7.70it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5449/17710 [13:19<26:33,  7.70it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5455/17710 [13:19<26:30,  7.71it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5463/17710 [13:20<26:43,  7.64it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▊                                                   | 5471/17710 [13:21<26:39,  7.65it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5479/17710 [13:22<26:38,  7.65it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5487/17710 [13:23<26:39,  7.64it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5495/17710 [13:24<26:50,  7.59it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5499/17710 [13:25<26:49,  7.59it/s, loss=nan]Epoch 0 - train:  31%|██████████████████████▉                                                   | 5503/17710 [13:25<26:41,  7.62it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5511/17710 [13:27<26:38,  7.63it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5519/17710 [13:28<26:30,  7.67it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████                                                   | 5527/17710 [13:29<26:27,  7.68it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5535/17710 [13:30<26:28,  7.67it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5543/17710 [13:31<26:28,  7.66it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5549/17710 [13:32<26:27,  7.66it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5551/17710 [13:32<26:29,  7.65it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▏                                                  | 5559/17710 [13:33<26:30,  7.64it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▎                                                  | 5567/17710 [13:34<26:29,  7.64it/s, loss=nan]Epoch 0 - train:  31%|███████████████████████▎                                                  | 5575/17710 [13:35<26:31,  7.63it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▎                                                  | 5583/17710 [13:36<26:31,  7.62it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▎                                                  | 5591/17710 [13:37<26:40,  7.57it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5599/17710 [13:38<26:37,  7.58it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5599/17710 [13:38<26:37,  7.58it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5607/17710 [13:39<26:42,  7.55it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5615/17710 [13:40<26:45,  7.53it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▍                                                  | 5623/17710 [13:41<26:43,  7.54it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5631/17710 [13:42<26:44,  7.53it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5639/17710 [13:43<26:38,  7.55it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5647/17710 [13:44<26:36,  7.56it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▌                                                  | 5649/17710 [13:45<26:36,  7.56it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5655/17710 [13:45<26:42,  7.52it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5663/17710 [13:47<26:31,  7.57it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5671/17710 [13:48<26:34,  7.55it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▋                                                  | 5679/17710 [13:49<26:50,  7.47it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5687/17710 [13:50<26:43,  7.50it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5695/17710 [13:51<26:39,  7.51it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5699/17710 [13:52<26:39,  7.51it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5703/17710 [13:52<27:27,  7.29it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▊                                                  | 5711/17710 [13:53<27:31,  7.27it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5719/17710 [13:54<28:53,  6.92it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5726/17710 [13:56<30:06,  6.63it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5733/17710 [13:57<30:06,  6.63it/s, loss=nan]Epoch 0 - train:  32%|███████████████████████▉                                                  | 5741/17710 [13:58<29:00,  6.88it/s, loss=nan]Epoch 0 - train:  32%|████████████████████████                                                  | 5748/17710 [13:59<29:21,  6.79it/s, loss=nan]Epoch 0 - train:  32%|████████████████████████                                                  | 5749/17710 [13:59<29:21,  6.79it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████                                                  | 5756/17710 [14:00<28:26,  7.00it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████                                                  | 5764/17710 [14:01<27:48,  7.16it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████                                                  | 5772/17710 [14:02<27:17,  7.29it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5780/17710 [14:03<27:03,  7.35it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5788/17710 [14:04<27:04,  7.34it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5796/17710 [14:05<27:36,  7.19it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▏                                                 | 5799/17710 [14:06<27:35,  7.19it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5804/17710 [14:06<28:23,  6.99it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5812/17710 [14:08<27:42,  7.15it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5820/17710 [14:09<27:15,  7.27it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▎                                                 | 5828/17710 [14:10<26:48,  7.39it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5836/17710 [14:11<26:32,  7.45it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5844/17710 [14:12<26:16,  7.52it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5849/17710 [14:13<26:16,  7.52it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5852/17710 [14:13<26:10,  7.55it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▍                                                 | 5860/17710 [14:14<26:05,  7.57it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5868/17710 [14:15<25:53,  7.62it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5876/17710 [14:16<25:52,  7.62it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5884/17710 [14:17<26:06,  7.55it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▌                                                 | 5892/17710 [14:18<26:13,  7.51it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5899/17710 [14:19<26:12,  7.51it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5900/17710 [14:19<26:20,  7.47it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5908/17710 [14:20<26:19,  7.47it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▋                                                 | 5916/17710 [14:21<26:36,  7.39it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▊                                                 | 5924/17710 [14:22<26:28,  7.42it/s, loss=nan]Epoch 0 - train:  33%|████████████████████████▊                                                 | 5932/17710 [14:23<26:18,  7.46it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5940/17710 [14:25<26:08,  7.50it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5948/17710 [14:26<26:12,  7.48it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▊                                                 | 5949/17710 [14:26<26:12,  7.48it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5956/17710 [14:27<26:02,  7.52it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5964/17710 [14:28<26:02,  7.52it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5972/17710 [14:29<25:58,  7.53it/s, loss=nan]Epoch 0 - train:  34%|████████████████████████▉                                                 | 5980/17710 [14:30<25:50,  7.56it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5988/17710 [14:31<25:55,  7.53it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5996/17710 [14:32<25:51,  7.55it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 5999/17710 [14:32<25:51,  7.55it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 6004/17710 [14:33<25:47,  7.56it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████                                                 | 6012/17710 [14:34<25:43,  7.58it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6020/17710 [14:35<25:46,  7.56it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6028/17710 [14:36<25:44,  7.56it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▏                                                | 6036/17710 [14:37<25:43,  7.56it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6044/17710 [14:38<25:47,  7.54it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6049/17710 [14:39<25:47,  7.54it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6052/17710 [14:39<26:03,  7.46it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6060/17710 [14:40<25:59,  7.47it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▎                                                | 6068/17710 [14:42<25:51,  7.50it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6076/17710 [14:43<25:43,  7.54it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6084/17710 [14:44<25:40,  7.55it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6092/17710 [14:45<25:50,  7.49it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6099/17710 [14:46<25:49,  7.49it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▍                                                | 6100/17710 [14:46<25:39,  7.54it/s, loss=nan]Epoch 0 - train:  34%|█████████████████████████▌                                                | 6108/17710 [14:47<25:33,  7.57it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6116/17710 [14:48<25:27,  7.59it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6124/17710 [14:49<25:29,  7.57it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▌                                                | 6132/17710 [14:50<25:26,  7.59it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6140/17710 [14:51<25:19,  7.62it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6148/17710 [14:52<25:12,  7.64it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6149/17710 [14:52<25:12,  7.64it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▋                                                | 6156/17710 [14:53<25:09,  7.65it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6164/17710 [14:54<25:09,  7.65it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6172/17710 [14:55<25:09,  7.64it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6180/17710 [14:56<25:06,  7.65it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▊                                                | 6188/17710 [14:57<25:03,  7.66it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6196/17710 [14:58<24:58,  7.68it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6199/17710 [14:59<24:57,  7.68it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6204/17710 [14:59<24:56,  7.69it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6212/17710 [15:00<24:56,  7.68it/s, loss=nan]Epoch 0 - train:  35%|█████████████████████████▉                                                | 6220/17710 [15:01<24:48,  7.72it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6228/17710 [15:02<24:55,  7.68it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6236/17710 [15:04<25:43,  7.44it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6244/17710 [15:05<26:36,  7.18it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6249/17710 [15:06<26:35,  7.18it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████                                                | 6252/17710 [15:06<27:42,  6.89it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6259/17710 [15:07<30:01,  6.36it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6267/17710 [15:09<28:53,  6.60it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▏                                               | 6275/17710 [15:10<27:54,  6.83it/s, loss=nan]Epoch 0 - train:  35%|██████████████████████████▎                                               | 6283/17710 [15:11<27:18,  6.97it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6291/17710 [15:12<26:42,  7.13it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6299/17710 [15:13<26:12,  7.26it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6299/17710 [15:13<26:12,  7.26it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▎                                               | 6307/17710 [15:14<25:49,  7.36it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6315/17710 [15:15<25:37,  7.41it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6323/17710 [15:16<25:31,  7.43it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6331/17710 [15:17<25:20,  7.48it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▍                                               | 6339/17710 [15:18<25:17,  7.49it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6347/17710 [15:19<25:20,  7.47it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6349/17710 [15:20<25:20,  7.47it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6355/17710 [15:20<25:06,  7.54it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6363/17710 [15:21<25:04,  7.54it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▌                                               | 6371/17710 [15:22<25:02,  7.55it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6379/17710 [15:23<25:12,  7.49it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6387/17710 [15:24<25:02,  7.53it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6395/17710 [15:26<25:07,  7.51it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▋                                               | 6399/17710 [15:26<25:06,  7.51it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6403/17710 [15:27<25:02,  7.52it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6411/17710 [15:28<24:59,  7.53it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6419/17710 [15:29<24:58,  7.54it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▊                                               | 6427/17710 [15:30<25:07,  7.49it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6435/17710 [15:31<25:53,  7.26it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6443/17710 [15:32<25:31,  7.36it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6449/17710 [15:33<25:30,  7.36it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6451/17710 [15:33<25:12,  7.45it/s, loss=nan]Epoch 0 - train:  36%|██████████████████████████▉                                               | 6459/17710 [15:35<28:05,  6.67it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6467/17710 [15:36<27:22,  6.84it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6475/17710 [15:37<26:32,  7.05it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6483/17710 [15:38<25:58,  7.20it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████                                               | 6491/17710 [15:39<25:32,  7.32it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6499/17710 [15:40<25:16,  7.39it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6499/17710 [15:40<25:16,  7.39it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6507/17710 [15:41<25:08,  7.43it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▏                                              | 6515/17710 [15:42<24:54,  7.49it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6523/17710 [15:43<24:54,  7.49it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6531/17710 [15:44<24:42,  7.54it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6539/17710 [15:45<24:30,  7.60it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6547/17710 [15:46<24:23,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▎                                              | 6549/17710 [15:47<24:23,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6555/17710 [15:47<24:22,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6563/17710 [15:48<24:13,  7.67it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6571/17710 [15:49<24:10,  7.68it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▍                                              | 6579/17710 [15:50<24:18,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6587/17710 [15:51<24:14,  7.65it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6595/17710 [15:52<24:08,  7.67it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6599/17710 [15:53<24:08,  7.67it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6603/17710 [15:54<24:10,  7.66it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▌                                              | 6611/17710 [15:55<24:21,  7.59it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6619/17710 [15:56<24:18,  7.61it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6627/17710 [15:57<24:13,  7.63it/s, loss=nan]Epoch 0 - train:  37%|███████████████████████████▋                                              | 6635/17710 [15:58<24:21,  7.58it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6643/17710 [15:59<24:11,  7.62it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6649/17710 [16:00<24:10,  7.62it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6651/17710 [16:00<24:07,  7.64it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6659/17710 [16:01<24:06,  7.64it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▊                                              | 6667/17710 [16:02<24:12,  7.60it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6675/17710 [16:03<24:14,  7.59it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6683/17710 [16:04<24:09,  7.61it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6691/17710 [16:05<24:09,  7.60it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6699/17710 [16:06<24:11,  7.59it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▉                                              | 6699/17710 [16:17<24:11,  7.59it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▎                                            | 6707/17710 [16:20<1:54:38,  1.60it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▎                                            | 6714/17710 [16:21<1:30:31,  2.02it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▎                                            | 6722/17710 [16:23<1:13:32,  2.49it/s, loss=nan]Epoch 0 - train:  38%|███████████████████████████▎                                            | 6729/17710 [16:25<1:05:19,  2.80it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6735/17710 [16:26<58:22,  3.13it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6741/17710 [16:27<51:42,  3.54it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6747/17710 [16:28<47:39,  3.83it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6749/17710 [16:29<47:39,  3.83it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▏                                             | 6755/17710 [16:29<40:12,  4.54it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6761/17710 [16:30<37:39,  4.85it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6768/17710 [16:31<34:57,  5.22it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6776/17710 [16:32<31:16,  5.83it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▎                                             | 6784/17710 [16:34<28:43,  6.34it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6792/17710 [16:35<27:09,  6.70it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6799/17710 [16:36<27:08,  6.70it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6800/17710 [16:36<26:01,  6.99it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6808/17710 [16:37<25:27,  7.14it/s, loss=nan]Epoch 0 - train:  38%|████████████████████████████▍                                             | 6816/17710 [16:38<24:56,  7.28it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6824/17710 [16:39<24:31,  7.40it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6832/17710 [16:40<24:28,  7.41it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6840/17710 [16:41<24:40,  7.34it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6848/17710 [16:42<24:21,  7.43it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▌                                             | 6849/17710 [16:42<24:21,  7.43it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6856/17710 [16:43<24:08,  7.49it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6864/17710 [16:44<24:13,  7.46it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6872/17710 [16:45<24:12,  7.46it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▋                                             | 6880/17710 [16:46<24:02,  7.51it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6888/17710 [16:47<23:54,  7.54it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6896/17710 [16:48<23:51,  7.55it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6899/17710 [16:49<23:51,  7.55it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▊                                             | 6904/17710 [16:49<23:47,  7.57it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6912/17710 [16:50<23:43,  7.58it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6920/17710 [16:51<23:38,  7.61it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6928/17710 [16:53<23:35,  7.62it/s, loss=nan]Epoch 0 - train:  39%|████████████████████████████▉                                             | 6936/17710 [16:54<23:31,  7.63it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6944/17710 [16:55<23:23,  7.67it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6949/17710 [16:55<23:23,  7.67it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6952/17710 [16:56<23:23,  7.66it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6960/17710 [16:57<23:19,  7.68it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████                                             | 6968/17710 [16:58<23:23,  7.65it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6976/17710 [16:59<23:30,  7.61it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6984/17710 [17:00<23:29,  7.61it/s, loss=nan]Epoch 0 - train:  39%|█████████████████████████████▏                                            | 6992/17710 [17:01<23:28,  7.61it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▏                                            | 6999/17710 [17:02<23:27,  7.61it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▏                                            | 7000/17710 [17:02<23:34,  7.57it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7008/17710 [17:03<23:35,  7.56it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7016/17710 [17:04<23:32,  7.57it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▎                                            | 7024/17710 [17:05<23:34,  7.55it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7032/17710 [17:06<23:32,  7.56it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7040/17710 [17:09<33:07,  5.37it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7047/17710 [17:11<36:34,  4.86it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7049/17710 [17:12<36:34,  4.86it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▍                                            | 7053/17710 [17:12<39:45,  4.47it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7061/17710 [17:13<34:59,  5.07it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7069/17710 [17:14<31:14,  5.68it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7077/17710 [17:15<28:50,  6.15it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▌                                            | 7085/17710 [17:16<27:03,  6.55it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7093/17710 [17:18<25:50,  6.85it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7099/17710 [17:18<25:49,  6.85it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7101/17710 [17:19<25:03,  7.06it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7109/17710 [17:20<24:27,  7.23it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▋                                            | 7117/17710 [17:21<23:58,  7.36it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7125/17710 [17:22<23:39,  7.45it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7133/17710 [17:23<23:28,  7.51it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7141/17710 [17:24<23:20,  7.54it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7149/17710 [17:25<23:14,  7.57it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▊                                            | 7149/17710 [17:25<23:14,  7.57it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▉                                            | 7157/17710 [17:26<23:10,  7.59it/s, loss=nan]Epoch 0 - train:  40%|█████████████████████████████▉                                            | 7165/17710 [17:27<23:20,  7.53it/s, loss=nan]Epoch 0 - train:  41%|█████████████████████████████▉                                            | 7173/17710 [17:28<23:12,  7.57it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7181/17710 [17:29<23:16,  7.54it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7189/17710 [17:30<23:11,  7.56it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7197/17710 [17:31<23:06,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7199/17710 [17:32<23:06,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████                                            | 7205/17710 [17:32<23:03,  7.59it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7213/17710 [17:33<23:07,  7.56it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7221/17710 [17:34<23:04,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7229/17710 [17:35<23:01,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▏                                           | 7237/17710 [17:36<23:09,  7.54it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7245/17710 [17:38<23:09,  7.53it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7249/17710 [17:38<23:09,  7.53it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7253/17710 [17:39<23:11,  7.52it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7261/17710 [17:40<23:11,  7.51it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▎                                           | 7269/17710 [17:41<23:01,  7.56it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7277/17710 [17:42<22:53,  7.59it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7285/17710 [17:43<22:46,  7.63it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7293/17710 [17:44<22:53,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▍                                           | 7299/17710 [17:45<22:53,  7.58it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7301/17710 [17:45<22:49,  7.60it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7309/17710 [17:46<22:49,  7.59it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7317/17710 [17:47<22:48,  7.59it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▌                                           | 7325/17710 [17:48<22:44,  7.61it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7333/17710 [17:49<22:45,  7.60it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7341/17710 [17:50<22:46,  7.59it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7349/17710 [17:51<22:58,  7.52it/s, loss=nan]Epoch 0 - train:  41%|██████████████████████████████▋                                           | 7349/17710 [17:51<22:58,  7.52it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▋                                           | 7357/17710 [17:52<23:00,  7.50it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7365/17710 [17:53<22:51,  7.54it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7373/17710 [17:54<22:48,  7.55it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7381/17710 [17:56<23:10,  7.43it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▊                                           | 7389/17710 [17:57<23:09,  7.43it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7397/17710 [17:58<22:56,  7.49it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7399/17710 [17:58<22:55,  7.49it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7405/17710 [17:59<22:53,  7.50it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▉                                           | 7413/17710 [18:00<22:45,  7.54it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7421/17710 [18:01<22:36,  7.58it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7429/17710 [18:02<22:34,  7.59it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7437/17710 [18:03<22:29,  7.61it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████                                           | 7445/17710 [18:04<22:27,  7.62it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7449/17710 [18:05<22:27,  7.62it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7453/17710 [18:05<22:22,  7.64it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▏                                          | 7461/17710 [18:06<22:16,  7.67it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▎                                         | 7469/17710 [18:19<1:36:45,  1.76it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▍                                         | 7473/17710 [18:20<1:30:02,  1.89it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▍                                         | 7480/17710 [18:21<1:10:12,  2.43it/s, loss=nan]Epoch 0 - train:  42%|██████████████████████████████▍                                         | 7487/17710 [18:23<1:01:54,  2.75it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7493/17710 [18:24<56:55,  2.99it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7499/17710 [18:26<49:37,  3.43it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7499/17710 [18:26<49:37,  3.43it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▎                                          | 7505/17710 [18:27<45:03,  3.77it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▍                                          | 7511/17710 [18:28<40:17,  4.22it/s, loss=nan]Epoch 0 - train:  42%|███████████████████████████████▍                                          | 7519/17710 [18:29<34:02,  4.99it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▍                                          | 7527/17710 [18:30<30:12,  5.62it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▍                                          | 7535/17710 [18:31<27:46,  6.11it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7543/17710 [18:32<25:59,  6.52it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7549/17710 [18:33<25:58,  6.52it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7551/17710 [18:33<24:49,  6.82it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7559/17710 [18:34<23:57,  7.06it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▌                                          | 7567/17710 [18:35<23:26,  7.21it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7575/17710 [18:36<23:13,  7.27it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7583/17710 [18:37<22:54,  7.37it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▋                                          | 7591/17710 [18:38<22:42,  7.43it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7599/17710 [18:39<22:31,  7.48it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7599/17710 [18:40<22:31,  7.48it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7607/17710 [18:40<22:20,  7.54it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7615/17710 [18:42<22:18,  7.54it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▊                                          | 7623/17710 [18:43<22:09,  7.59it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7631/17710 [18:44<22:03,  7.61it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7639/17710 [18:45<22:04,  7.61it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7647/17710 [18:46<22:04,  7.60it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7649/17710 [18:46<22:04,  7.60it/s, loss=nan]Epoch 0 - train:  43%|███████████████████████████████▉                                          | 7655/17710 [18:47<21:58,  7.63it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7663/17710 [18:48<21:51,  7.66it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7671/17710 [18:49<21:45,  7.69it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7679/17710 [18:50<21:39,  7.72it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████                                          | 7687/17710 [18:51<21:35,  7.74it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7695/17710 [18:52<21:37,  7.72it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7699/17710 [18:53<21:37,  7.72it/s, loss=nan]Epoch 0 - train:  43%|████████████████████████████████▏                                         | 7703/17710 [18:53<21:39,  7.70it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▏                                         | 7711/17710 [18:54<21:38,  7.70it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7719/17710 [18:55<21:34,  7.72it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7727/17710 [18:56<21:30,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7735/17710 [18:57<21:28,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▎                                         | 7743/17710 [18:58<21:27,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7749/17710 [18:59<21:26,  7.74it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7751/17710 [18:59<21:30,  7.72it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7759/17710 [19:00<21:28,  7.72it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7767/17710 [19:01<21:34,  7.68it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▍                                         | 7775/17710 [19:02<21:49,  7.58it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7783/17710 [19:03<21:40,  7.63it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7791/17710 [19:04<21:37,  7.64it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7799/17710 [19:05<21:31,  7.67it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7799/17710 [19:06<21:31,  7.67it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▌                                         | 7807/17710 [19:07<26:35,  6.21it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7814/17710 [19:09<31:27,  5.24it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7820/17710 [19:10<31:00,  5.32it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7828/17710 [19:11<28:24,  5.80it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▋                                         | 7836/17710 [19:12<26:15,  6.27it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7844/17710 [19:14<24:47,  6.63it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7849/17710 [19:14<24:46,  6.63it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7852/17710 [19:15<23:45,  6.92it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▊                                         | 7860/17710 [19:16<23:24,  7.01it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▉                                         | 7868/17710 [19:17<22:55,  7.15it/s, loss=nan]Epoch 0 - train:  44%|████████████████████████████████▉                                         | 7876/17710 [19:18<22:29,  7.29it/s, loss=nan]Epoch 0 - train:  45%|████████████████████████████████▉                                         | 7884/17710 [19:19<22:18,  7.34it/s, loss=nan]Epoch 0 - train:  45%|████████████████████████████████▉                                         | 7892/17710 [19:20<22:21,  7.32it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7899/17710 [19:21<22:20,  7.32it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7900/17710 [19:21<22:11,  7.37it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7908/17710 [19:22<21:57,  7.44it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7916/17710 [19:23<21:45,  7.50it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████                                         | 7924/17710 [19:24<21:35,  7.55it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7932/17710 [19:25<21:28,  7.59it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7940/17710 [19:26<21:24,  7.61it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7948/17710 [19:27<21:21,  7.62it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7949/17710 [19:28<21:21,  7.62it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▏                                        | 7956/17710 [19:28<21:17,  7.64it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7964/17710 [19:29<21:16,  7.64it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7972/17710 [19:30<21:13,  7.64it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▎                                        | 7980/17710 [19:31<21:11,  7.65it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7988/17710 [19:33<21:13,  7.63it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7996/17710 [19:34<21:15,  7.62it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 7999/17710 [19:34<21:14,  7.62it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 8004/17710 [19:35<21:13,  7.62it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▍                                        | 8012/17710 [19:36<21:14,  7.61it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8020/17710 [19:37<21:09,  7.63it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8028/17710 [19:38<21:05,  7.65it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8036/17710 [19:39<21:03,  7.66it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▌                                        | 8044/17710 [19:40<20:59,  7.68it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▋                                        | 8049/17710 [19:41<20:58,  7.68it/s, loss=nan]Epoch 0 - train:  45%|█████████████████████████████████▋                                        | 8052/17710 [19:41<21:04,  7.64it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8060/17710 [19:42<21:11,  7.59it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8068/17710 [19:43<21:20,  7.53it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▋                                        | 8076/17710 [19:44<21:09,  7.59it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8084/17710 [19:45<21:06,  7.60it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8092/17710 [19:46<21:14,  7.55it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8099/17710 [19:47<21:13,  7.55it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▊                                        | 8100/17710 [19:47<21:11,  7.56it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8108/17710 [19:48<21:16,  7.52it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8116/17710 [19:49<21:23,  7.48it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8124/17710 [19:50<21:12,  7.53it/s, loss=nan]Epoch 0 - train:  46%|█████████████████████████████████▉                                        | 8132/17710 [19:52<21:03,  7.58it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8140/17710 [19:53<20:59,  7.60it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8148/17710 [19:54<21:01,  7.58it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8149/17710 [19:54<21:00,  7.58it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8156/17710 [19:55<20:52,  7.63it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████                                        | 8164/17710 [19:56<20:44,  7.67it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8172/17710 [19:57<20:41,  7.68it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8180/17710 [19:58<20:37,  7.70it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8188/17710 [19:59<20:34,  7.71it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▏                                       | 8196/17710 [20:00<20:35,  7.70it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8199/17710 [20:00<20:35,  7.70it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8204/17710 [20:01<20:34,  7.70it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8212/17710 [20:02<20:29,  7.72it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▎                                       | 8220/17710 [20:03<20:27,  7.73it/s, loss=nan]Epoch 0 - train:  46%|██████████████████████████████████▍                                       | 8228/17710 [20:04<20:34,  7.68it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8236/17710 [20:05<20:45,  7.61it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8244/17710 [20:06<20:41,  7.62it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8249/17710 [20:08<20:41,  7.62it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▍                                       | 8252/17710 [20:08<24:33,  6.42it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8260/17710 [20:09<23:23,  6.73it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8268/17710 [20:10<24:34,  6.40it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8276/17710 [20:11<23:25,  6.71it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▌                                       | 8284/17710 [20:12<22:37,  6.95it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8292/17710 [20:13<22:08,  7.09it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8299/17710 [20:15<22:07,  7.09it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8300/17710 [20:15<21:46,  7.20it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8308/17710 [20:16<21:24,  7.32it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▋                                       | 8316/17710 [20:17<21:11,  7.39it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8324/17710 [20:18<21:03,  7.43it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8332/17710 [20:19<20:52,  7.49it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▊                                       | 8340/17710 [20:20<20:46,  7.52it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8348/17710 [20:21<20:38,  7.56it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8349/17710 [20:21<20:38,  7.56it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8356/17710 [20:22<20:34,  7.58it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8364/17710 [20:23<20:30,  7.59it/s, loss=nan]Epoch 0 - train:  47%|██████████████████████████████████▉                                       | 8372/17710 [20:24<20:29,  7.60it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8380/17710 [20:25<20:28,  7.59it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8388/17710 [20:26<20:28,  7.59it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8396/17710 [20:27<20:26,  7.59it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8399/17710 [20:28<20:26,  7.59it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████                                       | 8404/17710 [20:28<20:46,  7.46it/s, loss=nan]Epoch 0 - train:  47%|███████████████████████████████████▏                                      | 8412/17710 [20:29<20:43,  7.48it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8420/17710 [20:30<20:36,  7.52it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8428/17710 [20:31<20:29,  7.55it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▏                                      | 8436/17710 [20:33<20:30,  7.54it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8444/17710 [20:34<20:29,  7.54it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8449/17710 [20:34<20:28,  7.54it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8452/17710 [20:35<20:26,  7.55it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▎                                      | 8460/17710 [20:36<20:21,  7.57it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8468/17710 [20:37<20:21,  7.57it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8476/17710 [20:38<20:13,  7.61it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8484/17710 [20:39<20:10,  7.62it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▍                                      | 8492/17710 [20:40<20:06,  7.64it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8499/17710 [20:41<20:05,  7.64it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8500/17710 [20:41<20:01,  7.67it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8508/17710 [20:42<20:01,  7.66it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8516/17710 [20:43<20:01,  7.65it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▌                                      | 8524/17710 [20:44<19:56,  7.68it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8532/17710 [20:45<19:52,  7.70it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8540/17710 [20:46<19:48,  7.72it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8548/17710 [20:47<19:46,  7.72it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▋                                      | 8549/17710 [20:47<19:46,  7.72it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8556/17710 [20:48<19:47,  7.71it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8564/17710 [20:49<19:45,  7.71it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8572/17710 [20:50<19:51,  7.67it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▊                                      | 8580/17710 [20:51<19:49,  7.68it/s, loss=nan]Epoch 0 - train:  48%|███████████████████████████████████▉                                      | 8588/17710 [20:52<19:53,  7.64it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8596/17710 [20:53<19:52,  7.64it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8599/17710 [20:54<19:52,  7.64it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8604/17710 [20:54<19:52,  7.64it/s, loss=nan]Epoch 0 - train:  49%|███████████████████████████████████▉                                      | 8612/17710 [20:56<19:53,  7.62it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8620/17710 [20:57<19:51,  7.63it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8628/17710 [20:58<19:51,  7.62it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8636/17710 [20:59<19:51,  7.61it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████                                      | 8644/17710 [21:00<19:53,  7.60it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8649/17710 [21:01<19:52,  7.60it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8652/17710 [21:01<19:53,  7.59it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8660/17710 [21:02<19:50,  7.60it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▏                                     | 8668/17710 [21:03<19:56,  7.56it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8676/17710 [21:04<19:52,  7.58it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8684/17710 [21:05<19:51,  7.58it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8692/17710 [21:06<19:49,  7.58it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8699/17710 [21:07<19:49,  7.58it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▎                                     | 8700/17710 [21:07<21:01,  7.14it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8708/17710 [21:08<20:38,  7.27it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8716/17710 [21:09<20:20,  7.37it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8724/17710 [21:10<20:08,  7.44it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▍                                     | 8732/17710 [21:12<20:05,  7.45it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8740/17710 [21:13<19:55,  7.50it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8748/17710 [21:14<19:59,  7.47it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8749/17710 [21:14<19:58,  7.47it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8756/17710 [21:15<19:52,  7.51it/s, loss=nan]Epoch 0 - train:  49%|████████████████████████████████████▌                                     | 8764/17710 [21:16<19:45,  7.54it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8772/17710 [21:17<19:42,  7.56it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8780/17710 [21:18<19:48,  7.52it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▋                                     | 8788/17710 [21:19<19:47,  7.52it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8796/17710 [21:20<19:43,  7.53it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8799/17710 [21:21<19:43,  7.53it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8804/17710 [21:21<19:43,  7.52it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8812/17710 [21:22<19:40,  7.54it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▊                                     | 8820/17710 [21:23<19:33,  7.57it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8828/17710 [21:24<19:34,  7.56it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8836/17710 [21:25<19:25,  7.61it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8844/17710 [21:26<19:19,  7.65it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8849/17710 [21:27<19:19,  7.65it/s, loss=nan]Epoch 0 - train:  50%|████████████████████████████████████▉                                     | 8852/17710 [21:27<19:16,  7.66it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8860/17710 [21:28<19:14,  7.67it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8868/17710 [21:29<19:13,  7.66it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8876/17710 [21:31<19:16,  7.64it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████                                     | 8884/17710 [21:32<19:12,  7.66it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8892/17710 [21:33<19:09,  7.67it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8899/17710 [21:34<19:08,  7.67it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8900/17710 [21:34<19:08,  7.67it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▏                                    | 8908/17710 [21:35<19:05,  7.69it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8916/17710 [21:36<19:01,  7.70it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8924/17710 [21:37<19:04,  7.68it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8932/17710 [21:38<19:03,  7.68it/s, loss=nan]Epoch 0 - train:  50%|█████████████████████████████████████▎                                    | 8940/17710 [21:39<19:02,  7.68it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8948/17710 [21:40<19:11,  7.61it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8949/17710 [21:40<19:10,  7.61it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8956/17710 [21:41<19:12,  7.59it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8964/17710 [21:42<19:15,  7.57it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▍                                    | 8972/17710 [21:43<19:23,  7.51it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8980/17710 [21:44<19:27,  7.48it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8988/17710 [21:45<19:29,  7.46it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8996/17710 [21:46<19:23,  7.49it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 8999/17710 [21:47<19:22,  7.49it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▌                                    | 9004/17710 [21:47<19:14,  7.54it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9012/17710 [21:48<19:10,  7.56it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9020/17710 [21:49<19:11,  7.55it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▋                                    | 9028/17710 [21:51<19:13,  7.53it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9036/17710 [21:52<19:08,  7.55it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9044/17710 [21:53<19:05,  7.57it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9049/17710 [21:53<19:04,  7.57it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9052/17710 [21:54<19:02,  7.58it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▊                                    | 9060/17710 [21:55<19:04,  7.56it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9068/17710 [21:56<19:01,  7.57it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9076/17710 [21:57<19:01,  7.56it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9084/17710 [21:58<19:13,  7.48it/s, loss=nan]Epoch 0 - train:  51%|█████████████████████████████████████▉                                    | 9092/17710 [21:59<19:13,  7.47it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9099/17710 [22:00<19:12,  7.47it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9100/17710 [22:00<19:14,  7.46it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9108/17710 [22:01<19:08,  7.49it/s, loss=nan]Epoch 0 - train:  51%|██████████████████████████████████████                                    | 9116/17710 [22:02<18:59,  7.54it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████                                    | 9124/17710 [22:03<18:55,  7.56it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9132/17710 [22:04<19:04,  7.49it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9140/17710 [22:05<19:08,  7.46it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9148/17710 [22:07<19:06,  7.47it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▏                                   | 9149/17710 [22:07<19:06,  7.47it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9156/17710 [22:08<21:00,  6.79it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9164/17710 [22:09<20:20,  7.00it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9172/17710 [22:10<19:49,  7.18it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▎                                   | 9180/17710 [22:11<19:27,  7.30it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9188/17710 [22:12<19:11,  7.40it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9196/17710 [22:13<19:01,  7.46it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9199/17710 [22:14<19:00,  7.46it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9204/17710 [22:14<18:52,  7.51it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▍                                   | 9212/17710 [22:15<18:55,  7.48it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9220/17710 [22:16<18:53,  7.49it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9228/17710 [22:17<18:48,  7.51it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▌                                   | 9236/17710 [22:19<18:38,  7.58it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9244/17710 [22:20<18:30,  7.62it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9249/17710 [22:20<18:30,  7.62it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9252/17710 [22:21<18:28,  7.63it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9260/17710 [22:22<18:24,  7.65it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▋                                   | 9268/17710 [22:23<18:20,  7.67it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9276/17710 [22:24<18:19,  7.67it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9284/17710 [22:25<18:21,  7.65it/s, loss=nan]Epoch 0 - train:  52%|██████████████████████████████████████▊                                   | 9292/17710 [22:26<18:17,  7.67it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▊                                   | 9299/17710 [22:27<18:16,  7.67it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▊                                   | 9300/17710 [22:27<18:15,  7.68it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9308/17710 [22:28<18:19,  7.64it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9316/17710 [22:29<18:27,  7.58it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9324/17710 [22:30<18:30,  7.55it/s, loss=nan]Epoch 0 - train:  53%|██████████████████████████████████████▉                                   | 9332/17710 [22:31<18:26,  7.57it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9340/17710 [22:32<18:24,  7.58it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9348/17710 [22:33<18:25,  7.56it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9349/17710 [22:33<18:25,  7.56it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████                                   | 9356/17710 [22:34<18:26,  7.55it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9364/17710 [22:35<18:21,  7.58it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9372/17710 [22:36<18:20,  7.57it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9380/17710 [22:37<18:20,  7.57it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▏                                  | 9388/17710 [22:39<18:20,  7.56it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9396/17710 [22:40<18:24,  7.53it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9399/17710 [22:40<18:24,  7.53it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9404/17710 [22:41<18:22,  7.53it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9412/17710 [22:42<18:20,  7.54it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▎                                  | 9420/17710 [22:43<18:26,  7.49it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9428/17710 [22:44<18:21,  7.52it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9436/17710 [22:45<18:17,  7.54it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9444/17710 [22:46<18:15,  7.54it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9449/17710 [22:47<18:15,  7.54it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▍                                  | 9452/17710 [22:47<18:13,  7.55it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▌                                  | 9460/17710 [22:48<18:14,  7.54it/s, loss=nan]Epoch 0 - train:  53%|███████████████████████████████████████▌                                  | 9468/17710 [22:49<18:13,  7.54it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▌                                  | 9476/17710 [22:50<18:13,  7.53it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9484/17710 [22:51<18:07,  7.56it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9492/17710 [22:52<18:15,  7.50it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9499/17710 [22:53<18:14,  7.50it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9500/17710 [22:53<18:22,  7.45it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▋                                  | 9508/17710 [22:54<18:19,  7.46it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9516/17710 [22:56<18:20,  7.45it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9524/17710 [22:57<18:29,  7.38it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9532/17710 [22:58<18:22,  7.42it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▊                                  | 9540/17710 [22:59<18:12,  7.48it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9548/17710 [23:00<18:07,  7.51it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9549/17710 [23:00<18:07,  7.51it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9556/17710 [23:01<18:05,  7.52it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9564/17710 [23:02<18:08,  7.49it/s, loss=nan]Epoch 0 - train:  54%|███████████████████████████████████████▉                                  | 9572/17710 [23:03<18:05,  7.50it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9580/17710 [23:04<18:04,  7.50it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9588/17710 [23:05<18:00,  7.52it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9596/17710 [23:06<17:58,  7.52it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████                                  | 9599/17710 [23:07<17:58,  7.52it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9604/17710 [23:08<20:25,  6.61it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9611/17710 [23:09<20:18,  6.65it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9619/17710 [23:10<19:28,  6.92it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▏                                 | 9627/17710 [23:11<18:50,  7.15it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9635/17710 [23:12<18:25,  7.30it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9643/17710 [23:13<18:04,  7.44it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9649/17710 [23:14<18:03,  7.44it/s, loss=nan]Epoch 0 - train:  54%|████████████████████████████████████████▎                                 | 9651/17710 [23:14<18:01,  7.45it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▎                                 | 9659/17710 [23:15<18:00,  7.45it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9667/17710 [23:16<17:52,  7.50it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9675/17710 [23:17<17:43,  7.55it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9683/17710 [23:18<17:37,  7.59it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▍                                 | 9691/17710 [23:19<17:32,  7.62it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9699/17710 [23:20<17:29,  7.63it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9699/17710 [23:20<17:29,  7.63it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9707/17710 [23:21<17:29,  7.63it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▌                                 | 9715/17710 [23:22<17:32,  7.59it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9723/17710 [23:24<17:48,  7.48it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9731/17710 [23:25<17:48,  7.47it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9739/17710 [23:26<17:52,  7.43it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9747/17710 [23:27<17:56,  7.40it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▋                                 | 9749/17710 [23:27<17:56,  7.40it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9755/17710 [23:28<17:57,  7.38it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9763/17710 [23:29<17:51,  7.41it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9771/17710 [23:30<17:50,  7.41it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▊                                 | 9779/17710 [23:31<17:41,  7.47it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9787/17710 [23:32<17:34,  7.51it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9795/17710 [23:33<17:27,  7.56it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9799/17710 [23:34<17:27,  7.56it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9803/17710 [23:34<17:32,  7.51it/s, loss=nan]Epoch 0 - train:  55%|████████████████████████████████████████▉                                 | 9811/17710 [23:35<17:27,  7.54it/s, loss=nan]Epoch 0 - train:  55%|█████████████████████████████████████████                                 | 9819/17710 [23:36<17:24,  7.56it/s, loss=nan]Epoch 0 - train:  55%|█████████████████████████████████████████                                 | 9827/17710 [23:37<17:23,  7.55it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████                                 | 9835/17710 [23:39<17:28,  7.51it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9843/17710 [23:40<17:38,  7.43it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9849/17710 [23:41<17:38,  7.43it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9851/17710 [23:41<18:03,  7.25it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9859/17710 [23:42<17:42,  7.39it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                                | 9867/17710 [23:43<17:31,  7.46it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9875/17710 [23:44<17:31,  7.45it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9883/17710 [23:45<17:29,  7.46it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9891/17710 [23:46<17:18,  7.53it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9899/17710 [23:47<17:23,  7.49it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▎                                | 9899/17710 [23:47<17:23,  7.49it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9907/17710 [23:48<17:14,  7.54it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9915/17710 [23:49<17:06,  7.59it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9923/17710 [23:50<17:01,  7.62it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▍                                | 9931/17710 [23:51<16:59,  7.63it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9939/17710 [23:52<16:55,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9947/17710 [23:53<16:50,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9949/17710 [23:54<16:49,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▌                                | 9955/17710 [23:54<16:53,  7.65it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9963/17710 [23:55<16:52,  7.65it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9971/17710 [23:57<16:48,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9979/17710 [23:58<16:46,  7.68it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▋                                | 9987/17710 [23:59<16:48,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▊                                | 9995/17710 [24:00<16:47,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▊                                | 9999/17710 [24:00<16:47,  7.66it/s, loss=nan]Epoch 0 - train:  56%|█████████████████████████████████████████▏                               | 10003/17710 [24:01<16:48,  7.64it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10011/17710 [24:02<16:50,  7.62it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10019/17710 [24:03<16:49,  7.62it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10027/17710 [24:04<16:52,  7.59it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▎                               | 10035/17710 [24:05<16:49,  7.60it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10043/17710 [24:06<16:48,  7.60it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10049/17710 [24:15<16:47,  7.60it/s, loss=nan]Epoch 0 - train:  57%|████████████████████████████████████████▎                              | 10051/17710 [24:16<1:01:27,  2.08it/s, loss=nan]Epoch 0 - train:  57%|████████████████████████████████████████▎                              | 10053/17710 [24:18<1:05:19,  1.95it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10059/17710 [24:19<55:10,  2.31it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▍                               | 10066/17710 [24:21<45:18,  2.81it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10072/17710 [24:22<41:29,  3.07it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10077/17710 [24:23<37:25,  3.40it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10082/17710 [24:25<35:42,  3.56it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10089/17710 [24:26<29:50,  4.26it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▌                               | 10096/17710 [24:27<26:33,  4.78it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10099/17710 [24:27<26:33,  4.78it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10103/17710 [24:28<24:29,  5.17it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10110/17710 [24:29<23:53,  5.30it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10118/17710 [24:30<21:23,  5.92it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▋                               | 10126/17710 [24:31<19:45,  6.40it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10134/17710 [24:32<18:50,  6.70it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10142/17710 [24:33<18:10,  6.94it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10149/17710 [24:34<18:09,  6.94it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10150/17710 [24:34<17:43,  7.11it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▊                               | 10158/17710 [24:35<17:21,  7.25it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10166/17710 [24:36<17:05,  7.36it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10174/17710 [24:37<16:51,  7.45it/s, loss=nan]Epoch 0 - train:  57%|█████████████████████████████████████████▉                               | 10182/17710 [24:39<16:39,  7.53it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10190/17710 [24:40<16:33,  7.57it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10198/17710 [24:41<16:36,  7.54it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10199/17710 [24:41<16:36,  7.54it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10206/17710 [24:42<16:38,  7.52it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████                               | 10214/17710 [24:43<16:35,  7.53it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10222/17710 [24:44<16:39,  7.49it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10230/17710 [24:45<16:37,  7.50it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10238/17710 [24:46<16:33,  7.52it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10246/17710 [24:47<16:31,  7.53it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▏                              | 10249/17710 [24:48<16:31,  7.53it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10254/17710 [24:48<16:38,  7.47it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10262/17710 [24:49<16:33,  7.50it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10270/17710 [24:50<16:26,  7.54it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▎                              | 10278/17710 [24:51<16:25,  7.54it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10286/17710 [24:52<16:21,  7.56it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10294/17710 [24:53<16:20,  7.56it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10299/17710 [24:54<16:20,  7.56it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10302/17710 [24:54<16:12,  7.62it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▍                              | 10310/17710 [24:55<16:07,  7.65it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10318/17710 [24:56<16:06,  7.65it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10326/17710 [24:58<16:07,  7.63it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▌                              | 10334/17710 [24:59<16:09,  7.61it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10342/17710 [25:00<16:10,  7.59it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10349/17710 [25:01<16:09,  7.59it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10350/17710 [25:01<16:17,  7.53it/s, loss=nan]Epoch 0 - train:  58%|██████████████████████████████████████████▋                              | 10358/17710 [25:02<16:13,  7.55it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▋                              | 10366/17710 [25:03<16:09,  7.58it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10374/17710 [25:04<16:05,  7.60it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10382/17710 [25:05<16:13,  7.53it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10390/17710 [25:06<17:13,  7.08it/s, loss=nan]Epoch 0 - train:  59%|██████████████████████████████████████████▊                              | 10394/17710 [25:27<17:13,  7.08it/s, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10395/17710 [26:00<4:51:59,  2.39s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10396/17710 [26:07<5:20:27,  2.63s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10396/17710 [26:22<5:20:27,  2.63s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10397/17710 [26:28<8:10:55,  4.03s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10398/17710 [26:32<8:14:02,  4.05s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10399/17710 [26:38<8:13:58,  4.05s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10402/17710 [26:41<6:53:30,  3.39s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10405/17710 [26:43<5:20:19,  2.63s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▋                             | 10411/17710 [26:44<3:08:13,  1.55s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10415/17710 [26:45<2:22:53,  1.18s/it, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10419/17710 [26:47<1:58:04,  1.03it/s, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10423/17710 [26:49<1:37:57,  1.24it/s, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10427/17710 [26:50<1:21:26,  1.49it/s, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10430/17710 [26:51<1:11:57,  1.69it/s, loss=nan]Epoch 0 - train:  59%|█████████████████████████████████████████▊                             | 10433/17710 [26:52<1:04:26,  1.88it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10438/17710 [26:54<49:57,  2.43it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10443/17710 [26:55<41:52,  2.89it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10447/17710 [26:56<42:14,  2.87it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10449/17710 [26:57<42:14,  2.87it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10452/17710 [26:58<41:44,  2.90it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████                              | 10457/17710 [26:59<36:07,  3.35it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10463/17710 [27:00<31:13,  3.87it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10468/17710 [27:01<30:31,  3.95it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10474/17710 [27:02<27:46,  4.34it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10480/17710 [27:03<26:24,  4.56it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▏                             | 10487/17710 [27:04<23:50,  5.05it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10493/17710 [27:06<24:24,  4.93it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10499/17710 [27:07<24:23,  4.93it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10500/17710 [27:07<24:48,  4.84it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10505/17710 [27:08<24:42,  4.86it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10511/17710 [27:09<23:24,  5.13it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▎                             | 10517/17710 [27:11<23:43,  5.05it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▍                             | 10524/17710 [27:12<22:00,  5.44it/s, loss=nan]Epoch 0 - train:  59%|███████████████████████████████████████████▍                             | 10532/17710 [27:13<19:45,  6.05it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10540/17710 [27:14<18:29,  6.46it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10548/17710 [27:15<17:34,  6.79it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▍                             | 10549/17710 [27:15<17:34,  6.79it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10556/17710 [27:16<17:09,  6.95it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10563/17710 [27:17<17:11,  6.93it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10571/17710 [27:18<16:55,  7.03it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▌                             | 10579/17710 [27:19<16:51,  7.05it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10587/17710 [27:20<16:30,  7.19it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10595/17710 [27:21<16:22,  7.24it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10599/17710 [27:22<16:21,  7.24it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10603/17710 [27:22<16:28,  7.19it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▋                             | 10611/17710 [27:24<16:19,  7.24it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10619/17710 [27:25<16:12,  7.29it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10627/17710 [27:26<15:57,  7.39it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10635/17710 [27:27<15:45,  7.49it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▊                             | 10643/17710 [27:28<15:35,  7.55it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10649/17710 [27:29<15:35,  7.55it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10651/17710 [27:29<15:31,  7.58it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10659/17710 [27:30<15:32,  7.56it/s, loss=nan]Epoch 0 - train:  60%|███████████████████████████████████████████▉                             | 10667/17710 [27:31<15:29,  7.58it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10675/17710 [27:32<15:28,  7.58it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10683/17710 [27:33<15:26,  7.59it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10691/17710 [27:34<15:25,  7.58it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10699/17710 [27:35<15:24,  7.59it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████                             | 10699/17710 [27:35<15:24,  7.59it/s, loss=nan]Epoch 0 - train:  60%|████████████████████████████████████████████▏                            | 10707/17710 [27:36<15:31,  7.52it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10715/17710 [27:37<15:26,  7.55it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10723/17710 [27:38<15:22,  7.57it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▏                            | 10731/17710 [27:39<15:21,  7.57it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10739/17710 [27:40<15:24,  7.54it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10747/17710 [27:41<15:26,  7.52it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10749/17710 [27:42<15:25,  7.52it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10755/17710 [27:43<15:26,  7.51it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▎                            | 10763/17710 [27:44<15:22,  7.53it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10771/17710 [27:45<15:20,  7.54it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10779/17710 [27:46<15:17,  7.55it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10787/17710 [27:47<15:15,  7.56it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▍                            | 10795/17710 [27:48<15:11,  7.59it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10799/17710 [27:48<15:11,  7.59it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10803/17710 [27:49<15:11,  7.58it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10811/17710 [27:50<15:08,  7.60it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▌                            | 10819/17710 [27:51<15:05,  7.61it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10827/17710 [27:52<15:05,  7.60it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10835/17710 [27:53<15:05,  7.59it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10843/17710 [27:54<15:03,  7.60it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10849/17710 [27:55<15:02,  7.60it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▋                            | 10851/17710 [27:55<15:01,  7.61it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10859/17710 [27:56<14:59,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10867/17710 [27:57<14:57,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10875/17710 [27:58<14:56,  7.62it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▊                            | 10883/17710 [27:59<14:54,  7.63it/s, loss=nan]Epoch 0 - train:  61%|████████████████████████████████████████████▉                            | 10891/17710 [28:00<14:52,  7.64it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10899/17710 [28:01<14:52,  7.63it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10899/17710 [28:02<14:52,  7.63it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10907/17710 [28:03<14:56,  7.59it/s, loss=nan]Epoch 0 - train:  62%|████████████████████████████████████████████▉                            | 10915/17710 [28:04<14:51,  7.62it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10923/17710 [28:05<14:49,  7.63it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10931/17710 [28:06<14:44,  7.67it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10939/17710 [28:07<14:42,  7.67it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████                            | 10941/17710 [28:24<14:42,  7.67it/s, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▊                           | 10942/17710 [28:27<1:57:23,  1.04s/it, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▊                           | 10943/17710 [28:34<2:38:40,  1.41s/it, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10949/17710 [28:41<2:30:39,  1.34s/it, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10949/17710 [28:41<2:30:39,  1.34s/it, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10956/17710 [28:42<1:41:17,  1.11it/s, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10961/17710 [28:44<1:26:45,  1.30it/s, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10966/17710 [28:46<1:11:53,  1.56it/s, loss=nan]Epoch 0 - train:  62%|███████████████████████████████████████████▉                           | 10970/17710 [28:47<1:04:03,  1.75it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▏                           | 10974/17710 [28:48<55:22,  2.03it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10978/17710 [28:49<49:31,  2.27it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10982/17710 [28:50<43:41,  2.57it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10986/17710 [28:51<39:22,  2.85it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10992/17710 [28:52<31:55,  3.51it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10997/17710 [28:53<28:58,  3.86it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 10999/17710 [28:54<28:58,  3.86it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▎                           | 11005/17710 [28:55<24:04,  4.64it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11012/17710 [28:56<21:21,  5.23it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11019/17710 [28:57<19:48,  5.63it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11026/17710 [28:58<18:57,  5.88it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▍                           | 11034/17710 [28:59<17:41,  6.29it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11042/17710 [29:00<16:42,  6.65it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11049/17710 [29:01<16:41,  6.65it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11050/17710 [29:01<16:06,  6.89it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11058/17710 [29:02<15:50,  7.00it/s, loss=nan]Epoch 0 - train:  62%|█████████████████████████████████████████████▌                           | 11066/17710 [29:03<15:32,  7.13it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11074/17710 [29:04<15:19,  7.22it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11082/17710 [29:05<15:34,  7.09it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11090/17710 [29:09<26:52,  4.10it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11097/17710 [29:10<24:07,  4.57it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▋                           | 11099/17710 [29:11<24:07,  4.57it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11103/17710 [29:11<22:53,  4.81it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11110/17710 [29:13<21:23,  5.14it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11117/17710 [29:14<19:42,  5.57it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▊                           | 11125/17710 [29:15<18:06,  6.06it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11133/17710 [29:16<16:52,  6.49it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11141/17710 [29:17<16:00,  6.84it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11149/17710 [29:18<15:30,  7.05it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11149/17710 [29:18<15:30,  7.05it/s, loss=nan]Epoch 0 - train:  63%|█████████████████████████████████████████████▉                           | 11157/17710 [29:19<15:12,  7.19it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11165/17710 [29:20<14:58,  7.28it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11173/17710 [29:21<14:51,  7.33it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11181/17710 [29:22<15:02,  7.23it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████                           | 11189/17710 [29:23<15:02,  7.22it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11197/17710 [29:24<14:55,  7.28it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11199/17710 [29:25<14:54,  7.28it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11205/17710 [29:25<14:51,  7.29it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▏                          | 11213/17710 [29:26<14:46,  7.33it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11221/17710 [29:28<14:53,  7.26it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11229/17710 [29:29<14:40,  7.36it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11237/17710 [29:30<14:31,  7.43it/s, loss=nan]Epoch 0 - train:  63%|██████████████████████████████████████████████▎                          | 11245/17710 [29:31<14:19,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▎                          | 11249/17710 [29:31<14:19,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11253/17710 [29:32<14:21,  7.50it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11261/17710 [29:33<14:21,  7.48it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11269/17710 [29:34<14:17,  7.51it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▍                          | 11277/17710 [29:35<14:17,  7.50it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11285/17710 [29:36<14:14,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11293/17710 [29:37<14:13,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11299/17710 [29:38<14:12,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11301/17710 [29:38<14:12,  7.52it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▌                          | 11309/17710 [29:39<14:19,  7.44it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11317/17710 [29:40<14:17,  7.46it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11325/17710 [29:41<14:14,  7.47it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11333/17710 [29:43<14:11,  7.49it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▋                          | 11341/17710 [29:44<14:09,  7.50it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11349/17710 [29:45<14:14,  7.45it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11349/17710 [29:45<14:14,  7.45it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11357/17710 [29:46<14:55,  7.09it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▊                          | 11365/17710 [29:47<14:46,  7.16it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11373/17710 [29:49<16:22,  6.45it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11381/17710 [29:50<15:38,  6.74it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11389/17710 [29:51<15:22,  6.85it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11397/17710 [29:52<15:14,  6.91it/s, loss=nan]Epoch 0 - train:  64%|██████████████████████████████████████████████▉                          | 11399/17710 [29:52<15:13,  6.91it/s, loss=nan]Epoch 0 - train:  64%|███████████████████████████████████████████████                          | 11405/17710 [29:53<14:52,  7.07it/s, loss=nan]Epoch 0 - train:  64%|███████████████████████████████████████████████                          | 11413/17710 [29:54<14:48,  7.09it/s, loss=nan]Epoch 0 - train:  64%|███████████████████████████████████████████████                          | 11421/17710 [29:55<14:28,  7.24it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████                          | 11429/17710 [29:56<14:14,  7.35it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11437/17710 [29:57<14:06,  7.41it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11445/17710 [29:58<13:59,  7.46it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11449/17710 [29:59<13:59,  7.46it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11453/17710 [29:59<13:57,  7.47it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▏                         | 11461/17710 [30:00<13:51,  7.52it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11469/17710 [30:01<13:53,  7.49it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11477/17710 [30:03<13:48,  7.53it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11485/17710 [30:04<13:45,  7.54it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▎                         | 11493/17710 [30:05<13:42,  7.56it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11499/17710 [30:06<13:41,  7.56it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11501/17710 [30:06<13:44,  7.53it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11509/17710 [30:07<13:40,  7.56it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▍                         | 11517/17710 [30:09<19:44,  5.23it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11524/17710 [30:11<19:23,  5.31it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11532/17710 [30:12<17:30,  5.88it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11540/17710 [30:13<16:20,  6.30it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11547/17710 [30:14<15:53,  6.46it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▌                         | 11549/17710 [30:14<15:53,  6.46it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11555/17710 [30:15<15:08,  6.78it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11563/17710 [30:16<14:40,  6.98it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11571/17710 [30:17<14:20,  7.14it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▋                         | 11579/17710 [30:18<14:02,  7.28it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11587/17710 [30:19<13:49,  7.38it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11595/17710 [30:20<13:40,  7.45it/s, loss=nan]Epoch 0 - train:  65%|███████████████████████████████████████████████▊                         | 11599/17710 [30:21<13:39,  7.45it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▊                         | 11603/17710 [30:21<13:34,  7.50it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▊                         | 11611/17710 [30:22<13:34,  7.49it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11619/17710 [30:23<13:30,  7.51it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11627/17710 [30:24<13:29,  7.51it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11635/17710 [30:25<13:28,  7.52it/s, loss=nan]Epoch 0 - train:  66%|███████████████████████████████████████████████▉                         | 11643/17710 [30:26<13:29,  7.50it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11649/17710 [30:27<13:28,  7.50it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11651/17710 [30:28<13:28,  7.49it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11659/17710 [30:29<13:26,  7.51it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11667/17710 [30:30<13:36,  7.40it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████                         | 11675/17710 [30:31<13:28,  7.46it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11683/17710 [30:32<13:24,  7.49it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11691/17710 [30:33<13:21,  7.51it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11699/17710 [30:34<13:20,  7.51it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▏                        | 11699/17710 [30:34<13:20,  7.51it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11707/17710 [30:35<13:19,  7.51it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11715/17710 [30:36<13:14,  7.54it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11723/17710 [30:37<13:11,  7.56it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▎                        | 11731/17710 [30:38<13:08,  7.58it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11739/17710 [30:39<13:08,  7.57it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11747/17710 [30:40<13:09,  7.56it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11749/17710 [30:41<13:08,  7.56it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11755/17710 [30:41<13:08,  7.55it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▍                        | 11763/17710 [30:42<13:03,  7.59it/s, loss=nan]Epoch 0 - train:  66%|████████████████████████████████████████████████▌                        | 11771/17710 [30:43<13:01,  7.60it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▌                        | 11779/17710 [30:45<13:06,  7.54it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▌                        | 11787/17710 [30:46<13:04,  7.55it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▌                        | 11795/17710 [30:47<13:01,  7.57it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11799/17710 [30:47<13:01,  7.57it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11803/17710 [30:48<13:00,  7.57it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11811/17710 [30:49<12:56,  7.59it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▋                        | 11819/17710 [30:50<12:53,  7.61it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11827/17710 [30:51<12:54,  7.59it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11835/17710 [30:52<12:52,  7.60it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11843/17710 [30:53<12:53,  7.58it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11849/17710 [30:54<12:53,  7.58it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▊                        | 11851/17710 [30:54<12:53,  7.58it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11859/17710 [30:55<12:52,  7.57it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11867/17710 [30:56<12:47,  7.61it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11875/17710 [30:57<12:47,  7.60it/s, loss=nan]Epoch 0 - train:  67%|████████████████████████████████████████████████▉                        | 11883/17710 [30:58<12:50,  7.56it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11891/17710 [30:59<12:51,  7.55it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11899/17710 [31:00<12:48,  7.57it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11899/17710 [31:00<12:48,  7.57it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11907/17710 [31:01<12:50,  7.53it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████                        | 11915/17710 [31:03<12:56,  7.47it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11923/17710 [31:04<12:52,  7.49it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11931/17710 [31:05<12:52,  7.48it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11939/17710 [31:06<12:50,  7.49it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▏                       | 11947/17710 [31:07<12:46,  7.51it/s, loss=nan]Epoch 0 - train:  67%|█████████████████████████████████████████████████▎                       | 11949/17710 [31:07<12:46,  7.51it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11955/17710 [31:08<13:54,  6.90it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11963/17710 [31:09<13:38,  7.02it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▎                       | 11971/17710 [31:10<13:20,  7.17it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11979/17710 [31:11<13:05,  7.30it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11987/17710 [31:12<12:56,  7.37it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11995/17710 [31:13<12:50,  7.42it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 11999/17710 [31:14<12:49,  7.42it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▍                       | 12003/17710 [31:15<12:44,  7.46it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12011/17710 [31:16<12:39,  7.50it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12019/17710 [31:17<12:37,  7.51it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12027/17710 [31:18<12:34,  7.53it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▌                       | 12035/17710 [31:19<12:39,  7.47it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12043/17710 [31:20<12:38,  7.47it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12049/17710 [31:21<12:37,  7.47it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12051/17710 [31:21<12:33,  7.51it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12059/17710 [31:22<12:32,  7.51it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▋                       | 12067/17710 [31:23<12:32,  7.50it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12075/17710 [31:24<12:37,  7.44it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12083/17710 [31:25<12:33,  7.47it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12091/17710 [31:26<12:27,  7.51it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12099/17710 [31:27<12:21,  7.56it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▊                       | 12099/17710 [31:27<12:21,  7.56it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12107/17710 [31:28<12:16,  7.61it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12115/17710 [31:29<12:14,  7.62it/s, loss=nan]Epoch 0 - train:  68%|█████████████████████████████████████████████████▉                       | 12123/17710 [31:30<12:13,  7.62it/s, loss=nan]Epoch 0 - train:  68%|██████████████████████████████████████████████████                       | 12131/17710 [31:31<12:12,  7.61it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12139/17710 [31:33<12:12,  7.60it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12147/17710 [31:34<12:12,  7.59it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12149/17710 [31:34<12:12,  7.59it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████                       | 12155/17710 [31:35<12:13,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12163/17710 [31:36<12:13,  7.56it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12171/17710 [31:37<12:10,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12179/17710 [31:38<12:09,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▏                      | 12187/17710 [31:39<12:07,  7.59it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12195/17710 [31:40<12:15,  7.49it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12199/17710 [31:41<12:15,  7.49it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12203/17710 [31:41<12:13,  7.51it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12211/17710 [31:42<12:10,  7.53it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▎                      | 12219/17710 [31:43<12:11,  7.51it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12227/17710 [31:44<12:07,  7.54it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12235/17710 [31:45<12:03,  7.57it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12243/17710 [31:46<12:00,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12249/17710 [31:47<12:00,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▍                      | 12251/17710 [31:47<12:00,  7.58it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12259/17710 [31:48<12:15,  7.41it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12267/17710 [31:50<12:14,  7.41it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▌                      | 12275/17710 [31:51<12:16,  7.38it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12283/17710 [31:52<12:07,  7.45it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12291/17710 [31:53<12:02,  7.50it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12299/17710 [31:54<11:58,  7.53it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12299/17710 [31:54<11:58,  7.53it/s, loss=nan]Epoch 0 - train:  69%|██████████████████████████████████████████████████▋                      | 12307/17710 [31:55<11:54,  7.56it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12315/17710 [31:56<11:51,  7.58it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12323/17710 [31:57<11:52,  7.56it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12331/17710 [31:58<11:55,  7.52it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▊                      | 12339/17710 [31:59<11:51,  7.55it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12347/17710 [32:00<11:46,  7.59it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12349/17710 [32:01<11:46,  7.59it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12355/17710 [32:01<11:46,  7.58it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12363/17710 [32:02<11:53,  7.49it/s, loss=nan]Epoch 0 - train:  70%|██████████████████████████████████████████████████▉                      | 12371/17710 [32:03<11:49,  7.53it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12379/17710 [32:04<11:46,  7.55it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12387/17710 [32:05<11:41,  7.59it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12395/17710 [32:07<11:45,  7.54it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12399/17710 [32:07<11:44,  7.54it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████                      | 12403/17710 [32:08<12:16,  7.21it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12411/17710 [32:09<12:08,  7.27it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12419/17710 [32:10<12:02,  7.32it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▏                     | 12427/17710 [32:11<11:52,  7.42it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12435/17710 [32:12<11:46,  7.47it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12443/17710 [32:13<11:44,  7.48it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12449/17710 [32:14<11:43,  7.48it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12451/17710 [32:14<11:38,  7.53it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▎                     | 12459/17710 [32:15<11:35,  7.55it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▍                     | 12467/17710 [32:16<11:35,  7.54it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▍                     | 12475/17710 [32:17<11:38,  7.50it/s, loss=nan]Epoch 0 - train:  70%|███████████████████████████████████████████████████▍                     | 12483/17710 [32:18<11:35,  7.51it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▍                     | 12491/17710 [32:19<11:35,  7.50it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12499/17710 [32:21<11:34,  7.51it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12499/17710 [32:21<11:34,  7.51it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12507/17710 [32:22<11:31,  7.52it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12515/17710 [32:23<11:29,  7.53it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▌                     | 12523/17710 [32:24<11:31,  7.50it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12531/17710 [32:25<11:28,  7.53it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12539/17710 [32:26<11:26,  7.54it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12547/17710 [32:27<11:24,  7.55it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▋                     | 12549/17710 [32:27<11:23,  7.55it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12555/17710 [32:28<11:20,  7.57it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12563/17710 [32:29<11:17,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12571/17710 [32:30<11:16,  7.60it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▊                     | 12579/17710 [32:31<11:13,  7.62it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12587/17710 [32:32<11:12,  7.62it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12595/17710 [32:33<11:10,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12599/17710 [32:34<11:09,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12603/17710 [32:34<11:09,  7.63it/s, loss=nan]Epoch 0 - train:  71%|███████████████████████████████████████████████████▉                     | 12611/17710 [32:35<11:07,  7.64it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12619/17710 [32:36<11:06,  7.64it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12627/17710 [32:37<11:09,  7.59it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12635/17710 [32:38<11:09,  7.58it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████                     | 12643/17710 [32:39<11:06,  7.60it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12649/17710 [32:40<11:05,  7.60it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12651/17710 [32:41<11:06,  7.59it/s, loss=nan]Epoch 0 - train:  71%|████████████████████████████████████████████████████▏                    | 12659/17710 [32:42<11:08,  7.55it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▏                    | 12667/17710 [32:43<11:05,  7.57it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▏                    | 12675/17710 [32:44<11:03,  7.59it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12683/17710 [32:45<11:00,  7.61it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12691/17710 [32:46<10:58,  7.62it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12699/17710 [32:47<10:58,  7.62it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▎                    | 12699/17710 [32:47<10:58,  7.62it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12707/17710 [32:48<10:59,  7.58it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12715/17710 [32:49<11:00,  7.56it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12723/17710 [32:50<11:02,  7.53it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▍                    | 12731/17710 [32:51<11:03,  7.51it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12739/17710 [32:52<10:58,  7.55it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12747/17710 [32:53<10:55,  7.57it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12749/17710 [32:54<10:55,  7.57it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12755/17710 [32:54<11:02,  7.47it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▌                    | 12763/17710 [32:55<11:05,  7.43it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12771/17710 [32:56<11:01,  7.47it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12779/17710 [32:58<10:57,  7.49it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12787/17710 [32:59<10:53,  7.53it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▋                    | 12795/17710 [33:00<10:50,  7.55it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12799/17710 [33:00<10:50,  7.55it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12803/17710 [33:01<10:49,  7.56it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12811/17710 [33:02<10:51,  7.52it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12819/17710 [33:03<10:49,  7.53it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▊                    | 12827/17710 [33:04<10:47,  7.54it/s, loss=nan]Epoch 0 - train:  72%|████████████████████████████████████████████████████▉                    | 12835/17710 [33:05<10:44,  7.56it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12843/17710 [33:06<10:42,  7.58it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12849/17710 [33:07<10:41,  7.58it/s, loss=nan]Epoch 0 - train:  73%|████████████████████████████████████████████████████▉                    | 12851/17710 [33:07<10:41,  7.57it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12859/17710 [33:11<18:33,  4.36it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12867/17710 [33:12<16:17,  4.95it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12875/17710 [33:13<14:35,  5.52it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████                    | 12883/17710 [33:14<13:22,  6.02it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12891/17710 [33:15<12:34,  6.39it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12899/17710 [33:16<12:05,  6.64it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12899/17710 [33:16<12:05,  6.64it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12907/17710 [33:17<11:35,  6.91it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▏                   | 12915/17710 [33:18<11:14,  7.11it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12923/17710 [33:19<11:01,  7.24it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12931/17710 [33:20<11:00,  7.24it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12939/17710 [33:21<10:49,  7.34it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▎                   | 12947/17710 [33:22<10:42,  7.42it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12949/17710 [33:23<10:41,  7.42it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12955/17710 [33:23<10:36,  7.47it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12963/17710 [33:25<10:35,  7.47it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12971/17710 [33:26<10:28,  7.55it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▍                   | 12979/17710 [33:27<10:23,  7.59it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12987/17710 [33:28<10:19,  7.62it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12995/17710 [33:29<10:21,  7.59it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 12999/17710 [33:29<10:20,  7.59it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▌                   | 13003/17710 [33:30<10:19,  7.60it/s, loss=nan]Epoch 0 - train:  73%|█████████████████████████████████████████████████████▋                   | 13011/17710 [33:31<10:18,  7.60it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13019/17710 [33:32<10:16,  7.61it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13027/17710 [33:33<10:14,  7.62it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▋                   | 13035/17710 [33:34<10:12,  7.63it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13043/17710 [33:35<10:12,  7.62it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13049/17710 [33:36<10:11,  7.62it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13051/17710 [33:36<10:13,  7.59it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13059/17710 [33:37<10:13,  7.58it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▊                   | 13067/17710 [33:38<10:17,  7.52it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13075/17710 [33:39<10:15,  7.53it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13083/17710 [33:40<10:14,  7.53it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13091/17710 [33:41<10:12,  7.54it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13099/17710 [33:42<10:11,  7.54it/s, loss=nan]Epoch 0 - train:  74%|█████████████████████████████████████████████████████▉                   | 13099/17710 [33:43<10:11,  7.54it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13107/17710 [33:44<10:13,  7.50it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13115/17710 [33:45<10:13,  7.49it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████                   | 13123/17710 [33:46<10:10,  7.51it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13131/17710 [33:47<10:10,  7.50it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13139/17710 [33:48<10:11,  7.48it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13147/17710 [33:49<10:09,  7.48it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13149/17710 [33:49<10:09,  7.48it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▏                  | 13155/17710 [33:50<10:08,  7.49it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13163/17710 [33:51<10:05,  7.51it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13171/17710 [33:52<10:02,  7.54it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13179/17710 [33:53<10:01,  7.53it/s, loss=nan]Epoch 0 - train:  74%|██████████████████████████████████████████████████████▎                  | 13187/17710 [33:54<10:02,  7.51it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13195/17710 [33:55<10:04,  7.47it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13199/17710 [33:56<10:03,  7.47it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13203/17710 [33:56<10:02,  7.48it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13211/17710 [33:57<09:56,  7.54it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▍                  | 13219/17710 [33:58<09:58,  7.50it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13227/17710 [34:00<09:57,  7.51it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13235/17710 [34:01<09:56,  7.50it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13243/17710 [34:02<09:55,  7.50it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13249/17710 [34:03<09:54,  7.50it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▌                  | 13251/17710 [34:03<09:50,  7.55it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13259/17710 [34:04<09:44,  7.61it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13267/17710 [34:05<09:41,  7.64it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▋                  | 13275/17710 [34:06<09:42,  7.61it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13283/17710 [34:07<09:43,  7.58it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13286/17710 [34:24<09:43,  7.58it/s, loss=nan]Epoch 0 - train:  75%|█████████████████████████████████████████████████████▎                 | 13287/17710 [34:27<1:11:44,  1.03it/s, loss=nan]Epoch 0 - train:  75%|█████████████████████████████████████████████████████▎                 | 13288/17710 [34:29<1:19:22,  1.08s/it, loss=nan]Epoch 0 - train:  75%|█████████████████████████████████████████████████████▎                 | 13294/17710 [34:34<1:13:07,  1.01it/s, loss=nan]Epoch 0 - train:  75%|█████████████████████████████████████████████████████▎                 | 13299/17710 [34:35<1:13:02,  1.01it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13302/17710 [34:36<49:23,  1.49it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▊                  | 13309/17710 [34:37<36:56,  1.99it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13315/17710 [34:38<29:52,  2.45it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13321/17710 [34:39<25:41,  2.85it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13327/17710 [34:40<22:29,  3.25it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13333/17710 [34:41<20:17,  3.59it/s, loss=nan]Epoch 0 - train:  75%|██████████████████████████████████████████████████████▉                  | 13340/17710 [34:43<17:24,  4.18it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13347/17710 [34:44<15:15,  4.76it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13349/17710 [34:44<15:15,  4.76it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13353/17710 [34:45<14:48,  4.90it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13361/17710 [34:46<13:02,  5.56it/s, loss=nan]Epoch 0 - train:  75%|███████████████████████████████████████████████████████                  | 13369/17710 [34:47<11:55,  6.07it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13377/17710 [34:48<11:09,  6.48it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13385/17710 [34:49<10:37,  6.78it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13393/17710 [34:50<10:17,  6.99it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13399/17710 [34:51<10:16,  6.99it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▏                 | 13401/17710 [34:51<10:03,  7.14it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13409/17710 [34:52<09:51,  7.27it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13417/17710 [34:53<09:45,  7.33it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13425/17710 [34:54<09:38,  7.40it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▎                 | 13433/17710 [34:55<09:35,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13441/17710 [34:56<09:34,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13449/17710 [34:58<09:33,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13449/17710 [34:58<09:33,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▍                 | 13457/17710 [34:59<09:32,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13465/17710 [35:00<09:30,  7.44it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13473/17710 [35:01<09:30,  7.43it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13481/17710 [35:02<09:32,  7.38it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▌                 | 13489/17710 [35:03<09:30,  7.39it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13497/17710 [35:04<09:30,  7.39it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13499/17710 [35:04<09:29,  7.39it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13505/17710 [35:05<09:29,  7.38it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13513/17710 [35:06<09:26,  7.41it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▋                 | 13521/17710 [35:07<09:23,  7.44it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13529/17710 [35:12<19:35,  3.56it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13537/17710 [35:13<16:31,  4.21it/s, loss=nan]Epoch 0 - train:  76%|███████████████████████████████████████████████████████▊                 | 13545/17710 [35:14<14:23,  4.82it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▊                 | 13549/17710 [35:15<14:22,  4.82it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▊                 | 13553/17710 [35:16<12:51,  5.39it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13561/17710 [35:17<11:50,  5.84it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13569/17710 [35:18<11:08,  6.20it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13577/17710 [35:19<10:35,  6.51it/s, loss=nan]Epoch 0 - train:  77%|███████████████████████████████████████████████████████▉                 | 13585/17710 [35:20<10:12,  6.73it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13593/17710 [35:21<09:56,  6.91it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13599/17710 [35:22<09:55,  6.91it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13601/17710 [35:22<09:43,  7.04it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████                 | 13609/17710 [35:23<09:34,  7.14it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13617/17710 [35:24<09:31,  7.17it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13625/17710 [35:25<09:23,  7.25it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13633/17710 [35:26<09:18,  7.30it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▏                | 13641/17710 [35:27<09:13,  7.35it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13649/17710 [35:29<09:10,  7.38it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13649/17710 [35:29<09:10,  7.38it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13657/17710 [35:30<09:10,  7.36it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13665/17710 [35:31<09:06,  7.40it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▎                | 13673/17710 [35:32<09:06,  7.39it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13681/17710 [35:33<09:07,  7.36it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13689/17710 [35:34<09:06,  7.36it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13697/17710 [35:35<09:07,  7.33it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13699/17710 [35:36<09:07,  7.33it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▍                | 13705/17710 [35:36<09:06,  7.33it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▌                | 13713/17710 [35:37<09:09,  7.27it/s, loss=nan]Epoch 0 - train:  77%|████████████████████████████████████████████████████████▌                | 13721/17710 [35:38<09:07,  7.29it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▌                | 13729/17710 [35:39<09:04,  7.31it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▌                | 13737/17710 [35:41<09:00,  7.34it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13745/17710 [35:42<08:59,  7.35it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13749/17710 [35:42<08:58,  7.35it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13753/17710 [35:43<08:57,  7.36it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▋                | 13761/17710 [35:44<08:58,  7.34it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13769/17710 [35:45<08:54,  7.37it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13777/17710 [35:46<08:54,  7.36it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13785/17710 [35:47<08:52,  7.37it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▊                | 13793/17710 [35:48<08:50,  7.38it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13799/17710 [35:49<08:49,  7.38it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13801/17710 [35:49<08:47,  7.41it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13809/17710 [35:50<08:45,  7.42it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13817/17710 [35:51<08:48,  7.36it/s, loss=nan]Epoch 0 - train:  78%|████████████████████████████████████████████████████████▉                | 13825/17710 [35:52<08:44,  7.40it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13833/17710 [35:54<08:41,  7.43it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13841/17710 [35:55<08:48,  7.32it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13849/17710 [35:56<08:53,  7.24it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13849/17710 [35:56<08:53,  7.24it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████                | 13857/17710 [35:57<08:50,  7.27it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13865/17710 [35:58<08:51,  7.23it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13873/17710 [35:59<08:48,  7.27it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13881/17710 [36:00<08:43,  7.32it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▏               | 13889/17710 [36:01<08:38,  7.36it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▎               | 13897/17710 [36:02<08:42,  7.30it/s, loss=nan]Epoch 0 - train:  78%|█████████████████████████████████████████████████████████▎               | 13899/17710 [36:03<08:42,  7.30it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▎               | 13905/17710 [36:03<08:40,  7.31it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▎               | 13913/17710 [36:05<08:38,  7.32it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13921/17710 [36:06<08:39,  7.29it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13929/17710 [36:07<08:38,  7.30it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13937/17710 [36:08<09:19,  6.75it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13945/17710 [36:09<09:06,  6.88it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▍               | 13949/17710 [36:10<09:06,  6.88it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13953/17710 [36:10<08:53,  7.04it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13961/17710 [36:11<08:46,  7.13it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13969/17710 [36:13<08:39,  7.20it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▌               | 13977/17710 [36:14<08:34,  7.25it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13985/17710 [36:15<08:34,  7.24it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13993/17710 [36:16<08:27,  7.32it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 13999/17710 [36:17<08:27,  7.32it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 14001/17710 [36:17<08:27,  7.31it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▋               | 14009/17710 [36:18<08:27,  7.29it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14017/17710 [36:19<08:25,  7.31it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14025/17710 [36:20<08:24,  7.30it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▊               | 14033/17710 [36:21<08:21,  7.33it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14041/17710 [36:22<08:22,  7.30it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14049/17710 [36:23<08:19,  7.33it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14049/17710 [36:24<08:19,  7.33it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14057/17710 [36:25<08:19,  7.32it/s, loss=nan]Epoch 0 - train:  79%|█████████████████████████████████████████████████████████▉               | 14065/17710 [36:26<08:15,  7.35it/s, loss=nan]Epoch 0 - train:  79%|██████████████████████████████████████████████████████████               | 14073/17710 [36:27<08:15,  7.34it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14081/17710 [36:28<08:11,  7.38it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14089/17710 [36:29<08:07,  7.42it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14097/17710 [36:30<08:10,  7.37it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████               | 14099/17710 [36:30<08:09,  7.37it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14105/17710 [36:31<08:13,  7.31it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14113/17710 [36:32<08:11,  7.32it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14121/17710 [36:33<08:08,  7.35it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▏              | 14129/17710 [36:34<08:08,  7.33it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14137/17710 [36:35<08:09,  7.30it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14145/17710 [36:37<08:08,  7.30it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14149/17710 [36:37<08:08,  7.30it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14153/17710 [36:38<08:07,  7.30it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▎              | 14161/17710 [36:39<08:09,  7.25it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14169/17710 [36:40<08:09,  7.24it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14177/17710 [36:41<08:08,  7.24it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▍              | 14185/17710 [36:42<08:09,  7.20it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14193/17710 [36:43<08:08,  7.20it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14199/17710 [36:44<08:07,  7.20it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14201/17710 [36:44<08:05,  7.22it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14209/17710 [36:45<08:02,  7.26it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▌              | 14217/17710 [36:46<08:03,  7.23it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14225/17710 [36:48<08:01,  7.24it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14233/17710 [36:49<07:59,  7.25it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14241/17710 [36:50<07:55,  7.29it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14249/17710 [36:51<07:52,  7.32it/s, loss=nan]Epoch 0 - train:  80%|██████████████████████████████████████████████████████████▋              | 14249/17710 [36:51<07:52,  7.32it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14257/17710 [36:52<07:49,  7.35it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14265/17710 [36:53<07:48,  7.36it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14273/17710 [36:54<07:46,  7.37it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▊              | 14281/17710 [36:55<07:44,  7.39it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14289/17710 [36:56<07:44,  7.37it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14297/17710 [36:57<07:44,  7.34it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14299/17710 [36:58<07:44,  7.34it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14305/17710 [36:58<07:42,  7.36it/s, loss=nan]Epoch 0 - train:  81%|██████████████████████████████████████████████████████████▉              | 14313/17710 [37:00<07:40,  7.38it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14321/17710 [37:01<07:39,  7.38it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14329/17710 [37:02<07:39,  7.36it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████              | 14337/17710 [37:03<07:38,  7.36it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14345/17710 [37:04<07:38,  7.35it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14349/17710 [37:05<07:37,  7.35it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14353/17710 [37:05<07:34,  7.38it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14361/17710 [37:06<07:35,  7.35it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▏             | 14369/17710 [37:07<07:32,  7.39it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14377/17710 [37:08<07:42,  7.20it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14385/17710 [37:09<07:46,  7.13it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14393/17710 [37:11<07:42,  7.17it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14399/17710 [37:12<07:41,  7.17it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▎             | 14401/17710 [37:12<07:38,  7.21it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14409/17710 [37:13<07:36,  7.23it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14417/17710 [37:14<07:38,  7.18it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14425/17710 [37:15<07:38,  7.16it/s, loss=nan]Epoch 0 - train:  81%|███████████████████████████████████████████████████████████▍             | 14433/17710 [37:16<07:34,  7.21it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14441/17710 [37:17<07:31,  7.24it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14449/17710 [37:18<07:28,  7.26it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14449/17710 [37:18<07:28,  7.26it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14457/17710 [37:19<07:29,  7.24it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▌             | 14465/17710 [37:21<07:29,  7.22it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14473/17710 [37:22<07:27,  7.23it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14481/17710 [37:23<07:27,  7.22it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▋             | 14489/17710 [37:24<07:24,  7.25it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14497/17710 [37:25<07:20,  7.29it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14499/17710 [37:25<07:20,  7.29it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14505/17710 [37:26<07:17,  7.32it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14513/17710 [37:27<07:15,  7.35it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▊             | 14521/17710 [37:28<07:11,  7.39it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14529/17710 [37:29<07:10,  7.39it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14537/17710 [37:30<07:08,  7.40it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14545/17710 [37:31<07:11,  7.33it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14549/17710 [37:32<07:11,  7.33it/s, loss=nan]Epoch 0 - train:  82%|███████████████████████████████████████████████████████████▉             | 14553/17710 [37:32<07:09,  7.34it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14561/17710 [37:34<07:11,  7.30it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14569/17710 [37:35<07:09,  7.31it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14577/17710 [37:36<07:14,  7.22it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████             | 14585/17710 [37:37<07:10,  7.26it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14593/17710 [37:38<07:07,  7.28it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14599/17710 [37:39<07:07,  7.28it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14601/17710 [37:39<07:05,  7.31it/s, loss=nan]Epoch 0 - train:  82%|████████████████████████████████████████████████████████████▏            | 14609/17710 [37:40<07:06,  7.27it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14617/17710 [37:41<07:04,  7.28it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14625/17710 [37:42<07:03,  7.28it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14633/17710 [37:43<06:59,  7.34it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▎            | 14641/17710 [37:45<06:56,  7.37it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14649/17710 [37:46<06:52,  7.41it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14649/17710 [37:46<06:52,  7.41it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14657/17710 [37:47<06:50,  7.44it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14665/17710 [37:48<06:51,  7.39it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▍            | 14673/17710 [37:49<06:50,  7.40it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14681/17710 [37:50<06:48,  7.42it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14689/17710 [37:51<06:46,  7.43it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14697/17710 [37:52<06:45,  7.42it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14699/17710 [37:52<06:45,  7.42it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▌            | 14705/17710 [37:53<06:51,  7.30it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14713/17710 [37:54<06:49,  7.33it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14721/17710 [37:55<06:46,  7.36it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14729/17710 [37:56<06:43,  7.39it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▋            | 14737/17710 [37:58<06:48,  7.29it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14745/17710 [37:59<06:46,  7.30it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14749/17710 [37:59<06:45,  7.30it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14753/17710 [38:00<06:43,  7.32it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▊            | 14761/17710 [38:01<06:44,  7.28it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▉            | 14769/17710 [38:02<06:42,  7.30it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▉            | 14777/17710 [38:03<06:39,  7.34it/s, loss=nan]Epoch 0 - train:  83%|████████████████████████████████████████████████████████████▉            | 14785/17710 [38:04<06:36,  7.37it/s, loss=nan]Epoch 0 - train:  84%|████████████████████████████████████████████████████████████▉            | 14793/17710 [38:05<06:37,  7.34it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14799/17710 [38:06<06:36,  7.34it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14801/17710 [38:06<06:37,  7.33it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14809/17710 [38:07<06:36,  7.31it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14817/17710 [38:09<06:53,  7.00it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████            | 14825/17710 [38:10<06:48,  7.06it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14833/17710 [38:11<06:44,  7.11it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14841/17710 [38:12<06:41,  7.14it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14849/17710 [38:13<06:37,  7.19it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14849/17710 [38:13<06:37,  7.19it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▏           | 14857/17710 [38:14<06:34,  7.23it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14865/17710 [38:15<06:31,  7.27it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14873/17710 [38:16<06:29,  7.28it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14881/17710 [38:17<06:30,  7.25it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▎           | 14889/17710 [38:19<06:30,  7.22it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14897/17710 [38:20<06:29,  7.23it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14899/17710 [38:20<06:29,  7.23it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14905/17710 [38:21<06:26,  7.25it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▍           | 14913/17710 [38:22<06:23,  7.30it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14921/17710 [38:23<06:20,  7.32it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14929/17710 [38:24<06:17,  7.36it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14937/17710 [38:25<06:16,  7.36it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14945/17710 [38:26<06:16,  7.34it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▌           | 14949/17710 [38:27<06:16,  7.34it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▋           | 14953/17710 [38:27<06:19,  7.27it/s, loss=nan]Epoch 0 - train:  84%|█████████████████████████████████████████████████████████████▋           | 14961/17710 [38:28<06:15,  7.32it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▋           | 14969/17710 [38:29<06:12,  7.36it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▋           | 14977/17710 [38:31<06:10,  7.38it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14985/17710 [38:32<06:10,  7.35it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14993/17710 [38:33<06:08,  7.37it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 14999/17710 [38:34<06:07,  7.37it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 15001/17710 [38:34<06:06,  7.39it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▊           | 15009/17710 [38:35<06:07,  7.35it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15017/17710 [38:36<06:08,  7.30it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15025/17710 [38:37<06:08,  7.29it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15033/17710 [38:38<06:07,  7.28it/s, loss=nan]Epoch 0 - train:  85%|█████████████████████████████████████████████████████████████▉           | 15041/17710 [38:39<06:06,  7.27it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15049/17710 [38:40<06:04,  7.29it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15049/17710 [38:41<06:04,  7.29it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15057/17710 [38:42<06:02,  7.33it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████           | 15065/17710 [38:43<06:02,  7.30it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15073/17710 [38:44<06:00,  7.32it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15081/17710 [38:45<05:59,  7.31it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15089/17710 [38:46<05:58,  7.31it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15097/17710 [38:47<05:56,  7.33it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▏          | 15099/17710 [38:47<05:56,  7.33it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15105/17710 [38:48<05:56,  7.30it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15113/17710 [38:49<05:55,  7.30it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15121/17710 [38:50<05:53,  7.31it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▎          | 15129/17710 [38:51<05:52,  7.32it/s, loss=nan]Epoch 0 - train:  85%|██████████████████████████████████████████████████████████████▍          | 15137/17710 [38:52<05:50,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15145/17710 [38:54<05:49,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15149/17710 [38:54<05:48,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15153/17710 [38:55<05:48,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▍          | 15161/17710 [38:56<05:46,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15169/17710 [38:57<05:45,  7.35it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15177/17710 [38:58<05:43,  7.37it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▌          | 15185/17710 [38:59<05:40,  7.41it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15193/17710 [39:00<05:38,  7.44it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15199/17710 [39:01<05:37,  7.44it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15201/17710 [39:01<05:37,  7.43it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15209/17710 [39:02<05:37,  7.40it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▋          | 15217/17710 [39:03<05:38,  7.37it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15225/17710 [39:04<05:38,  7.34it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15233/17710 [39:05<05:37,  7.34it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15241/17710 [39:07<05:38,  7.29it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15249/17710 [39:08<05:48,  7.07it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▊          | 15249/17710 [39:08<05:48,  7.07it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15257/17710 [39:09<05:48,  7.04it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15265/17710 [39:10<05:43,  7.11it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15273/17710 [39:11<05:44,  7.08it/s, loss=nan]Epoch 0 - train:  86%|██████████████████████████████████████████████████████████████▉          | 15281/17710 [39:12<05:41,  7.12it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15289/17710 [39:13<05:35,  7.21it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15297/17710 [39:14<05:36,  7.18it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15299/17710 [39:15<05:35,  7.18it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15305/17710 [39:16<05:35,  7.16it/s, loss=nan]Epoch 0 - train:  86%|███████████████████████████████████████████████████████████████          | 15313/17710 [39:17<05:33,  7.20it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15321/17710 [39:18<05:31,  7.22it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15329/17710 [39:19<05:31,  7.19it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▏         | 15337/17710 [39:20<05:29,  7.20it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15345/17710 [39:21<05:28,  7.21it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15349/17710 [39:22<05:27,  7.21it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15353/17710 [39:22<05:27,  7.19it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15361/17710 [39:23<05:24,  7.23it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▎         | 15369/17710 [39:24<05:23,  7.24it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15377/17710 [39:26<05:21,  7.26it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15385/17710 [39:27<05:18,  7.29it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15393/17710 [39:28<05:17,  7.31it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15399/17710 [39:29<05:16,  7.31it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▍         | 15401/17710 [39:29<05:16,  7.30it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15409/17710 [39:30<05:20,  7.18it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15417/17710 [39:31<05:16,  7.24it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15425/17710 [39:32<05:15,  7.25it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▌         | 15433/17710 [39:33<05:13,  7.26it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15441/17710 [39:34<05:12,  7.25it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15449/17710 [39:35<05:10,  7.28it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15449/17710 [39:36<05:10,  7.28it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15457/17710 [39:37<05:08,  7.30it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▋         | 15465/17710 [39:38<05:09,  7.25it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15473/17710 [39:39<05:06,  7.31it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15481/17710 [39:40<05:03,  7.33it/s, loss=nan]Epoch 0 - train:  87%|███████████████████████████████████████████████████████████████▊         | 15489/17710 [39:41<05:03,  7.33it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15497/17710 [39:42<05:02,  7.31it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15499/17710 [39:42<05:02,  7.31it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15505/17710 [39:43<05:03,  7.27it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15513/17710 [39:44<05:03,  7.23it/s, loss=nan]Epoch 0 - train:  88%|███████████████████████████████████████████████████████████████▉         | 15521/17710 [39:45<05:04,  7.19it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15529/17710 [39:46<05:01,  7.23it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15537/17710 [39:48<05:01,  7.21it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15545/17710 [39:49<05:00,  7.21it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15549/17710 [39:49<04:59,  7.21it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████         | 15553/17710 [39:50<04:59,  7.19it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15561/17710 [39:51<04:56,  7.25it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15569/17710 [39:52<04:54,  7.28it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15577/17710 [39:53<04:53,  7.27it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▏        | 15585/17710 [39:54<04:52,  7.27it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15593/17710 [39:55<04:51,  7.27it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15599/17710 [39:56<04:50,  7.27it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15601/17710 [39:56<04:50,  7.27it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15609/17710 [39:58<04:49,  7.25it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▎        | 15617/17710 [39:59<04:47,  7.29it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15625/17710 [40:00<04:46,  7.29it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15633/17710 [40:01<04:44,  7.29it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▍        | 15641/17710 [40:02<04:43,  7.29it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15649/17710 [40:03<04:43,  7.28it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15649/17710 [40:03<04:43,  7.28it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15657/17710 [40:04<04:43,  7.24it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15665/17710 [40:05<04:42,  7.23it/s, loss=nan]Epoch 0 - train:  88%|████████████████████████████████████████████████████████████████▌        | 15673/17710 [40:06<04:41,  7.23it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15681/17710 [40:07<04:42,  7.18it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15689/17710 [40:09<05:02,  6.68it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15697/17710 [40:10<04:53,  6.85it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15699/17710 [40:10<04:53,  6.85it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▋        | 15705/17710 [40:11<04:47,  6.97it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15713/17710 [40:12<04:42,  7.06it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15721/17710 [40:13<04:38,  7.13it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15729/17710 [40:14<04:35,  7.19it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▊        | 15737/17710 [40:15<04:32,  7.24it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15745/17710 [40:16<04:29,  7.30it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15749/17710 [40:17<04:28,  7.30it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15753/17710 [40:18<04:28,  7.29it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15761/17710 [40:19<04:24,  7.36it/s, loss=nan]Epoch 0 - train:  89%|████████████████████████████████████████████████████████████████▉        | 15769/17710 [40:20<04:25,  7.32it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15777/17710 [40:21<04:25,  7.28it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15785/17710 [40:22<04:26,  7.22it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15793/17710 [40:23<04:25,  7.22it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████        | 15799/17710 [40:24<04:24,  7.22it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15801/17710 [40:24<04:30,  7.06it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15809/17710 [40:25<04:29,  7.05it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15817/17710 [40:27<04:26,  7.11it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▏       | 15825/17710 [40:28<04:21,  7.21it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15833/17710 [40:29<04:20,  7.20it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15841/17710 [40:30<04:20,  7.19it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15849/17710 [40:31<04:15,  7.28it/s, loss=nan]Epoch 0 - train:  89%|█████████████████████████████████████████████████████████████████▎       | 15849/17710 [40:31<04:15,  7.28it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▎       | 15857/17710 [40:32<04:12,  7.35it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15865/17710 [40:33<04:11,  7.33it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15873/17710 [40:34<04:09,  7.36it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15881/17710 [40:35<04:07,  7.39it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▍       | 15889/17710 [40:36<04:05,  7.41it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15897/17710 [40:37<04:04,  7.40it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15899/17710 [40:38<04:04,  7.40it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15905/17710 [40:38<04:02,  7.43it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▌       | 15913/17710 [40:40<04:02,  7.41it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15921/17710 [40:41<04:01,  7.41it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15929/17710 [40:42<03:59,  7.43it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15937/17710 [40:43<04:00,  7.36it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15945/17710 [40:44<03:58,  7.40it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▋       | 15949/17710 [40:45<03:57,  7.40it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15953/17710 [40:45<03:56,  7.42it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15961/17710 [40:46<03:55,  7.43it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15969/17710 [40:47<03:53,  7.44it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▊       | 15977/17710 [40:48<03:53,  7.43it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15985/17710 [40:49<03:54,  7.36it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15993/17710 [40:50<03:52,  7.38it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 15999/17710 [40:51<03:51,  7.38it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 16001/17710 [40:51<03:52,  7.35it/s, loss=nan]Epoch 0 - train:  90%|█████████████████████████████████████████████████████████████████▉       | 16009/17710 [40:53<03:54,  7.26it/s, loss=nan]Epoch 0 - train:  90%|██████████████████████████████████████████████████████████████████       | 16017/17710 [40:54<03:52,  7.29it/s, loss=nan]Epoch 0 - train:  90%|██████████████████████████████████████████████████████████████████       | 16025/17710 [40:55<03:48,  7.37it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████       | 16033/17710 [40:56<03:46,  7.40it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████       | 16041/17710 [40:57<03:43,  7.47it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16049/17710 [40:58<03:41,  7.51it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16049/17710 [40:58<03:41,  7.51it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16057/17710 [40:59<03:41,  7.47it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▏      | 16065/17710 [41:00<03:40,  7.47it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16073/17710 [41:01<03:39,  7.44it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16081/17710 [41:02<03:38,  7.44it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16089/17710 [41:03<03:39,  7.37it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16097/17710 [41:04<03:37,  7.43it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▎      | 16099/17710 [41:05<03:36,  7.43it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16105/17710 [41:05<03:36,  7.42it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16113/17710 [41:07<03:35,  7.42it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16121/17710 [41:08<03:43,  7.11it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▍      | 16129/17710 [41:09<03:46,  6.98it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16137/17710 [41:10<03:42,  7.08it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16145/17710 [41:11<03:40,  7.11it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16149/17710 [41:12<03:39,  7.11it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16153/17710 [41:12<03:36,  7.20it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▌      | 16161/17710 [41:13<03:34,  7.22it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16169/17710 [41:14<03:33,  7.23it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16177/17710 [41:16<03:30,  7.28it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16185/17710 [41:17<03:28,  7.30it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▋      | 16193/17710 [41:18<03:26,  7.33it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▊      | 16199/17710 [41:19<03:26,  7.33it/s, loss=nan]Epoch 0 - train:  91%|██████████████████████████████████████████████████████████████████▊      | 16201/17710 [41:19<03:26,  7.31it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▊      | 16209/17710 [41:20<03:25,  7.31it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▊      | 16217/17710 [41:21<03:24,  7.32it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16225/17710 [41:22<03:23,  7.29it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16233/17710 [41:23<03:22,  7.28it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16241/17710 [41:24<03:22,  7.26it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16249/17710 [41:25<03:20,  7.29it/s, loss=nan]Epoch 0 - train:  92%|██████████████████████████████████████████████████████████████████▉      | 16249/17710 [41:26<03:20,  7.29it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16257/17710 [41:26<03:18,  7.30it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16265/17710 [41:28<03:17,  7.32it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16273/17710 [41:29<03:15,  7.34it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████      | 16281/17710 [41:30<03:13,  7.37it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16289/17710 [41:31<03:11,  7.42it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16297/17710 [41:32<03:11,  7.37it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16299/17710 [41:32<03:11,  7.37it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16305/17710 [41:33<03:10,  7.37it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▏     | 16313/17710 [41:34<03:08,  7.40it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16321/17710 [41:35<03:06,  7.45it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16329/17710 [41:36<03:05,  7.43it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16337/17710 [41:37<03:05,  7.39it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▎     | 16345/17710 [41:38<03:04,  7.39it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16349/17710 [41:39<03:04,  7.39it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16353/17710 [41:39<03:03,  7.38it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16361/17710 [41:41<03:02,  7.39it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▍     | 16369/17710 [41:42<03:03,  7.31it/s, loss=nan]Epoch 0 - train:  92%|███████████████████████████████████████████████████████████████████▌     | 16377/17710 [41:43<03:02,  7.32it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16385/17710 [41:44<03:00,  7.36it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16393/17710 [41:45<02:58,  7.39it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16399/17710 [41:46<02:57,  7.39it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▌     | 16401/17710 [41:46<02:58,  7.32it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16409/17710 [41:47<02:57,  7.35it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16417/17710 [41:48<02:55,  7.37it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16425/17710 [41:49<02:54,  7.36it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▋     | 16433/17710 [41:50<02:53,  7.34it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16441/17710 [41:51<02:53,  7.33it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16449/17710 [41:53<02:51,  7.37it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16449/17710 [41:53<02:51,  7.37it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16457/17710 [41:54<02:50,  7.33it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▊     | 16465/17710 [41:55<02:48,  7.37it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16473/17710 [41:56<02:48,  7.34it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16481/17710 [41:57<02:48,  7.30it/s, loss=nan]Epoch 0 - train:  93%|███████████████████████████████████████████████████████████████████▉     | 16489/17710 [41:58<02:48,  7.26it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16497/17710 [41:59<02:46,  7.28it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16499/17710 [42:00<02:46,  7.28it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16505/17710 [42:00<02:45,  7.29it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16513/17710 [42:01<02:42,  7.35it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████     | 16521/17710 [42:02<02:41,  7.37it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16529/17710 [42:03<02:39,  7.38it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16537/17710 [42:05<02:40,  7.32it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16545/17710 [42:06<02:38,  7.35it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16549/17710 [42:06<02:37,  7.35it/s, loss=nan]Epoch 0 - train:  93%|████████████████████████████████████████████████████████████████████▏    | 16553/17710 [42:07<02:36,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16561/17710 [42:08<02:38,  7.23it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16569/17710 [42:09<02:37,  7.27it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16577/17710 [42:10<02:36,  7.24it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▎    | 16585/17710 [42:11<02:32,  7.35it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16593/17710 [42:12<02:30,  7.44it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16599/17710 [42:13<02:29,  7.44it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16601/17710 [42:13<02:27,  7.50it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16609/17710 [42:14<02:27,  7.44it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▍    | 16617/17710 [42:15<02:29,  7.33it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16625/17710 [42:17<02:27,  7.34it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16633/17710 [42:18<02:26,  7.34it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▌    | 16641/17710 [42:19<02:24,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16649/17710 [42:20<02:24,  7.35it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16649/17710 [42:20<02:24,  7.35it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16657/17710 [42:21<02:23,  7.32it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16665/17710 [42:22<02:21,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▋    | 16673/17710 [42:23<02:20,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16681/17710 [42:24<02:18,  7.42it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16689/17710 [42:25<02:18,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16697/17710 [42:26<02:17,  7.35it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16699/17710 [42:27<02:17,  7.35it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▊    | 16705/17710 [42:27<02:17,  7.32it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16713/17710 [42:28<02:15,  7.34it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16721/17710 [42:30<02:13,  7.38it/s, loss=nan]Epoch 0 - train:  94%|████████████████████████████████████████████████████████████████████▉    | 16729/17710 [42:31<02:12,  7.38it/s, loss=nan]Epoch 0 - train:  95%|████████████████████████████████████████████████████████████████████▉    | 16737/17710 [42:32<02:12,  7.37it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16745/17710 [42:33<02:10,  7.40it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16749/17710 [42:34<02:09,  7.40it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16753/17710 [42:34<02:11,  7.29it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16761/17710 [42:35<02:09,  7.33it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████    | 16769/17710 [42:36<02:08,  7.35it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16777/17710 [42:37<02:06,  7.37it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16785/17710 [42:38<02:04,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16793/17710 [42:39<02:03,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▏   | 16799/17710 [42:40<02:02,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16801/17710 [42:40<02:02,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16809/17710 [42:41<02:01,  7.45it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16817/17710 [42:43<01:59,  7.44it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▎   | 16825/17710 [42:44<01:59,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16833/17710 [42:45<01:58,  7.40it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16841/17710 [42:46<01:56,  7.43it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16849/17710 [42:47<01:56,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16849/17710 [42:47<01:56,  7.42it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▍   | 16857/17710 [42:48<01:54,  7.46it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16865/17710 [42:49<01:53,  7.43it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16873/17710 [42:50<01:52,  7.45it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16881/17710 [42:51<01:50,  7.49it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▌   | 16889/17710 [42:52<01:50,  7.45it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16897/17710 [42:53<01:50,  7.39it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16899/17710 [42:54<01:49,  7.39it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16905/17710 [42:54<01:49,  7.35it/s, loss=nan]Epoch 0 - train:  95%|█████████████████████████████████████████████████████████████████████▋   | 16913/17710 [42:55<01:48,  7.36it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▋   | 16921/17710 [42:57<01:47,  7.36it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16929/17710 [42:58<01:46,  7.33it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16937/17710 [42:59<01:45,  7.32it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16945/17710 [43:00<01:45,  7.24it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▊   | 16949/17710 [43:01<01:45,  7.24it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16953/17710 [43:01<01:45,  7.19it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16961/17710 [43:02<01:44,  7.20it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16969/17710 [43:03<01:42,  7.22it/s, loss=nan]Epoch 0 - train:  96%|█████████████████████████████████████████████████████████████████████▉   | 16977/17710 [43:04<01:42,  7.18it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16985/17710 [43:05<01:40,  7.20it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16993/17710 [43:07<01:38,  7.26it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 16999/17710 [43:08<01:37,  7.26it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 17001/17710 [43:08<01:38,  7.23it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████   | 17009/17710 [43:09<01:39,  7.05it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17017/17710 [43:10<01:37,  7.14it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17025/17710 [43:11<01:35,  7.17it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17033/17710 [43:12<01:33,  7.21it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▏  | 17041/17710 [43:13<01:32,  7.22it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17049/17710 [43:14<01:31,  7.21it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17049/17710 [43:15<01:31,  7.21it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17057/17710 [43:15<01:30,  7.23it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17065/17710 [43:17<01:29,  7.24it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▎  | 17073/17710 [43:18<01:28,  7.23it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▍  | 17081/17710 [43:19<01:27,  7.16it/s, loss=nan]Epoch 0 - train:  96%|██████████████████████████████████████████████████████████████████████▍  | 17089/17710 [43:20<01:26,  7.20it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▍  | 17097/17710 [43:21<01:25,  7.19it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▍  | 17099/17710 [43:21<01:24,  7.19it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17105/17710 [43:22<01:23,  7.21it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17113/17710 [43:23<01:22,  7.28it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17121/17710 [43:24<01:20,  7.27it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▌  | 17129/17710 [43:25<01:19,  7.29it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17137/17710 [43:26<01:18,  7.33it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17145/17710 [43:28<01:16,  7.35it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17149/17710 [43:28<01:16,  7.35it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17153/17710 [43:29<01:15,  7.40it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▋  | 17161/17710 [43:30<01:14,  7.38it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17169/17710 [43:31<01:13,  7.38it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17177/17710 [43:32<01:13,  7.28it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17185/17710 [43:33<01:12,  7.23it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▊  | 17193/17710 [43:34<01:11,  7.27it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17199/17710 [43:35<01:10,  7.27it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17201/17710 [43:35<01:09,  7.30it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17209/17710 [43:36<01:08,  7.30it/s, loss=nan]Epoch 0 - train:  97%|██████████████████████████████████████████████████████████████████████▉  | 17217/17710 [43:37<01:07,  7.32it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17225/17710 [43:39<01:06,  7.26it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17233/17710 [43:40<01:05,  7.27it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17241/17710 [43:41<01:04,  7.22it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17249/17710 [43:42<01:03,  7.27it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████  | 17249/17710 [43:42<01:03,  7.27it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████▏ | 17257/17710 [43:43<01:03,  7.16it/s, loss=nan]Epoch 0 - train:  97%|███████████████████████████████████████████████████████████████████████▏ | 17265/17710 [43:44<01:02,  7.14it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▏ | 17273/17710 [43:45<01:00,  7.21it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▏ | 17281/17710 [43:46<00:59,  7.26it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17289/17710 [43:47<00:57,  7.29it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17297/17710 [43:48<00:56,  7.29it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17299/17710 [43:49<00:56,  7.29it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17305/17710 [43:50<00:55,  7.36it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▎ | 17313/17710 [43:51<00:53,  7.40it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17321/17710 [43:52<00:52,  7.36it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17329/17710 [43:53<00:51,  7.36it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17337/17710 [43:54<00:50,  7.32it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▍ | 17345/17710 [43:55<00:49,  7.40it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17349/17710 [43:56<00:48,  7.40it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17353/17710 [43:56<00:48,  7.35it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17361/17710 [43:57<00:47,  7.40it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▌ | 17369/17710 [43:58<00:45,  7.42it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17377/17710 [43:59<00:45,  7.30it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17385/17710 [44:00<00:44,  7.32it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17393/17710 [44:02<00:43,  7.27it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17399/17710 [44:02<00:42,  7.27it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▋ | 17401/17710 [44:03<00:42,  7.27it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17409/17710 [44:04<00:41,  7.34it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17417/17710 [44:05<00:39,  7.40it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17425/17710 [44:06<00:38,  7.43it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▊ | 17433/17710 [44:07<00:37,  7.48it/s, loss=nan]Epoch 0 - train:  98%|███████████████████████████████████████████████████████████████████████▉ | 17441/17710 [44:08<00:36,  7.31it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17449/17710 [44:09<00:35,  7.31it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17449/17710 [44:09<00:35,  7.31it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17457/17710 [44:10<00:34,  7.30it/s, loss=nan]Epoch 0 - train:  99%|███████████████████████████████████████████████████████████████████████▉ | 17465/17710 [44:11<00:33,  7.35it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17473/17710 [44:12<00:32,  7.36it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17481/17710 [44:13<00:31,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17489/17710 [44:15<00:29,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████ | 17497/17710 [44:16<00:28,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17499/17710 [44:16<00:28,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17505/17710 [44:17<00:27,  7.34it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17513/17710 [44:18<00:27,  7.29it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▏| 17521/17710 [44:19<00:25,  7.33it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17529/17710 [44:20<00:24,  7.32it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17537/17710 [44:21<00:23,  7.32it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17545/17710 [44:22<00:22,  7.26it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17549/17710 [44:23<00:22,  7.26it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▎| 17553/17710 [44:23<00:21,  7.32it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17561/17710 [44:24<00:20,  7.37it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17569/17710 [44:25<00:19,  7.41it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17577/17710 [44:27<00:17,  7.43it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▍| 17585/17710 [44:28<00:16,  7.44it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17593/17710 [44:29<00:15,  7.43it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17599/17710 [44:30<00:14,  7.43it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17601/17710 [44:30<00:14,  7.42it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17609/17710 [44:31<00:13,  7.43it/s, loss=nan]Epoch 0 - train:  99%|████████████████████████████████████████████████████████████████████████▌| 17617/17710 [44:32<00:12,  7.45it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17625/17710 [44:33<00:11,  7.45it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17633/17710 [44:34<00:10,  7.42it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17641/17710 [44:35<00:09,  7.42it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17649/17710 [44:36<00:08,  7.40it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▋| 17649/17710 [44:36<00:08,  7.40it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17657/17710 [44:37<00:07,  7.41it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17665/17710 [44:38<00:06,  7.37it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▊| 17673/17710 [44:39<00:05,  7.38it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17681/17710 [44:41<00:03,  7.40it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17689/17710 [44:42<00:02,  7.40it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17697/17710 [44:43<00:01,  7.46it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17699/17710 [44:43<00:01,  7.46it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17705/17710 [44:44<00:00,  7.25it/s, loss=nan]Epoch 0 - train: 100%|████████████████████████████████████████████████████████████████████████▉| 17709/17710 [44:45<00:00,  7.25it/s, loss=nan]Epoch 0 - train: 100%|█████████████████████████████████████████████████████████████████████████| 17710/17710 [44:45<00:00,  6.60it/s, loss=nan]
训练损失: nan
Epoch 0 - validation:   0%|                                                                                            | 0/782 [00:00<?, ?it/s]Epoch 0 - validation:   0%|                                                                                    | 1/782 [00:01<19:43,  1.52s/it]Epoch 0 - validation:   1%|▊                                                                                   | 7/782 [00:02<04:02,  3.20it/s]Epoch 0 - validation:   2%|█▍                                                                                 | 13/782 [00:03<02:59,  4.29it/s]Epoch 0 - validation:   2%|██                                                                                 | 19/782 [00:04<02:36,  4.88it/s]Epoch 0 - validation:   3%|██▋                                                                                | 25/782 [00:05<02:24,  5.24it/s]Epoch 0 - validation:   4%|███▎                                                                               | 31/782 [00:06<02:17,  5.46it/s]Epoch 0 - validation:   5%|███▉                                                                               | 37/782 [00:07<02:12,  5.61it/s]Epoch 0 - validation:   5%|████▌                                                                              | 43/782 [00:08<02:09,  5.70it/s]Epoch 0 - validation:   6%|█████▏                                                                             | 49/782 [00:09<02:07,  5.77it/s]Epoch 0 - validation:   6%|████▌                                                                    | 49/782 [00:09<02:07,  5.77it/s, loss=137]Epoch 0 - validation:   7%|█████▏                                                                   | 55/782 [00:10<02:05,  5.81it/s, loss=137]Epoch 0 - validation:   8%|█████▋                                                                   | 61/782 [00:11<02:03,  5.83it/s, loss=137]Epoch 0 - validation:   9%|██████▎                                                                  | 67/782 [00:12<02:02,  5.86it/s, loss=137]Epoch 0 - validation:   9%|██████▊                                                                  | 73/782 [00:13<02:00,  5.88it/s, loss=137]Epoch 0 - validation:  10%|███████▎                                                                 | 79/782 [00:14<01:59,  5.90it/s, loss=137]Epoch 0 - validation:  11%|███████▉                                                                 | 85/782 [00:15<01:58,  5.89it/s, loss=137]Epoch 0 - validation:  12%|████████▍                                                                | 91/782 [00:16<01:58,  5.85it/s, loss=137]Epoch 0 - validation:  12%|█████████                                                                | 97/782 [00:17<01:56,  5.86it/s, loss=137]Epoch 0 - validation:  13%|█████████▏                                                               | 99/782 [00:18<01:56,  5.86it/s, loss=137]Epoch 0 - validation:  13%|█████████▍                                                              | 103/782 [00:18<01:55,  5.87it/s, loss=137]Epoch 0 - validation:  14%|██████████                                                              | 109/782 [00:19<01:54,  5.89it/s, loss=137]Epoch 0 - validation:  15%|██████████▌                                                             | 115/782 [00:20<01:53,  5.90it/s, loss=137]Epoch 0 - validation:  15%|███████████▏                                                            | 121/782 [00:21<01:52,  5.88it/s, loss=137]Epoch 0 - validation:  16%|███████████▋                                                            | 127/782 [00:22<01:51,  5.88it/s, loss=137]Epoch 0 - validation:  17%|████████████▏                                                           | 133/782 [00:24<01:58,  5.47it/s, loss=137]Epoch 0 - validation:  18%|████████████▊                                                           | 139/782 [00:25<01:54,  5.60it/s, loss=137]Epoch 0 - validation:  19%|█████████████▎                                                          | 145/782 [00:26<01:52,  5.68it/s, loss=137]Epoch 0 - validation:  19%|█████████████▋                                                          | 149/782 [00:27<01:51,  5.68it/s, loss=137]Epoch 0 - validation:  19%|█████████████▉                                                          | 151/782 [00:27<01:50,  5.74it/s, loss=137]Epoch 0 - validation:  20%|██████████████▍                                                         | 157/782 [00:28<01:48,  5.78it/s, loss=137]Epoch 0 - validation:  21%|███████████████                                                         | 163/782 [00:29<01:46,  5.81it/s, loss=137]Epoch 0 - validation:  22%|███████████████▌                                                        | 169/782 [00:30<01:45,  5.83it/s, loss=137]Epoch 0 - validation:  22%|████████████████                                                        | 175/782 [00:31<01:43,  5.86it/s, loss=137]Epoch 0 - validation:  23%|████████████████▋                                                       | 181/782 [00:32<01:42,  5.87it/s, loss=137]Epoch 0 - validation:  24%|█████████████████▏                                                      | 187/782 [00:33<01:41,  5.88it/s, loss=137]Epoch 0 - validation:  25%|█████████████████▊                                                      | 193/782 [00:34<01:40,  5.89it/s, loss=137]Epoch 0 - validation:  25%|██████████████████▎                                                     | 199/782 [00:35<01:38,  5.89it/s, loss=137]Epoch 0 - validation:  25%|██████████████████▎                                                     | 199/782 [00:35<01:38,  5.89it/s, loss=137]Epoch 0 - validation:  26%|██████████████████▊                                                     | 205/782 [00:36<01:38,  5.89it/s, loss=137]Epoch 0 - validation:  27%|███████████████████▍                                                    | 211/782 [00:37<01:37,  5.89it/s, loss=137]Epoch 0 - validation:  28%|███████████████████▉                                                    | 217/782 [00:38<01:35,  5.90it/s, loss=137]Epoch 0 - validation:  29%|████████████████████▌                                                   | 223/782 [00:39<01:34,  5.92it/s, loss=137]Epoch 0 - validation:  29%|█████████████████████                                                   | 229/782 [00:40<01:33,  5.92it/s, loss=137]Epoch 0 - validation:  30%|█████████████████████▋                                                  | 235/782 [00:41<01:32,  5.92it/s, loss=137]Epoch 0 - validation:  31%|██████████████████████▏                                                 | 241/782 [00:42<01:31,  5.92it/s, loss=137]Epoch 0 - validation:  32%|██████████████████████▋                                                 | 247/782 [00:43<01:30,  5.92it/s, loss=137]Epoch 0 - validation:  32%|██████████████████████▉                                                 | 249/782 [00:43<01:30,  5.92it/s, loss=137]Epoch 0 - validation:  32%|███████████████████████▎                                                | 253/782 [00:44<01:29,  5.92it/s, loss=137]Epoch 0 - validation:  33%|███████████████████████▊                                                | 259/782 [00:45<01:28,  5.92it/s, loss=137]Epoch 0 - validation:  34%|████████████████████████▍                                               | 265/782 [00:46<01:27,  5.90it/s, loss=137]Epoch 0 - validation:  35%|████████████████████████▉                                               | 271/782 [00:47<01:26,  5.90it/s, loss=137]Epoch 0 - validation:  35%|█████████████████████████▌                                              | 277/782 [00:48<01:25,  5.90it/s, loss=137]Epoch 0 - validation:  36%|██████████████████████████                                              | 283/782 [00:49<01:24,  5.91it/s, loss=137]Epoch 0 - validation:  37%|██████████████████████████▌                                             | 289/782 [00:50<01:23,  5.89it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▏                                            | 295/782 [00:51<01:22,  5.90it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▌                                            | 299/782 [00:52<01:21,  5.90it/s, loss=137]Epoch 0 - validation:  38%|███████████████████████████▋                                            | 301/782 [00:52<01:21,  5.91it/s, loss=137]Epoch 0 - validation:  39%|████████████████████████████▎                                           | 307/782 [00:53<01:20,  5.90it/s, loss=137]Epoch 0 - validation:  40%|████████████████████████████▊                                           | 313/782 [00:54<01:19,  5.88it/s, loss=137]Epoch 0 - validation:  41%|█████████████████████████████▎                                          | 319/782 [00:55<01:18,  5.87it/s, loss=137]Epoch 0 - validation:  42%|█████████████████████████████▉                                          | 325/782 [00:56<01:17,  5.87it/s, loss=137]Epoch 0 - validation:  42%|██████████████████████████████▍                                         | 331/782 [00:57<01:16,  5.88it/s, loss=137]Epoch 0 - validation:  43%|███████████████████████████████                                         | 337/782 [00:58<01:15,  5.87it/s, loss=137]Epoch 0 - validation:  44%|███████████████████████████████▌                                        | 343/782 [00:59<01:14,  5.88it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████▏                                       | 349/782 [01:00<01:13,  5.88it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████▏                                       | 349/782 [01:00<01:13,  5.88it/s, loss=137]Epoch 0 - validation:  45%|████████████████████████████████▋                                       | 355/782 [01:01<01:12,  5.88it/s, loss=137]Epoch 0 - validation:  46%|█████████████████████████████████▏                                      | 361/782 [01:02<01:11,  5.88it/s, loss=137]Epoch 0 - validation:  47%|█████████████████████████████████▊                                      | 367/782 [01:03<01:10,  5.88it/s, loss=137]Epoch 0 - validation:  48%|██████████████████████████████████▎                                     | 373/782 [01:04<01:09,  5.88it/s, loss=137]Epoch 0 - validation:  48%|██████████████████████████████████▉                                     | 379/782 [01:05<01:08,  5.89it/s, loss=137]Epoch 0 - validation:  49%|███████████████████████████████████▍                                    | 385/782 [01:06<01:07,  5.89it/s, loss=137]Epoch 0 - validation:  50%|████████████████████████████████████                                    | 391/782 [01:07<01:06,  5.90it/s, loss=137]Epoch 0 - validation:  51%|████████████████████████████████████▌                                   | 397/782 [01:08<01:05,  5.89it/s, loss=137]Epoch 0 - validation:  51%|████████████████████████████████████▋                                   | 399/782 [01:09<01:04,  5.89it/s, loss=137]Epoch 0 - validation:  52%|█████████████████████████████████████                                   | 403/782 [01:09<01:04,  5.89it/s, loss=137]Epoch 0 - validation:  52%|█████████████████████████████████████▋                                  | 409/782 [01:10<01:03,  5.89it/s, loss=137]Epoch 0 - validation:  53%|██████████████████████████████████████▏                                 | 415/782 [01:12<01:02,  5.89it/s, loss=137]Epoch 0 - validation:  54%|██████████████████████████████████████▊                                 | 421/782 [01:13<01:01,  5.88it/s, loss=137]Epoch 0 - validation:  55%|███████████████████████████████████████▎                                | 427/782 [01:14<01:00,  5.88it/s, loss=137]Epoch 0 - validation:  55%|███████████████████████████████████████▊                                | 433/782 [01:15<00:59,  5.88it/s, loss=137]Epoch 0 - validation:  56%|████████████████████████████████████████▍                               | 439/782 [01:16<00:58,  5.88it/s, loss=137]Epoch 0 - validation:  57%|████████████████████████████████████████▉                               | 445/782 [01:17<00:57,  5.89it/s, loss=137]Epoch 0 - validation:  57%|█████████████████████████████████████████▎                              | 449/782 [01:17<00:56,  5.89it/s, loss=137]Epoch 0 - validation:  58%|█████████████████████████████████████████▌                              | 451/782 [01:18<00:56,  5.90it/s, loss=137]Epoch 0 - validation:  58%|██████████████████████████████████████████                              | 457/782 [01:19<00:55,  5.89it/s, loss=137]Epoch 0 - validation:  59%|██████████████████████████████████████████▋                             | 463/782 [01:20<00:54,  5.89it/s, loss=137]Epoch 0 - validation:  60%|███████████████████████████████████████████▏                            | 469/782 [01:21<00:53,  5.89it/s, loss=137]Epoch 0 - validation:  61%|███████████████████████████████████████████▋                            | 475/782 [01:22<00:52,  5.89it/s, loss=137]Epoch 0 - validation:  62%|████████████████████████████████████████████▎                           | 481/782 [01:23<00:51,  5.79it/s, loss=137]Epoch 0 - validation:  62%|████████████████████████████████████████████▊                           | 487/782 [01:24<00:50,  5.81it/s, loss=137]Epoch 0 - validation:  63%|█████████████████████████████████████████████▍                          | 493/782 [01:25<00:49,  5.83it/s, loss=137]Epoch 0 - validation:  64%|█████████████████████████████████████████████▉                          | 499/782 [01:26<00:48,  5.85it/s, loss=137]Epoch 0 - validation:  64%|█████████████████████████████████████████████▉                          | 499/782 [01:26<00:48,  5.85it/s, loss=137]Epoch 0 - validation:  65%|██████████████████████████████████████████████▍                         | 505/782 [01:27<00:47,  5.86it/s, loss=137]Epoch 0 - validation:  65%|███████████████████████████████████████████████                         | 511/782 [01:28<00:46,  5.86it/s, loss=137]Epoch 0 - validation:  66%|███████████████████████████████████████████████▌                        | 517/782 [01:29<00:45,  5.86it/s, loss=137]Epoch 0 - validation:  67%|████████████████████████████████████████████████▏                       | 523/782 [01:30<00:44,  5.88it/s, loss=137]Epoch 0 - validation:  68%|████████████████████████████████████████████████▋                       | 529/782 [01:31<00:42,  5.89it/s, loss=137]Epoch 0 - validation:  68%|█████████████████████████████████████████████████▎                      | 535/782 [01:32<00:41,  5.90it/s, loss=137]Epoch 0 - validation:  69%|█████████████████████████████████████████████████▊                      | 541/782 [01:33<00:40,  5.89it/s, loss=137]Epoch 0 - validation:  70%|██████████████████████████████████████████████████▎                     | 547/782 [01:34<00:39,  5.89it/s, loss=137]Epoch 0 - validation:  70%|██████████████████████████████████████████████████▌                     | 549/782 [01:35<00:39,  5.89it/s, loss=137]Epoch 0 - validation:  71%|██████████████████████████████████████████████████▉                     | 553/782 [01:35<00:38,  5.89it/s, loss=137]Epoch 0 - validation:  71%|███████████████████████████████████████████████████▍                    | 559/782 [01:36<00:37,  5.89it/s, loss=137]Epoch 0 - validation:  72%|████████████████████████████████████████████████████                    | 565/782 [01:37<00:36,  5.89it/s, loss=137]Epoch 0 - validation:  73%|████████████████████████████████████████████████████▌                   | 571/782 [01:38<00:35,  5.89it/s, loss=137]Epoch 0 - validation:  74%|█████████████████████████████████████████████████████▏                  | 577/782 [01:39<00:34,  5.89it/s, loss=137]Epoch 0 - validation:  75%|█████████████████████████████████████████████████████▋                  | 583/782 [01:40<00:33,  5.90it/s, loss=137]Epoch 0 - validation:  75%|██████████████████████████████████████████████████████▏                 | 589/782 [01:41<00:32,  5.90it/s, loss=137]Epoch 0 - validation:  76%|██████████████████████████████████████████████████████▊                 | 595/782 [01:42<00:31,  5.90it/s, loss=137]Epoch 0 - validation:  77%|███████████████████████████████████████████████████████▏                | 599/782 [01:43<00:31,  5.90it/s, loss=137]Epoch 0 - validation:  77%|███████████████████████████████████████████████████████▎                | 601/782 [01:43<00:30,  5.90it/s, loss=137]Epoch 0 - validation:  78%|███████████████████████████████████████████████████████▉                | 607/782 [01:44<00:29,  5.90it/s, loss=137]Epoch 0 - validation:  78%|████████████████████████████████████████████████████████▍               | 613/782 [01:45<00:28,  5.90it/s, loss=137]Epoch 0 - validation:  79%|████████████████████████████████████████████████████████▉               | 619/782 [01:46<00:27,  5.90it/s, loss=137]Epoch 0 - validation:  80%|█████████████████████████████████████████████████████████▌              | 625/782 [01:47<00:26,  5.90it/s, loss=137]Epoch 0 - validation:  81%|██████████████████████████████████████████████████████████              | 631/782 [01:48<00:25,  5.90it/s, loss=137]Epoch 0 - validation:  81%|██████████████████████████████████████████████████████████▋             | 637/782 [01:49<00:24,  5.90it/s, loss=137]Epoch 0 - validation:  82%|███████████████████████████████████████████████████████████▏            | 643/782 [01:50<00:23,  5.90it/s, loss=137]Epoch 0 - validation:  83%|███████████████████████████████████████████████████████████▊            | 649/782 [01:51<00:22,  5.90it/s, loss=137]Epoch 0 - validation:  83%|███████████████████████████████████████████████████████████▊            | 649/782 [01:51<00:22,  5.90it/s, loss=137]Epoch 0 - validation:  84%|████████████████████████████████████████████████████████████▎           | 655/782 [01:52<00:21,  5.88it/s, loss=137]Epoch 0 - validation:  85%|████████████████████████████████████████████████████████████▊           | 661/782 [01:53<00:20,  5.88it/s, loss=137]Epoch 0 - validation:  85%|█████████████████████████████████████████████████████████████▍          | 667/782 [01:54<00:19,  5.90it/s, loss=137]Epoch 0 - validation:  86%|█████████████████████████████████████████████████████████████▉          | 673/782 [01:55<00:18,  5.91it/s, loss=137]Epoch 0 - validation:  87%|██████████████████████████████████████████████████████████████▌         | 679/782 [01:56<00:17,  5.91it/s, loss=137]Epoch 0 - validation:  88%|███████████████████████████████████████████████████████████████         | 685/782 [01:57<00:16,  5.91it/s, loss=137]Epoch 0 - validation:  88%|███████████████████████████████████████████████████████████████▌        | 691/782 [01:58<00:15,  5.90it/s, loss=137]Epoch 0 - validation:  89%|████████████████████████████████████████████████████████████████▏       | 697/782 [01:59<00:14,  5.90it/s, loss=137]Epoch 0 - validation:  89%|████████████████████████████████████████████████████████████████▎       | 699/782 [02:00<00:14,  5.90it/s, loss=137]Epoch 0 - validation:  90%|████████████████████████████████████████████████████████████████▋       | 703/782 [02:00<00:13,  5.90it/s, loss=137]Epoch 0 - validation:  91%|█████████████████████████████████████████████████████████████████▎      | 709/782 [02:01<00:12,  5.90it/s, loss=137]Epoch 0 - validation:  91%|█████████████████████████████████████████████████████████████████▊      | 715/782 [02:02<00:11,  5.89it/s, loss=137]Epoch 0 - validation:  92%|██████████████████████████████████████████████████████████████████▍     | 721/782 [02:04<00:10,  5.89it/s, loss=137]Epoch 0 - validation:  93%|██████████████████████████████████████████████████████████████████▉     | 727/782 [02:05<00:09,  5.88it/s, loss=137]Epoch 0 - validation:  94%|███████████████████████████████████████████████████████████████████▍    | 733/782 [02:06<00:08,  5.88it/s, loss=137]Epoch 0 - validation:  95%|████████████████████████████████████████████████████████████████████    | 739/782 [02:07<00:07,  5.89it/s, loss=137]Epoch 0 - validation:  95%|████████████████████████████████████████████████████████████████████▌   | 745/782 [02:08<00:06,  5.88it/s, loss=137]Epoch 0 - validation:  96%|████████████████████████████████████████████████████████████████████▉   | 749/782 [02:08<00:05,  5.88it/s, loss=137]Epoch 0 - validation:  96%|█████████████████████████████████████████████████████████████████████▏  | 751/782 [02:09<00:05,  5.88it/s, loss=137]Epoch 0 - validation:  97%|█████████████████████████████████████████████████████████████████████▋  | 757/782 [02:10<00:04,  5.89it/s, loss=137]Epoch 0 - validation:  98%|██████████████████████████████████████████████████████████████████████▎ | 763/782 [02:11<00:03,  5.89it/s, loss=137]Epoch 0 - validation:  98%|██████████████████████████████████████████████████████████████████████▊ | 769/782 [02:12<00:02,  5.89it/s, loss=137]Epoch 0 - validation:  99%|███████████████████████████████████████████████████████████████████████▎| 775/782 [02:13<00:01,  5.89it/s, loss=137]Epoch 0 - validation: 100%|███████████████████████████████████████████████████████████████████████▉| 781/782 [02:14<00:00,  5.88it/s, loss=137]Epoch 0 - validation: 100%|███████████████████████████████████████████████████████████████████████▉| 781/782 [02:14<00:00,  5.88it/s, loss=137]Epoch 0 - validation: 100%|████████████████████████████████████████████████████████████████████████| 782/782 [02:14<00:00,  5.82it/s, loss=137]
验证损失: 136.8897
Epoch 0 - evaluation:   0%|                                                                                            | 0/834 [00:00<?, ?it/s]Epoch 0 - evaluation:   0%|                                                                                            | 0/834 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "train_transformer.py", line 379, in <module>
    scores_val = evaluate_metrics(model, dict_dataloader_val, text_field, e, device)
  File "train_transformer.py", line 76, in evaluate_metrics
    for it, ((detections, _), caps_gt) in enumerate(iter(dataloader)):
ValueError: too many values to unpack (expected 2)
